% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/kuenm_mop.R
\name{kuenm_mop}
\alias{kuenm_mop}
\title{Analysis of extrapolation risks using the MOP metric}
\usage{
kuenm_mop(
  data,
  subset_variables = TRUE,
  fitted_models = NULL,
  projection_data,
  out_dir,
  type = "basic",
  calculate_distance = FALSE,
  where_distance = "in_range",
  distance = "euclidean",
  scale = FALSE,
  center = FALSE,
  fix_NA = TRUE,
  percentage = 1,
  comp_each = 2000,
  tol = NULL,
  rescale_distance = FALSE,
  parallel = FALSE,
  n_cores = 1,
  progress_bar = FALSE,
  overwrite = FALSE
)
}
\arguments{
\item{data}{an object of class \code{prepare_data} returned by the \code{\link[kuenm2]{prepare_data}}
function.}

\item{subset_variables}{(logical) whether to include in the analysis only the variables present in the selected models. Default is TRUE.}

\item{fitted_models}{an object of class \code{fitted_models} returned by the
\code{\link[kuenm2]{fit_selected}} function.}

\item{projection_data}{an object of class \code{prepared_proj} returned by the
\code{\link[kuenm2]{prepare_proj}}function. This file contains the paths to
the rasters representing each scenario.}

\item{out_dir}{(character) a path to a root directory for saving the raster file of each projection.}

\item{type}{(character) type of MOP analysis to be performed. Options available are "basic", "simple" and "detailed". See Details for further information.}

\item{calculate_distance}{(logical) whether to calculate distances (dissimilarities) between m and g. The default, FALSE, runs rapidly and does not assess dissimilarity levels.}

\item{where_distance}{(character) where to calculate distances, considering how conditions in g are positioned in comparison to the range of conditions in m. Options available are "in_range", "out_range" and "all". Default is "in_range".}

\item{distance}{(character) which distances are calculated, euclidean or mahalanobis. Only applicable if calculate_distance = TRUE.}

\item{scale}{(logical or numeric) whether to scale as in \code{\link[base]{scale}}. Default is FALSE.}

\item{center}{(logical or numeric) whether to center as in \code{\link[base]{scale}}. Default is FALSE.}

\item{fix_NA}{(logical) whether to fix layers so cells with NA values are the same in all layers. Setting to FALSE may save time if the rasters are big and have no NA matching problems. Default is TRUE.}

\item{percentage}{(numeric) percentage of \code{m} closest conditions used to derive mean environmental distances to each combination of conditions in \code{g}.}

\item{comp_each}{(numeric) number of combinations in \code{g} to be used for
distance calculations at a time. Increasing this number requires more RAM}

\item{tol}{(numeric) tolerance to detect linear dependencies when calculating
Mahalanobis distances. The default, NULL, uses \code{.Machine$double.eps}.}

\item{rescale_distance}{(logical) whether to re-scale distances 0-1.
Re-scaling prevents comparisons of dissimilarity values obtained from runs
with different values of \code{percentage}.}

\item{parallel}{(logical) whether to fit the candidate models in parallel.
Default is FALSE.}

\item{n_cores}{(numeric) number of cores to use for parallel processing.
Default is 1. This is only applicable if \code{parallel = TRUE}.}

\item{progress_bar}{(logical) whether to display a progress bar during processing. Default is FALSE.}

\item{overwrite}{(logical) whether to overwrite SpatRaster if they already exists. Only applicable if \code{write_files} is set to TRUE. Default is FALSE.}
}
\value{
A dataframe containing the file paths where the results were stored for each scenario. The paths contain the following files:
\itemize{
\item \strong{summary} - a data.frame with details of the data used in the analysis:
\itemize{
\item \emph{variables} - names of variables considered.
\item \emph{type} - type of MOP analysis performed.
\item \emph{scale} - value according to the argument \code{scale}.
\item \emph{center} - value according to the argument \code{center}.
\item \emph{calculate_distance} - value according to the argument
\code{calculate_distance}.
\item \emph{distance} - option regarding distance used.
\item \emph{percentage} - percentage of \code{m} used as reference for
distance calculation.
\item \emph{rescale_distance} - value according to the argument
\code{rescale_distance}.
\item \emph{fix_NA} - value according to the argument \code{fix_NA}.
\item \emph{N_m} - total number of elements (cells with values or valid
rows) in \code{m}.
\item \emph{N_g} - total number of elements (cells with values or valid
rows) in \code{g}.
\item \emph{m_min} - minimum values (lower limit) of the variables in reference conditions
(\code{m}).
\item \emph{m_max} - maximum values (upper limit) of the variables in reference conditions
(\code{m}).
}
\item \strong{mop_distances} - if \code{calculate_distance} = TRUE, a SpatRaster or
vector with distance values for the set of interest (\code{g}). Higher values
represent greater dissimilarity compared to the set of reference (\code{m}).
\item \strong{mop_basic} - a SpatRaster or vector, for the set of interest,
representing conditions in which at least one of the variables is
non-analogous to the set of reference. Values should be: 1 for non-analogous
conditions, and NA for conditions inside the ranges of the reference set.
\item \strong{mop_simple} - a SpatRaster or vector, for the set of interest,
representing how many variables in the set of interest are non-analogous to
those in the reference set. NA is used for conditions inside the ranges of
the reference set.
\item \strong{mop_detailed} - a list containing:
\itemize{
\item \emph{interpretation_combined} - a data.frame to help identify combinations
of variables in \emph{towards_low_combined} and \emph{towards_high_combined} that
are non-analogous to \code{m}.
\item \emph{towards_low_end} - a SpatRaster or matrix for all variables
representing where non-analogous conditions were found towards low values
of each variable.
\item \emph{towards_high_end} - a SpatRaster or matrix for all variables
representing where non-analogous conditions were found towards high
values of each variable.
\item \emph{towards_low_combined} - a SpatRaster or vector with values
representing the identity of the variables found to have non-analogous
conditions towards low values. If vector, interpretation requires the use
of the data.frame \emph{interpretation_combined}.
\item \emph{towards_high_combined} - a SpatRaster or vector with values
representing the identity of the variables found to have non-analogous
conditions towards high values. If vector, interpretation requires the
use of the data.frame \emph{interpretation_combined}.
}
}
}
\description{
This function calculates the mobility-oriented parity metric and other sub-products to represent dissimilarities and non-analogous conditions when comparing a set of reference conditions (M) against another set of conditions of interest (G).
}
\details{
\code{type} options return results that differ in the detail of how non-analogous
conditions are identified.
\itemize{
\item \strong{basic} - makes calculation as proposed by Owens et al. (2013)
\url{doi:10.1016/j.ecolmodel.2013.04.011}.
\item \strong{simple} - calculates how many variables in the set of interest are
non-analogous to those in the reference set.
\item \strong{detailed} - calculates five additional extrapolation metrics. See
\code{mop_detailed} under \code{Value} below for full details.
}

\code{where_distance} options determine what values should be used to calculate
dissimilarity
\itemize{
\item \strong{in_range} - only conditions inside \code{m} ranges
\item \strong{out_range} - only conditions outside \code{m} ranges
\item \strong{all} - all conditions
}

When the variables used to represent conditions have different units,
scaling and centering are recommended. This step is only valid when Euclidean
distances are used.
}
\examples{
#Import raster layers
var <- terra::rast(system.file("extdata", "Current_variables.tif",
                               package = "kuenm2"))
#Import occurrences
data(occ_data, package = "kuenm2")
#Prepare data
sp_swd <- prepare_data(model_type = "glmnet", occ = occ_data,
                       species = occ_data[1, 1], x = "x", y = "y",
                       spat_variables = var, mask = NULL,
                       categorical_variables = "SoilType",
                       do_pca = FALSE, deviance_explained = 95,
                       min_explained = 5, center = TRUE, scale = TRUE,
                       write_pca = FALSE, output_pca = NULL, nbg = 500,
                       kfolds = 4, weights = NULL, min_number = 2,
                       min_continuous = NULL,
                       features = c("l", "q", "p", "lq", "lqp"),
                       regm = c(0.1, 1, 2, 3, 5),
                       include_xy = TRUE,
                       write_file = FALSE, file_name = NULL,
                       seed = 1)
sp_swd
#Example with GLMNET
# Import example of fitted_models (output of fit_selected())
data("fitted_model_glmnet", package = "kuenm2")

# Organize and structure future climate variables from WorldClim
# Import the current variables used to fit the model.
# In this case, SoilType will be treated as a static variable (constant across future scenarios).
var <- terra::rast(system.file("extdata", "Current_variables.tif",
                               package = "kuenm2"))
# Create a "Current_raw" folder in a temporary directory and copy the raw variables there.
out_dir_current <- file.path(tempdir(), "Current_raw")
dir.create(out_dir_current, recursive = TRUE)
# Save current variables in temporary directory
writeRaster(var, file.path(out_dir_current, "Variables.tif"))

# Set the input directory containing the raw future climate variables.
# For this example, the data is located in the "inst/extdata" folder.
in_dir <- "inst/extdata/"
# Create a "Future_raw" folder in a temporary directory and copy the raw variables there.
out_dir_future <- file.path(tempdir(), "Future_raw")
# Organize and rename the future climate data, structuring it by year and GCM.
# The 'SoilType' variable will be appended as a static variable in each scenario.
# The files will be renamed following the "bio_" format
organize_future_worldclim(input_dir = in_dir,
                          output_dir = out_dir_future,
                          name_format = "bio_", variables = NULL,
                          fixed_variables = var$SoilType, mask = NULL,
                          overwrite = TRUE)
# Prepare projections
pr <- prepare_proj(models = fitted_model_glmnet,
                   present_dir = out_dir_current,
                   past_dir = NULL,
                   past_period = NULL,
                   past_gcm = NULL,
                   future_dir = out_dir_future,
                   future_period = c("2041-2060", "2081-2100"),
                   future_pscen = c("ssp126", "ssp585"),
                   future_gcm = c("ACCESS-CM2", "MIROC6"),
                   write_file = FALSE,
                   filename = NULL,
                   raster_pattern = ".tif*")

#Create folder to save MOP results
out_dir <- file.path(tempdir(), "MOP_results")
dir.create(out_dir, recursive = TRUE)

# MOP
kmop <- kuenm_mop(data = sp_swd,
                  subset_variables = TRUE,
                  fitted_models = fitted_model_glmnet,
                  projection_data = pr,
                  out_dir = out_dir,
                  type = "detailed", calculate_distance = FALSE,
                  where_distance = "in_range", distance = "euclidean",
                  scale = FALSE, center = FALSE, fix_NA = TRUE, percentage = 1,
                  comp_each = 2000, tol = NULL, rescale_distance = FALSE,
                  parallel = FALSE, n_cores = 1, progress_bar = FALSE,
                  overwrite = TRUE)

}
