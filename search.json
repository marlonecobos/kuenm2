[{"path":"https://marlonecobos.github.io/kuenm2/articles/basic_bata_cleaning.html","id":"description","dir":"Articles","previous_headings":"","what":"Description","title":"Occurrence Data Cleaning","text":"modeling technique, ecological niche modeling depends quality input data, particularly species occurrence records. Cleaning data critical step minimize biases, reduce errors, ensure meaningful model outcomes. vignette introduces tools available kuenm2 package facilitate cleaning occurrence data prior modeling. guides users loading inspecting data, applying cleaning functions, saving cleaned datasets, within reproducible R workflow. want highlight additional data cleaning filtering steps (e.g., spatial thinning) may necessary depending type model modeling approach user intends adopt. tools presented designed assist basic steps preparing data modeling.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/articles/basic_bata_cleaning.html","id":"getting-ready","dir":"Articles","previous_headings":"","what":"Getting ready","title":"Occurrence Data Cleaning","text":"kuenm2 installed yet, please . See Main guide installation instructions. Load kuenm2 required packages, define working directory (needed). general, setting working directory R considered good practice, provides better control files read saved . users working within R project, recommend setting working directory, since least one file saved later stages guide.","code":"# Load packages library(kuenm2) library(terra)  # Current directory getwd()  # Define new directory #setwd(\"YOUR/DIRECTORY\")  # uncomment this line if setting a new directory"},{"path":[]},{"path":"https://marlonecobos.github.io/kuenm2/articles/basic_bata_cleaning.html","id":"import-data","dir":"Articles","previous_headings":"Cleaning data","what":"Import data","title":"Occurrence Data Cleaning","text":"use occurrence records provided within kuenm2 package. example data sets package derived Trindade & Marques (2024). occ_data_noclean object contains 51 valid occurrences Myrcia hatschbachii (tree endemic Southern Brazil) group erroneous records demonstrate cleaning steps.  raster layer group layers include package also used example. bioclimatic variable WorldClim 2.1 10 arc-minute resolution. layer masked using polygon generated drawing minimum convex polygon around records 300 km buffer.   Visualize occurrences records geography:","code":"# Import occurrences data(occ_data_noclean, package = \"kuenm2\")  # Check data structure str(occ_data_noclean) #> 'data.frame':    64 obs. of  3 variables: #>  $ species: chr  \"Myrcia hatschbachii\" \"Myrcia hatschbachii\" \"Myrcia hatschbachii\" \"Myrcia hatschbachii\" ... #>  $ x      : num  -51.3 -50.6 -49.3 -49.8 -50.2 ... #>  $ y      : num  -29 -27.6 -27.8 -26.9 -28.2 ... # Import raster layers var <- rast(system.file(\"extdata\", \"Current_variables.tif\", package = \"kuenm2\"))  # Keep only one layer var <- var$bio_1  # Check variable plot(var) # Visualize occurrences on one variable ## Create an extent based on the layer and the records to see all errors vext <- ext(var)  # extent of layer pext <- apply(occ_data_noclean[, 2:3], 2, range, na.rm = TRUE)  # extent of records  allext <- ext(c(min(pext[1, 1], vext[1]), max(pext[2, 1], vext[2]),                  min(pext[1, 2], vext[3]), max(pext[2, 2], vext[4]))) + 1  # plotting records on the variable plot(var, ext = allext, main = \"Bio 1\") points(occ_data_noclean[, c(\"x\", \"y\")])"},{"path":"https://marlonecobos.github.io/kuenm2/articles/basic_bata_cleaning.html","id":"basic-cleaning-steps","dir":"Articles","previous_headings":"Cleaning data","what":"Basic cleaning steps","title":"Occurrence Data Cleaning","text":"basic data cleaning steps implemented kuenm2 help : remove missing data, eliminate duplicates, exclude typically (though always) erroneous coordinates 0 longitude 0 latitude, filter records low coordinate precision based number decimal places. example cleaning missing data. example uses data.frame containing columns “Species”, “x”, “y” (“x” “y” represent longitude latitude, respectively). data.frame includes additional columns considered identifying missing values, users can specify columns use via columns argument (default = NULL, includes columns). function, recommend consulting documentation detailed explanations (e.g., help(remove_missing)).  code uses previous results continues process cleaning data removing duplicates. argument columns can used explained . See full documentation help(remove_duplicates).  Continue process removing coordinates values 0 (zero) longitude latitude (always needed, location valid working marine species). See full documentation help(remove_corrdinates_00).  following lines code take previous result remove coordinates low precision. longitude latitude contain decimal places, may rounded, can problematic areas. step recommended users know coordinate rounding issue. filtering process can also applied longitude latitude independently. See full documentation help(filter_decimal_precision).  Users can perform steps single function follows:","code":"# remove missing data mis <- remove_missing(data = occ_data_noclean, columns = NULL, remove_na = TRUE,                       remove_empty = TRUE)  # quick check nrow(occ_data_noclean) #> [1] 64 nrow(mis) #> [1] 60 # remove exact duplicates mis_dup <- remove_duplicates(data = mis, columns = NULL, keep_all_columns = TRUE)  # quick check nrow(mis) #> [1] 60 nrow(mis_dup) #> [1] 57 # remove records with 0 for x and y coordinates mis_dup_00 <- remove_corrdinates_00(data = mis_dup, x = \"x\", y = \"y\")  # quick check nrow(mis_dup) #> [1] 57 nrow(mis_dup_00) #> [1] 56 # remove coordinates with low decimal precision. mis_dup_00_dec <- filter_decimal_precision(data = mis_dup_00, x = \"x\", y = \"y\",                                             decimal_precision = 2)  # quick check nrow(mis_dup_00) #> [1] 56 nrow(mis_dup_00_dec) #> [1] 51 # all basinc cleaning steps clean_init <- initial_cleaning(data = occ_data_noclean, species = \"species\",                                 x = \"x\", y = \"y\", remove_na = TRUE,                                 remove_empty = TRUE, remove_duplicates = TRUE,                                 by_decimal_precision = TRUE,                                decimal_precision = 2)  # quick check nrow(occ_data_noclean)  # original data #> [1] 64 nrow(clean_init)  # data after all basic cleaning steps #> [1] 51  # a final plot to check par(mfrow = c(2, 2))  ## initial data plot(var, ext = allext, main = \"Initial data\") points(occ_data_noclean[, c(\"x\", \"y\")])  ## data after basic cleaning steps plot(var, ext = allext, main = \"After basic cleaning\") points(clean_init[, c(\"x\", \"y\")])  plot(var, main = \"After basic cleaning (zoom)\") points(clean_init[, c(\"x\", \"y\")])"},{"path":"https://marlonecobos.github.io/kuenm2/articles/basic_bata_cleaning.html","id":"other-cleaning-steps","dir":"Articles","previous_headings":"Cleaning data","what":"Other cleaning steps","title":"Occurrence Data Cleaning","text":"Two additional cleaning steps implemented kuenm2, removing cell duplicates moving points valid cells. Removing cell duplicates involves excluding records exact coordinate duplicates located within pixel. process randomly selects one record cell retain. See full documentation help(remove_cell_duplicates).  following lines code help adjust records fall just outside valid raster cells prevent data loss. Given nature resolution raster layers, valid records sometimes perceived outside boundaries cells data. cases, alternative move records nearest valid cell. distance limit applied avoid relocating records far study area. See example use approach. See full documentation help(move_2closest_cell).  function advanced_cleaning facilitates two processes single step:","code":"# exclude duplicates based on raster cell (pixel) celldup <- remove_cell_duplicates(data = clean_init, x = \"x\", y = \"y\",                                   raster_layer = var)  # quick check nrow(clean_init)  # data after all basic cleaning steps #> [1] 51 nrow(celldup)  # plus removing cell duplicates #> [1] 42 # move records to valid pixels moved <- move_2closest_cell(data = celldup, x = \"x\", y = \"y\",                              raster_layer = var, move_limit_distance = 10) #> Moving occurrences to closest pixels...  # quick check nrow(celldup)  # basic cleaning and no cell duplicates #> [1] 42 nrow(moved[moved$condition != \"Not_moved\", ])  # plus moved to valid cells #> [1] 41 # move records to valid pixels clean_data <- advanced_cleaning(data = clean_init, x = \"x\", y = \"y\",                                  raster_layer = var, cell_duplicates = TRUE,                                 move_points_inside = TRUE,                                  move_limit_distance = 10) #> Moving occurrences to closest pixels...  # exclude points not moved clean_data <- clean_data[clean_data$condition != \"Not_moved\", 1:3]  # quick check nrow(occ_data_noclean)  # original data #> [1] 64 nrow(clean_init)  # data after all basic cleaning steps #> [1] 51 nrow(clean_data)  # data after all basic cleaning steps #> [1] 41  # a final plot to check par(mfrow = c(3, 2))  ## initial data plot(var, ext = allext, main = \"Initial\") points(occ_data_noclean[, c(\"x\", \"y\")])  ## data after basic cleaning steps plot(var, ext = allext, main = \"Basic cleaning\") points(clean_init[, c(\"x\", \"y\")])  plot(var, main = \"Basic cleaning (zoom)\") points(clean_init[, c(\"x\", \"y\")])  ## data after basic cleaning steps plot(var, main = \"Final data\") points(clean_data[, c(\"x\", \"y\")])  ## zoom to a particular area, initial data plot(var, xlim = c(-48, -50), ylim = c(-26, -25),  main = \"Initial (zoom +)\") points(occ_data_noclean[, c(\"x\", \"y\")])  ## zoom to a particular area, final data plot(var, xlim = c(-48, -50), ylim = c(-26, -25),  main = \"Final (zoom +)\") points(clean_data[, c(\"x\", \"y\")])"},{"path":"https://marlonecobos.github.io/kuenm2/articles/basic_bata_cleaning.html","id":"saving-results","dir":"Articles","previous_headings":"","what":"Saving results","title":"Occurrence Data Cleaning","text":"results data cleaning steps kuenm2 simple data.frames may include additional columns fewer records original dataset. easy way save results writing CSV files. Although multiple options exist saving type data, another useful alternative save RDS file directory. See examples :","code":"# Save as CSV write.csv(clean_data, file = \"Clean_data.csv\", row.names = FALSE)  # Save as RDS saveRDS(clean_data, file = \"Clean_data.rds\")"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_calibration.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Model Calibration","text":"Model calibration computationally challenging process automated kuenm2. step, candidate models trained tested using k-fold cross-validation approach. , models selected based multiple criteria warranty models used later steps robust among candidates. main function used step calibration(). start calibration process, need prepared_data object. details data preparation, please refer vignette prepare data model calibration. start, let’s create two prepared_data object: one using maxnet algorithm, another GLM:","code":"#Load packages library(kuenm2) library(terra) #> terra 1.8.54  # Import occurrences data(occ_data, package = \"kuenm2\")  # Import raster layers var <- rast(system.file(\"extdata\", \"Current_variables.tif\", package = \"kuenm2\"))  # Prepare data for maxnet model d_maxnet <- prepare_data(algorithm = \"maxnet\",                          occ = occ_data,                          x = \"x\", y = \"y\",                          raster_variables = var,                          species = \"Myrcia hatschbachii\",                          categorical_variables = \"SoilType\",                          n_background = 300,                          features = c(\"l\", \"q\", \"lq\", \"lqp\"),                          r_multiplier = c(0.1, 1, 2))  # Prepare data for glm model d_glm <- prepare_data(algorithm = \"glm\",                          occ = occ_data,                          x = \"x\", y = \"y\",                          raster_variables = var,                          species = \"Myrcia hatschbachii\",                          categorical_variables = \"SoilType\",                          n_background = 300,                          features = c(\"l\", \"q\", \"lq\", \"lqp\"))"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_calibration.html","id":"calibration","dir":"Articles","previous_headings":"","what":"Calibration","title":"Model Calibration","text":"calibration() function fits evaluates candidate models considering follow metrics: Omission error: calculated using models trained separate testing data subsets. Users can specify multiple omission rates considered (e.g., c(5%, 10%)), though one can used threshold selecting best models. Partial ROC: calculated following Peterson et al. (2008). Model complexity (AIC): assessed using models generated complete set occurrences. Unimodality (optional): Assessed beta coefficients quadratic terms, following Arias-Giraldo & Cobos (2024).  summary, calibrate evaluate models, function requires prepared_data object following definitions: Omission Errors: Values ranging 0 100, representing percentage potential error attributed various sources uncertainty data. values utilized calculation omission rates partial ROC. Omission Rate Model Selection: specific omission error threshold used select models. value defines maximum omission rate candidate model can considered selection. Removal Concave Curves: specification whether exclude candidate models exhibit concave curves. Optional arguments allow modifications changing delta AIC threshold model selection (default 2), determining whether add presence samples background (default TRUE), whether employ user-specified weights. comprehensive description arguments, refer ?calibration. example, evaluate models considering two omission errors (5% 10%), model selection based 5% omission error. improve computational speed, can set parallel TRUE specify number cores utilize; candidate models distributed among cores. detect number available cores machine, run parallel::detectCores().","code":""},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_calibration.html","id":"maxnet-models","dir":"Articles","previous_headings":"Calibration","what":"Maxnet Models","title":"Model Calibration","text":"Let’s calibrate maxnet models: calibration() function returns calibration_results object, list containing various essential pieces information model calibration process. elements calibration_results object can explored indexing . example, evaluation metrics stored within calibration_results element:  can also examine details selected models:  printed, calibration_results object provides summary model selection process. includes total number candidate models considered, number models failed fit, number models exhibiting concave curves (along indication whether removed). Additionally, reports number models excluded due non-significant partial ROC (pROC) values, high omission error rates, elevated AIC values. Finally, summary metrics selected models presented.  example, 300 candidate maxnet models fitted, two selected based significant pROC value, low omission error (<10%), low AIC score (<2).","code":"#Calibrate maxnet models m_maxnet <- calibration(data = d_maxnet,                   error_considered = c(5, 10),                  omission_rate = 5,                  parallel = FALSE, #Set TRUE to run in parallel                  ncores = 1) #Define number of cores to run in parallel # Task 1/1: fitting and evaluating models: #   |=====================================================================| 100% #  # Model selection step: # Selecting best among 300 models. # Calculating pROC... #  # Filtering 300 models. # Removing 0 model(s) because they failed to fit. # 153 models were selected with omission rate below 5%. # Selecting 2 final model(s) with delta AIC <2. # Validating pROC of selected models... #   |=====================================================================| 100% # All selected models have significant pROC values. # See first rows of the summary of calibration results head(m_maxnet$calibration_results$Summary[,c(\"ID\", \"Omission_rate_at_10.mean\", \"AICc\",                                       \"Is_concave\")]) #>   ID Omission_rate_at_10.mean     AICc Is_concave #> 1  1                   0.0785 564.6870      FALSE #> 2  2                   0.0785 564.7657      FALSE #> 3  3                   0.0785 564.7059      FALSE #> 4  4                   0.1571 574.4960      FALSE #> 5  5                   0.1378 574.4347      FALSE #> 6  6                   0.1170 574.4141      FALSE # See first rows of the summary of calibration results m_maxnet$selected_models[,c(\"ID\", \"Formulas\", \"R_multiplier\",                       \"Omission_rate_at_10.mean\", \"AICc\", \"Is_concave\")] #>      ID                                                           Formulas #> 159 159                        ~bio_1 + bio_7 + I(bio_1^2) + I(bio_7^2) -1 #> 189 189 ~bio_1 + bio_7 + bio_12 + I(bio_1^2) + I(bio_7^2) + I(bio_12^2) -1 #>     R_multiplier Omission_rate_at_10.mean     AICc Is_concave #> 159          0.1                   0.0577 528.3151      FALSE #> 189          0.1                   0.0577 527.8733      FALSE print(m_maxnet) #> calibration_results object summary (maxnet) #> ============================================================= #> Species: Myrcia hatschbachii  #> Number of candidate models: 300  #>   - Models removed because they failed to fit: 0  #>   - Models identified with concave curves: 35  #>   - Model with concave curves not removed  #>   - Models removed with non-significant values of pROC: 0  #>   - Models removed with omission error > 5%: 147  #>   - Models removed with delta AIC > 2: 151  #> Selected models: 2  #>   - Up to 5 printed here: #>      ID                                                           Formulas #> 159 159                        ~bio_1 + bio_7 + I(bio_1^2) + I(bio_7^2) -1 #> 189 189 ~bio_1 + bio_7 + bio_12 + I(bio_1^2) + I(bio_7^2) + I(bio_12^2) -1 #>     Features R_multiplier pval_pROC_at_5.mean Omission_rate_at_5.mean      dAIC #> 159       lq          0.1                   0                  0.0192 0.4418045 #> 189       lq          0.1                   0                  0.0192 0.0000000 #>     Parameters #> 159          3 #> 189          5"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_calibration.html","id":"glm-models","dir":"Articles","previous_headings":"Calibration","what":"GLM Models","title":"Model Calibration","text":"Now, let’s calibrate GLM Models see algorith achieve different selected models: Now, instead two selected models, one:","code":"#Calibrate maxnet models m_glm <- calibration(data = d_glm,                       error_considered = c(5, 10),                      omission_rate = 5,                      parallel = FALSE, #Set TRUE to run in parallel                      ncores = 1) #Define number of cores to run in parallel # Task 1/1: fitting and evaluating models: #   |=====================================================================| 100% # Model selection step: # Selecting best among 100 models. # Calculating pROC... #  # Filtering 100 models. # Removing 0 model(s) because they failed to fit. # 50 models were selected with omission rate below 5%. # Selecting 1 final model(s) with delta AIC <2. # Validating pROC of selected models... #   |=====================================================================| 100% # All selected models have significant pROC values. m_glm #> calibration_results object summary (glm) #> ============================================================= #> Species: Myrcia hatschbachii  #> Number of candidate models: 100  #>   - Models removed because they failed to fit: 0  #>   - Models identified with concave curves: 18  #>   - Model with concave curves not removed  #>   - Models removed with non-significant values of pROC: 0  #>   - Models removed with omission error > 5%: 50  #>   - Models removed with delta AIC > 2: 49  #> Selected models: 1  #>   - Up to 5 printed here: #>    ID #> 86 86 #>                                                                                                       Formulas #> 86 ~bio_1 + bio_7 + bio_15 + I(bio_1^2) + I(bio_7^2) + I(bio_15^2) + bio_1:bio_7 + bio_1:bio_15 + bio_7:bio_15 #>    Features pval_pROC_at_5.mean Omission_rate_at_5.mean dAIC Parameters #> 86      lqp                   0                  0.0192    0          9"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_calibration.html","id":"concave-curves","dir":"Articles","previous_headings":"Calibration","what":"Concave curves","title":"Model Calibration","text":"worth noting maxnet glm algorithm, models identified concave curves. Concave (bimodal) curves indicate peak suitability found extremes variable range. example, shown right panel figure , higher suitability observed driest wettest regions, lower suitabilities occurring intermediate precipitation levels.   example, none selected models concave curves:  However, occasionally, model concave curves might selected sufficiently low omission rate AIC values. ensure none selected models concave curves, can set remove_concave = TRUE within calibration() function. Let’s test maxnet algorithm: Note process now divided two tasks: Task 1/2: candidate models include quadratic terms fitted. Maxent models (using maxnet algorithm), function first fits candidate model highest regularization multiplier (e.g., 5) formula. approach used particular formula produces concave response high regularization value, also produce concave responses lower regularization values. checking model highest regularization first, function can skip fitting models formula lower regularization values, saving time computation. Task 2/2: step, function fits evaluates two groups models: Models without quadratic terms. Models quadratic terms, formulas produce concave responses Task 1/2 (.e., passed concavity check higher regularization multiplier).","code":"#Selected maxnet models m_maxnet$selected_models[,c(\"ID\", \"Formulas\", \"Is_concave\")] #>      ID                                                           Formulas #> 159 159                        ~bio_1 + bio_7 + I(bio_1^2) + I(bio_7^2) -1 #> 189 189 ~bio_1 + bio_7 + bio_12 + I(bio_1^2) + I(bio_7^2) + I(bio_12^2) -1 #>     Is_concave #> 159      FALSE #> 189      FALSE  #Selected glm models m_glm$selected_models[,c(\"ID\", \"Formulas\", \"Is_concave\")] #>    ID #> 86 86 #>                                                                                                       Formulas #> 86 ~bio_1 + bio_7 + bio_15 + I(bio_1^2) + I(bio_7^2) + I(bio_15^2) + bio_1:bio_7 + bio_1:bio_15 + bio_7:bio_15 #>    Is_concave #> 86      FALSE m_unimodal <- calibration(data = d_maxnet,                            remove_concave = TRUE, # Ensures concave models are not selected                           error_considered = c(5, 10),                           omission_rate = 5) # Task 1/2: checking for concave responses in models: #   |=====================================================================| 100% #  # Task 2/2: fitting and evaluating models with no concave responses: #   |=====================================================================| 100% #  # Model selection step: # Selecting best among 370 models. # Calculating pROC... #  # Filtering 370 models. # Removing 0 model(s) because they failed to fit. # Removing 105 model(s) with concave curves. # 129 models were selected with omission rate below 5%. # Selecting 2 final model(s) with delta AIC <2. # Validating pROC of selected models... #   |=====================================================================| 100% # All selected models have significant pROC values."},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_calibration.html","id":"re-selecting-models","dir":"Articles","previous_headings":"","what":"Re-selecting models","title":"Model Calibration","text":"model selection procedure conducted internally calibration process. However, possible re-select models considering omission rates (since calculated calibration), model complexity (delta AIC) concave curves. default, calibration() calculates pROC values selected models optimize computational time. Consequently, pROC values non-selected models filled NA.  pROC calculated models calibration(), select_models() function requires prepared_data used calibration step, compute_proc must set TRUE. instance, let’s re-select maxnet models calibration results, applying omission rate 10% instead 5%:  calibration_results object provided, select_models() return calibration_results output selected models summary updated. Note now 1 model selected maxnet algoritm:  can also provide data.frame containing evaluation metrics candidate model directly select_models(). data.frame available output calibration() function object$calibration_results$Summary. case, function return list containing selected models along summaries model selection process.","code":"# See first rows of the summary of calibration results (pROC values) head(m_maxnet$calibration_results$Summary[,c(\"ID\", \"Mean_AUC_ratio_at_10.mean\",                                  \"pval_pROC_at_10.mean\")]) #>   ID Mean_AUC_ratio_at_10.mean pval_pROC_at_10.mean #> 1  1                        NA                   NA #> 2  2                        NA                   NA #> 3  3                        NA                   NA #> 4  4                        NA                   NA #> 5  5                        NA                   NA #> 6  6                        NA                   NA # See pROC values of selected models m_maxnet$selected_models[,c(\"ID\", \"Mean_AUC_ratio_at_10.mean\",                                  \"pval_pROC_at_10.mean\")] #>      ID Mean_AUC_ratio_at_10.mean pval_pROC_at_10.mean #> 159 159                        NA                   NA #> 189 189                        NA                   NA #Re-select maxnet models new_m_maxnet <- select_models(calibration_results = m_maxnet,                         data = d_maxnet, #Necessary for computing pROC                        compute_proc = TRUE,                         omission_rate = 10) # New omission rate #> Selecting best among 300 models. #> Calculating pROC... #>  #> Filtering 300 models. #> Removing 0 model(s) because they failed to fit. #> 156 models were selected with omission rate below 10%. #> Selecting 1 final model(s) with delta AIC <2. #> Validating pROC of selected models... #>  #> All selected models have significant pROC values. print(new_m_maxnet) #> calibration_results object summary (maxnet) #> ============================================================= #> Species: Myrcia hatschbachii  #> Number of candidate models: 300  #>   - Models removed because they failed to fit: 0  #>   - Models identified with concave curves: 35  #>   - Model with concave curves not removed  #>   - Models removed with non-significant values of pROC: 0  #>   - Models removed with omission error > 10%: 144  #>   - Models removed with delta AIC > 2: 155  #> Selected models: 1  #>   - Up to 5 printed here: #>      ID                                                           Formulas #> 192 192 ~bio_1 + bio_7 + bio_15 + I(bio_1^2) + I(bio_7^2) + I(bio_15^2) -1 #>     Features R_multiplier pval_pROC_at_10.mean Omission_rate_at_10.mean dAIC #> 192       lq          0.1                    0                   0.0769    0 #>     Parameters #> 192          5 new_m_maxnet$selected_models[,c(\"ID\", \"Formulas\", \"R_multiplier\",                       \"Omission_rate_at_5.mean\", \"Mean_AUC_ratio_at_10.mean\",                      \"AICc\", \"Is_concave\")] #>      ID                                                           Formulas #> 192 192 ~bio_1 + bio_7 + bio_15 + I(bio_1^2) + I(bio_7^2) + I(bio_15^2) -1 #>     R_multiplier Omission_rate_at_5.mean Mean_AUC_ratio_at_10.mean     AICc #> 192          0.1                  0.0769                  1.434188 522.9691 #>     Is_concave #> 192      FALSE #Re-select models using data.frame new_summary <- select_models(candidate_models = m_maxnet$calibration_results$Summary,                              data = d_maxnet, #Necessary for computing pROC                              compute_proc = TRUE,                               omission_rate = 10) #> Selecting best among 300 models. #> Calculating pROC... #>  #> Filtering 300 models. #> Removing 0 model(s) because they failed to fit. #> 156 models were selected with omission rate below 10%. #> Selecting 1 final model(s) with delta AIC <2. #> Validating pROC of selected models... #>  #> All selected models have significant pROC values.  #Get class of object class(new_summary) #> [1] \"list\"  #See selected models new_summary$selected_models[,c(\"ID\", \"Formulas\", \"R_multiplier\",                       \"Omission_rate_at_5.mean\", \"Mean_AUC_ratio_at_10.mean\",                      \"AICc\", \"Is_concave\")] #>      ID                                                           Formulas #> 192 192 ~bio_1 + bio_7 + bio_15 + I(bio_1^2) + I(bio_7^2) + I(bio_15^2) -1 #>     R_multiplier Omission_rate_at_5.mean Mean_AUC_ratio_at_10.mean     AICc #> 192          0.1                  0.0769                  1.434421 522.9691 #>     Is_concave #> 192      FALSE"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_calibration.html","id":"saving-a-calibration_results-object","dir":"Articles","previous_headings":"","what":"Saving a calibration_results object","title":"Model Calibration","text":"calibrating selecting best-performing models, can proceed fit final models (see vignette model exploration) using calibration_results object. object essentially list, users can save local directory using saveRDS(). Saving object facilitates loading back R session later using readRDS(). See example :","code":"# Set directory to save (here, in a temporary directory) dir_to_save <- file.path(tempdir())  # Save the data saveRDS(m_maxnet, file.path(dir_to_save, \"Candidates_maxnet.rds\"))  # Import data m_maxnet <- readRDS(file.path(dir_to_save, \"Candidates_maxnet.rds\"))"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_exploration.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Fit and Explore Selected Models","text":"best performing models selected, users need fit models (using fit_selected()) order explore characteristics continue next steps. Fitted models can used assess variable importance models, well explore variable response curves. fit selected models, need calibration_results object. details model calibration, please refer vignette Model Calibration. calibration_results object generated vignette available data example package. Let’s load . object contains results candidate models calibrated using maxnet algorithm. package also provides similar example using glm algorithm, works exactly way. Note calibration_results object stores information related calibration process model evaluation—include fitted maxnet (glm) models . obtain final fitted models, need use fit_selected() function. default, function fits full model (.e., without replicates without splitting data training testing sets). However, can configure fit final models replicates desired. example, ’ll fit final models using replication settings (4-fold cross-validation) used Model Calibration vignette.  fit_selected() function returns fitted_models object, list contains essential information fitted models, required subsequent steps. can explore contents fitted_models object indexing elements. example, fitted maxnet (glm) model objects stored within Models element. Note Models nested list: selected model (case, models 159 189), includes replicates (fitted replicates) full model. fitted_models object also stores thresholds can used binarize models suitable unsuitable areas. thresholds correspond omission error used model selection (e.g., 5% 10%). can access omission error used calculate thresholds directly object: omission error used calculate thresholds 5%, meaning predictions binarized, approximately 5% presence records used calibrate models fall cells predicted values threshold. thresholds summarized two ways: mean median across replicates model, consensus mean median across selected models (one model selected): Now, can use fitted_models object generate response curves compute variable importance.","code":"#Load packages library(kuenm2) library(terra) #> terra 1.8.54  #Import calib_results_maxnet data(\"calib_results_maxnet\", package = \"kuenm2\") #Print calibration result calib_results_maxnet #> calibration_results object summary (maxnet) #> ============================================================= #> Species: Myrcia hatschbachii  #> Number of candidate models: 300  #>   - Models removed because they failed to fit: 0  #>   - Models identified with concave curves: 35  #>   - Model with concave curves not removed  #>   - Models removed with non-significant values of pROC: 0  #>   - Models removed with omission error > 5%: 147  #>   - Models removed with delta AIC > 2: 151  #> Selected models: 2  #>   - Up to 5 printed here: #>      ID                                                           Formulas #> 159 159                        ~bio_1 + bio_7 + I(bio_1^2) + I(bio_7^2) -1 #> 189 189 ~bio_1 + bio_7 + bio_12 + I(bio_1^2) + I(bio_7^2) + I(bio_12^2) -1 #>     Features R_multiplier pval_pROC_at_5.mean Omission_rate_at_5.mean      dAIC #> 159       lq          0.1                   0                  0.0192 0.4418045 #> 189       lq          0.1                   0                  0.0192 0.0000000 #>     Parameters #> 159          3 #> 189          5 #Import calib_results_glm data(\"calib_results_glm\", package = \"kuenm2\") #Print calibration result calib_results_glm #> calibration_results object summary (glm) #> ============================================================= #> Species: Myrcia hatschbachii  #> Number of candidate models: 100  #>   - Models removed because they failed to fit: 0  #>   - Models identified with concave curves: 18  #>   - Model with concave curves not removed  #>   - Models removed with non-significant values of pROC: 0  #>   - Models removed with omission error > 5%: 50  #>   - Models removed with delta AIC > 2: 49  #> Selected models: 1  #>   - Up to 5 printed here: #>    ID #> 86 86 #>                                                                                                       Formulas #> 86 ~bio_1 + bio_7 + bio_15 + I(bio_1^2) + I(bio_7^2) + I(bio_15^2) + bio_1:bio_7 + bio_1:bio_15 + bio_7:bio_15 #>    Features pval_pROC_at_5.mean Omission_rate_at_5.mean dAIC Parameters #> 86      lqp                   0                  0.0192    0          9 # Fit selected models using calibration results fm <- fit_selected(calibration_results = calib_results_maxnet, #or calib_results_glm                    n_replicates = 4) # Fitting replicates... #   |========================================================================| 100% # Fitting full models... #   |========================================================================| 100% #See names of selected models names(fm$Models) #> [1] \"Model_159\" \"Model_189\"  #See models inside Model 189 names(fm$Models$Model_189) #> [1] \"Rep_1\"      \"Rep_2\"      \"Rep_3\"      \"Rep_4\"      \"Full_model\" #Get omission error used to select models and calculate the thesholds fm$omission_rate #> [1] 5 fm$thresholds #> $Model_159 #> $Model_159$mean #> [1] 0.2976193 #>  #> $Model_159$median #> [1] 0.314841 #>  #>  #> $Model_189 #> $Model_189$mean #> [1] 0.3298963 #>  #> $Model_189$median #> [1] 0.3491305 #>  #>  #> $consensus #> $consensus$mean #> [1] 0.315051 #>  #> $consensus$median #> [1] 0.336047"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_exploration.html","id":"response-curve","dir":"Articles","previous_headings":"","what":"Response curve","title":"Fit and Explore Selected Models","text":"response curves illustrate environmental variable influences predicted suitability, keeping variables constant. default, curves generated variables set mean values (mode categorical variables), calculated combined set presence background localities (averages_from = \"pr_bg\"). can change behavior use presence localities setting averages_from = \"pr\". Let’s check variables available plot examining coefficients full models: variables bio_1, bio_7, bio_12 non-zero coefficient values, means contribute model available generating response curves. default, response curves computed using selected models. resulting plots include line mean response, along shaded area representing 95% confidence interval.  can also specify selected models used generate response curves:  dashed lines indicate range variable within calibration data. default, plot extends beyond limits based variable’s minimum maximum values extrapolation_factor (extrapolation = TRUE). default extrapolation set 10% variable’s range (.e., range × 0.1). extrapolation = FALSE, extrapolation occurs, plot limits match calibration data range exactly. can increase extrapolation factor allow broader range beyond observed data. response curve plotted extrapolation factor 2:  Note response curve now extends beyond observed data range (indicated dashed lines). Optionally, can manually set lower upper limits variables. example, since bio_12 represents annual precipitation negative values meaningful, can set lower limit 0:  Now, lower limit plot bio_12 set 0. Since specify upper limit, plot uses extrapolation factor (, 0.1) define upper limit. Optionally, can add original presence background points plot setting add_point = TRUE:","code":"#Get variables with non-zero coefficients in the models fm$Models[[1]]$Full_model$betas #From the first model selected #>       bio_1  I(bio_1^2)  I(bio_7^2)  #> 15.52377637 -0.46828240 -0.01261841 fm$Models[[2]]$Full_model$betas #From the second model selected #>         bio_1        bio_12    I(bio_1^2)    I(bio_7^2)   I(bio_12^2)  #>  1.462835e+01  3.592615e-02 -4.407921e-01 -1.208573e-02 -1.152889e-05 par(mfrow = c(1, 3)) #Set grid of plot response_curve(models = fm, variable = \"bio_1\") response_curve(models = fm, variable = \"bio_7\") response_curve(models = fm, variable = \"bio_12\") on.exit() #Reinitiate grid par(mfrow = c(2, 2)) #Set grid of plot response_curve(models = fm, variable = \"bio_1\",                modelID = \"Model_159\", main = \"Model_159\") response_curve(models = fm, variable = \"bio_1\",                 modelID = \"Model_189\", main = \"Model_189\") response_curve(models = fm, variable = \"bio_7\",                 modelID = \"Model_159\", main = \"Model_159\") response_curve(models = fm, variable = \"bio_7\",                 modelID = \"Model_189\", main = \"Model_189\") on.exit() #Reinitiate grid par(mfrow = c(1, 3)) #Set grid of plot response_curve(models = fm, variable = \"bio_1\", extrapolation_factor = 2) response_curve(models = fm, variable = \"bio_7\", extrapolation_factor = 2) response_curve(models = fm, variable = \"bio_12\", extrapolation_factor = 2) on.exit() #Reinitiate grid response_curve(models = fm, variable = \"bio_12\",                 extrapolation_factor = 0.1,                 l_limit = 0) response_curve(models = fm, variable = \"bio_1\",                 add_points = TRUE)"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_exploration.html","id":"variable-importance","dir":"Articles","previous_headings":"","what":"Variable importance","title":"Fit and Explore Selected Models","text":"relative importance predictor variables can calculated using explained deviance var_importance() function. process starts fitting full model (maxnet glm), includes predictor variables. , function fits separate models excluding one variable time, assessing removal affects model performance. systematically evaluating impact predictor’s exclusion, function provides insights individual contribution variable model’s overall performance explanatory power. default, function runs single core. can enable parallel processing setting parallel = TRUE specifying number cores ncores. Note parallelization speeds computation many variables (7) large calibration dataset (15,000 presence background points). default, variable importance computed selected models: function returns data.frame relative contribution variable. multiple models included fitted object, additional column identifies distinct model. can visualize variable importance using plot_importance() function. fitted_models object contains one selected model, plot displays boxplot contributions, along mean contribution number (N) fitted models.  variable importance computed single model, plot displays barplot instead boxplot:","code":"# Calculate variable importance imp <- variable_importance(models = fm)  # Calculating variable contribution for model 1 of 2 #   |======================================================================| 100% # Calculating variable contribution for model 2 of 2 #   |======================================================================| 100% imp #>     predictor contribution    Models #> 1  I(bio_1^2)  0.515387743 Model_159 #> 2       bio_1  0.482802883 Model_159 #> 3  I(bio_7^2)  0.001809375 Model_159 #> 4  I(bio_1^2)  0.444939057 Model_189 #> 5       bio_1  0.425438027 Model_189 #> 6 I(bio_12^2)  0.065575776 Model_189 #> 7      bio_12  0.062618167 Model_189 #> 8  I(bio_7^2)  0.001428973 Model_189 plot_importance(imp) # Calculate variable importance for a specific selected Model imp_189 <- variable_importance(models = fm, modelID = \"Model_189\",                                 progress_bar = FALSE) #Plot variable contribution for model 189 plot_importance(imp_189, main = \"Variable importance - Model 189\")"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_exploration.html","id":"saving-a-fitted_models-object","dir":"Articles","previous_headings":"","what":"Saving a fitted_models object","title":"Fit and Explore Selected Models","text":"fitting best-performing models fit_selected(), can proceed predict models single multiple scenarios. object essentially list, users can save local directory using saveRDS(). Saving object facilitates loading back R session later using readRDS(). See example :","code":"# Set directory to save (here, in a temporary directory) dir_to_save <- file.path(tempdir())  # Save the data saveRDS(fm, file.path(dir_to_save, \"fitted_models.rds\"))  # Import data fm <- readRDS(file.path(dir_to_save, \"fitted_models.rds\"))"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_predictions.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Predict models to single scenario","text":"selected models fit using fit_selected(), projections single multiple scenarios can performed. predict_selected() function designed projections single scenarios. predict using selected models, fitted_models object required. detailed information model fitting, please consult vignette Fit Explore Selected Models. fitted_models object generated vignette included example dataset within package. Let’s load . compare results, let’s import fitted_models object generated using GLM algorithm:","code":"#Load packages library(kuenm2) library(terra) #> terra 1.8.54  #Import calib_results_maxnet data(\"fitted_model_maxnet\", package = \"kuenm2\") #Print calibration result fitted_model_maxnet #> fitted_models object summary #> ============================ #> Species: Myrcia hatschbachii  #> Algortihm: maxnet  #> Number of fitted models: 2  #> Models fitted with 4 replicates #Import calib_results_maxnet data(\"fitted_model_glm\", package = \"kuenm2\") #Print calibration result fitted_model_glm #> fitted_models object summary #> ============================ #> Species: Myrcia hatschbachii  #> Algortihm: glm  #> Number of fitted models: 1  #> Models fitted with 4 replicates"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_predictions.html","id":"predict-selected-models-for-a-single-scenario","dir":"Articles","previous_headings":"","what":"Predict Selected Models for a Single Scenario","title":"Predict models to single scenario","text":"predict selected models single scenario, need fitted_models object corresponding predictor variables. predictor variables can provided either SpatRaster data.frame. names variables (columns data.frame) must precisely match used model calibration used running PCA (do_pca = TRUE set prepare_data() function; see Prepare Data Model Calibration details).","code":""},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_predictions.html","id":"predict-to-spatraster","dir":"Articles","previous_headings":"Predict Selected Models for a Single Scenario","what":"Predict to SpatRaster","title":"Predict models to single scenario","text":"Let’s use raster variables used prepare data calibrate models. included example data within package:  Let’s check variables used calibrate models. available calibration_data element object: first column, “pr_bg”, indicates presence (1) absence (0) records, columns represent environmental variables. case, variables bio_1, bio_7, bio_12, bio_15, SoilType. variables present SpatRaster (var) imported. Therefore, can now predict models raster. Let’s begin predicting maxnet model: default, function computes consensus metrics (mean, median, range, standard deviation) model across replicates (one model selected), well general consensus across models. case, output list containing SpatRaster predictions replicate, along consensus results model overall general consensus: Let’s plot general consensus:  can also plot results replicate consensus model:    comparison, let’s predict GLM model:","code":"# Import raster layers var <- rast(system.file(\"extdata\", \"Current_variables.tif\", package = \"kuenm2\")) #Plot raster layers plot(var) # Variables used to calibrate maxnet models colnames(fitted_model_maxnet$calibration_data) #> [1] \"pr_bg\"    \"bio_1\"    \"bio_7\"    \"bio_12\"   \"bio_15\"   \"SoilType\"  #Variables used to calibrate glm models colnames(fitted_model_glm$calibration_data) #> [1] \"pr_bg\"    \"bio_1\"    \"bio_7\"    \"bio_12\"   \"bio_15\"   \"SoilType\" p_maxnet <- predict_selected(models = fitted_model_maxnet,                               raster_variables = var,                              progress_bar = FALSE) #See objects in the output of predict_selected names(p_maxnet) #> [1] \"Model_159\"         \"Model_189\"         \"General_consensus\" plot(p_maxnet$General_consensus) #Predictions for each replicate from model 159 plot(p_maxnet$Model_159$Replicates) #Consensus across each replicate from model 159 plot(p_maxnet$Model_159$Model_consensus) # Predict glm model p_glm <- predict_selected(models = fitted_model_glm,                            raster_variables = var,                           progress_bar = FALSE) #See selected models that were predicted names(p_glm) #> [1] \"Model_86\"          \"General_consensus\"  #Compare general consensus (mean) between maxnet and glm par(mfrow= c(1, 2)) #Set grid to plot plot(p_maxnet$General_consensus$mean, main = \"Maxnet\") plot(p_glm$General_consensus$mean, main = \"GLM\") on.exit() #Reinitiate grid"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_predictions.html","id":"predict-to-data-frame","dir":"Articles","previous_headings":"Predict Selected Models for a Single Scenario","what":"Predict to data.frame","title":"Predict models to single scenario","text":"Instead SpatRaster, can also predict models data.frame stores variable values. see example, let’s convert raster variables var data.frame: Note column stores values variable. Let’s predict Maxnet models data.frame: Now, instead SpatRaster objects, function returns data.frame objects predictions:","code":"var_df <- as.data.frame(var) head(var_df) #>       bio_1    bio_7 bio_12   bio_15 SoilType #> 11 22.77717 18.12400   1180 48.03594       NA #> 12 22.76711 17.74400   1191 49.31194       10 #> 13 22.68580 17.46575   1206 51.51922       10 #> 14 22.50121 17.84525   1228 53.90265       10 #> 15 22.07609 18.14125   1254 54.10397       10 #> 16 21.88485 18.80800   1276 54.07279       10 p_df <- predict_selected(models = fitted_model_maxnet,                           raster_variables = var_df, #Now, a data.frame                          progress_bar = FALSE) #Results by replicate of the model 159 head(p_df$Model_159$Replicates) #>          Rep_1        Rep_2        Rep_3        Rep_4 #> 1 4.953374e-09 2.990750e-07 4.429839e-07 1.836235e-07 #> 2 6.387873e-09 3.707596e-07 5.490833e-07 2.281607e-07 #> 3 1.230260e-08 6.275917e-07 9.136320e-07 3.912725e-07 #> 4 3.233261e-08 1.323430e-06 1.844737e-06 8.476498e-07 #> 5 3.462922e-07 8.467052e-06 1.078599e-05 5.758022e-06 #> 6 7.178695e-07 1.464941e-05 1.791809e-05 1.020809e-05  #Consensus across replicates of the model 159 head(p_df$Model_159$Model_consensus) #>         median        range         mean        stdev #> 1 2.413492e-07 4.380305e-07 2.326589e-07 1.852044e-07 #> 2 2.994601e-07 5.426955e-07 2.885979e-07 2.294184e-07 #> 3 5.094321e-07 9.013294e-07 4.861997e-07 3.813484e-07 #> 4 1.085540e-06 1.812404e-06 1.012037e-06 7.696750e-07 #> 5 7.112537e-06 1.043969e-05 6.339338e-06 4.492749e-06 #> 6 1.242875e-05 1.720022e-05 1.087337e-05 7.471354e-06  #General consensus across all models head(p_df$General_consensus) #>         median         mean        stdev        range #> 1 1.892740e-07 2.154842e-07 1.874738e-07 4.976784e-07 #> 2 2.418142e-07 2.764726e-07 2.408419e-07 6.614167e-07 #> 3 4.261519e-07 4.815362e-07 4.140724e-07 1.171038e-06 #> 4 9.560208e-07 1.040946e-06 8.638481e-07 2.514376e-06 #> 5 6.485619e-06 6.530262e-06 4.897458e-06 1.426154e-05 #> 6 1.188007e-05 1.162486e-05 8.369096e-06 2.486310e-05"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_predictions.html","id":"binarize-models","dir":"Articles","previous_headings":"Predict Selected Models for a Single Scenario","what":"Binarize Models","title":"Predict models to single scenario","text":"fitted_models object stores thresholds can used binarize models suitable unsuitable areas. thresholds correspond omission error rate used model selection (e.g., 5% 10%). can access omission error rate used calculate thresholds directly object: models, omission error rate used calculate thresholds 5%. means predictions binarized, approximately 5% presence records used calibrate models fall cells classified unsuitable. thresholds summarized two ways: mean median across replicates model, consensus mean median across selected models (one model selected). Let’s check thresholds general consensus: Let’s use thresholds binarize models (functionality available predicting SpatRaster):","code":"#Get omission error used to select models and calculate the thesholds ## For maxnet model fitted_model_maxnet$omission_rate #> [1] 5  ## For glm model fitted_model_glm$omission_rate #> [1] 5 #For maxnet fitted_model_maxnet$thresholds$consensus #> $mean #> [1] 0.315051 #>  #> $median #> [1] 0.336047  #For glm fitted_model_glm$thresholds$consensus #> $mean #>          4  #> 0.09240012  #>  #> $median #>          4  #> 0.08753728 #Get the thersholds for models (general consensus) thr_mean_maxnet <- fitted_model_maxnet$thresholds$consensus$mean #Maxnet thr_mean_glm <- fitted_model_glm$thresholds$consensus$mean #glm  #Binarize models mean_maxnet_bin <- (p_maxnet$General_consensus$mean > thr_mean_maxnet) * 1 mean_glm_bin <- (p_glm$General_consensus$mean > thr_mean_glm) * 1  #Compare results par(mfrow= c(1, 2)) #Set grid to plot plot(mean_maxnet_bin, main = \"Maxnet\") plot(mean_glm_bin, main = \"GLM\") on.exit() #Reinitiate grid"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_predictions.html","id":"clamping-variables","dir":"Articles","previous_headings":"Predict Selected Models for a Single Scenario","what":"Clamping Variables","title":"Predict models to single scenario","text":"default, predictions performed free extrapolation (extrapolation_type = \"E\"). can problematic peak suitability occurs extremes predictor’s range. example, let’s examine response curve Maxnet model bio_7 (Temperature Annual Range):  Note higher suitability occurs low values temperature range. However, lower limit calibration data used fit models (dashed line) 15.7ºC. premise suitability increase stabilize lower values bio_7 extrapolation model (area left dashed line). ’s possible suitability begin decrease extremely low values, rendering extrapolation inaccurate, calibration data insufficient model predict . One way address clamping variables. means values outside calibration range (lower value upper value) set respective lower upper limits calibration range. example, calibration data Maxnet models, lower upper limits bio_7 15.7ºC 23.3ºC, respectively: observe effect clamping variable, let’s create hypothetical (extreme) scenario bio_7 extremely low values:  Let’s predict Maxnet models new scenario free extrapolation (extrapolation_type = \"E\") clamped variables (extrapolation_type = \"EC\"):  Note clamp variables, regions extremely low values (hypothetical) bio_7 exhibit lower predicted suitabilities compared free extrapolation allowed. default, extrapolation_type = \"EC\" set, predictor variables clamped. can specify variables clamp using var_to_clamp argument.","code":"response_curve(models = fitted_model_maxnet, variable = \"bio_7\",                 extrapolation_factor = 1) range(fitted_model_maxnet$calibration_data$bio_7) #> [1] 15.71120 23.30475 #From bio_7, reduce values new_bio7 <- var$bio_7 - 7 #Create new scenario new_var <- var #Replace bio_7 with new_bio7 in this scenario new_var$bio_7 <- new_bio7  #Plot the differences par(mfrow = c(1,2)) plot(var$bio_7, main = \"Original bio_7\") plot(new_var$bio_7, main = \"New bio_7\") on.exit() #Reinitiate grid #Predict to hypothetical scenario with free extrapolation p_free_extrapolation <- predict_selected(models = fitted_model_maxnet,                                           raster_variables = new_var, #New scenario                                          consensus = \"mean\",                                          extrapolation_type = \"E\", #Free extrapolation (Default)                                          progress_bar = FALSE)  #Predict to hypothetical scenario with clamping p_clamping <- predict_selected(models = fitted_model_maxnet,                                 raster_variables = new_var, #New scenario                                consensus = \"mean\",                                extrapolation_type = \"EC\", #Extrapolation with clamping                                progress_bar = FALSE)  #Get and see differences p_difference <- p_free_extrapolation$General_consensus$mean - p_clamping$General_consensus$mean  #Plot the differences par(mfrow = c(2,2)) plot(p_free_extrapolation$General_consensus$mean, main = \"Free extrapolation\",      zlim = c(0, 1)) plot(p_clamping$General_consensus$mean, main = \"Clamping\",      zlim = c(0, 1)) plot(p_difference, main = \"Difference\") plot(new_bio7, main = \"Hypothetical bio_7\", type = \"interval\") on.exit() #Reinitiate grid"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_predictions.html","id":"no-extrapolation","dir":"Articles","previous_headings":"Predict Selected Models for a Single Scenario","what":"No Extrapolation","title":"Predict models to single scenario","text":"rigorous approach predict extrapolation, regions outside limits calibration data assigned suitability value 0. Let’s predict Maxnet models using hypothetical scenario created previous step observe difference:  example, almost entire predicted area shows zero suitability, except small patch. occurred , hypothetical scenario, nearly entire region bio_7 values lower calibration data (minimum 15ºC). region suitability predicted greater 0 bio_7 values fall within limits calibration data. default, extrapolation_type = \"NE\" set, predictor variables considered process. can specify subset variables considered extrapolation using var_to_clamp argument.","code":"#Predict to hypothetical scenario with no extrapolation p_no_extrapolation <- predict_selected(models = fitted_model_maxnet,                                         raster_variables = new_var, #New scenario                                        consensus = \"mean\",                                        extrapolation_type = \"NE\", #No extrapolation                                        progress_bar = FALSE) #Plot the differences par(mfrow = c(2,2)) plot(p_free_extrapolation$General_consensus$mean, main = \"Free extrapolation\",      zlim = c(0, 1)) plot(p_clamping$General_consensus$mean, main = \"Clamping\",      zlim = c(0, 1)) plot(p_no_extrapolation$General_consensus$mean, main = \"No extrapolation\",      zlim = c(0, 1)) plot(new_bio7, main = \"Hypothetical bio_7\", type = \"interval\") on.exit() #Reinitiate grid"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_predictions.html","id":"output-type","dir":"Articles","previous_headings":"Predict Selected Models for a Single Scenario","what":"Output Type","title":"Predict models to single scenario","text":"Maximum entropy models (maxnet) produce four different types output predictions: raw, cumulative, logistic, cloglog. described Merow et al. 2013 Phillips et al. 2017. four output types monotonically related. Therefore, rank-based metrics model fit (e.g., omission rate partial ROC) identical. However, output types different scaling, leads distinct interpretations visually different prediction maps. Raw (exponential) output interpreted Relative Occurrence Rate (ROR). ROR sums 1 predicted calibration data. Cumulative output assigns location sum raw values less equal raw value location, rescales range 0 100. Cumulative output can interpreted terms omission rate thresholding value c predict suitable/unsuitable cell omit approximately c% presences. Cloglog output (Default) transforms raw values scale relative suitability ranging 0 1, using logistic transformation based user-specified parameter ‘τ\\tau’, represents probability presence ‘average’ presence locations. context, tau value defaults τ≈0.632\\tau \\approx 0.632. Logistic output similar Cloglog, assumes τ=0.5\\tau = 0.5. Let’s examine differences four output types Maxnet models:","code":"p_cloglog <- predict_selected(models = fitted_model_maxnet, raster_variables = var,                                type = \"cloglog\", progress_bar = FALSE) p_logistic <- predict_selected(models = fitted_model_maxnet, raster_variables = var,                                type = \"logistic\", progress_bar = FALSE) p_cumulative <- predict_selected(models = fitted_model_maxnet, raster_variables = var,                                type = \"cumulative\", progress_bar = FALSE) p_raw <- predict_selected(models = fitted_model_maxnet, raster_variables = var,                                type = \"raw\", progress_bar = FALSE)  #Plot the differences par(mfrow = c(2,2)) plot(p_cloglog$General_consensus$mean, main = \"Cloglog (Default)\",      zlim = c(0, 1)) plot(p_logistic$General_consensus$mean, main = \"Logistic\",      zlim = c(0, 1)) plot(p_cumulative$General_consensus$mean, main = \"Cumulative\",      zlim = c(0, 1)) plot(p_raw$General_consensus$mean, main = \"Raw\",      zlim = c(0, 1)) on.exit() #Reinitiate grid"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_predictions.html","id":"saving-predictions","dir":"Articles","previous_headings":"","what":"Saving Predictions","title":"Predict models to single scenario","text":"can save predictions disk setting write_files = TRUE. option enabled, must provide directory path out_dir argument. raster_variables SpatRaster, function save output files GeoTIFF (.tif) files. raster_variables data.frame, function save output files Comma Separated Value (.csv) files.","code":"p_save <- predict_selected(models = fitted_model_maxnet,                             raster_variables = var,                             write_files = TRUE, #To save to the disk                            write_replicates = TRUE, #To save predictions for each replicate                            out_dir = tempdir(), #A path to save the resuls (here, the temporary directory)                            progress_bar = FALSE)"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_projections.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Project models to multiple scenarios","text":"selected models fit using fit_selected(), projections single multiple scenarios can performed. project_selected() function designed projections multiple scenarios. project using selected models, fitted_models object required. detailed information model fitting, please consult vignette Fit Explore Selected Models. fitted_models object generated vignette included example dataset within package. Let’s load .","code":"#Load packages library(kuenm2) library(terra) #> terra 1.8.54  #Import calib_results_maxnet data(\"fitted_model_maxnet\", package = \"kuenm2\") #Print calibration result fitted_model_maxnet #> fitted_models object summary #> ============================ #> Species: Myrcia hatschbachii  #> Algortihm: maxnet  #> Number of fitted models: 2  #> Models fitted with 4 replicates"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_projections.html","id":"pre-processing-raster-predictors","dir":"Articles","previous_headings":"","what":"Pre-processing raster predictors","title":"Project models to multiple scenarios","text":"predicting models single scenario requires single SpatRaster object containing predictor variables (detailed Predict models single scenario), projecting models multiple scenarios necessitates folder stores predictor variables scenario. folders must organized specific hierarchical manner: root directory contain nested folders representing different scenarios, raster variables stored within. first level inside root folder, subfolders correspond distinct time periods (e.g., future years like “2070” “2100,” past periods “Mid-holocene” “LGM”). Within period folder, applicable, include subfolders emission scenario (e.g., “ssp126”, “ssp585”). Finally, within emission scenario time period folder, include separate folder General Circulation Model (GCM) (e.g., “BCC-CSM2-MR”, “MIROC6”). structured organization enables function automatically access process data according period, emission scenario, GCM.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_projections.html","id":"organize-and-structure-future-climate-variables-from-worldclim","dir":"Articles","previous_headings":"Pre-processing raster predictors","what":"Organize and structure future climate variables from WorldClim","title":"Project models to multiple scenarios","text":"package provides function import future climate variables downloaded WorldClim (version 2.1). function renames files organizes folders categorized period/year, emission scenario (Shared Socioeconomic Pathways; SSPs), General Circulation Model (GCM). simplifies preparation climate data, ensuring required variables properly structured modeling projections. use function, download future raster variables WorldClim 2.1 save within folder. rename files variables, function relies patterns provided original files work properly. package also provides example raw variables downloaded WorldClim 2.1. example includes bioclimatic predictions periods “2041-2060” “2081-2100”, two SSPs (125 585) two GCMs (ACCESS-CM2 MIROC6), 10 arc-minutes resolution. Note variables folder retain original names provided WorldClim. can download variables directly WorldClim using geodata R package: Let’s check variables inside “geodata_dir” folder: Now, can organize structure files using organize_future_worldclim function.","code":"# See raster files with future predictors provided as example # The data is located in the \"inst/extdata\" folder. in_dir <- system.file(\"extdata\", package = \"kuenm2\") list.files(in_dir) #>  [1] \"bias_file.tif\"                                  #>  [2] \"Current_variables.tif\"                          #>  [3] \"wc2.1_10m_bioc_ACCESS-CM2_ssp126_2041-2060.tif\" #>  [4] \"wc2.1_10m_bioc_ACCESS-CM2_ssp126_2081-2100.tif\" #>  [5] \"wc2.1_10m_bioc_ACCESS-CM2_ssp585_2041-2060.tif\" #>  [6] \"wc2.1_10m_bioc_ACCESS-CM2_ssp585_2081-2100.tif\" #>  [7] \"wc2.1_10m_bioc_MIROC6_ssp126_2041-2060.tif\"     #>  [8] \"wc2.1_10m_bioc_MIROC6_ssp126_2081-2100.tif\"     #>  [9] \"wc2.1_10m_bioc_MIROC6_ssp585_2041-2060.tif\"     #> [10] \"wc2.1_10m_bioc_MIROC6_ssp585_2081-2100.tif\" #Install geodata if necessary if(!require(\"geodata\")){   install.packages(\"geodata\") } #Load geodata library(geodata) #Create folder to save the raster files #Here, in a temporary directory geodata_dir <- file.path(tempdir(), \"Future_worldclim\") dir.create(geodata_dir) #Define GCMs, SSPs and time periods gcms <- c(\"ACCESS-CM2\", \"MIROC6\") ssps <- c(\"126\", \"585\") periods <- c(\"2041-2060\", \"2061-2080\") #Create a grid of combination of periods, ssps and gcms g <- expand.grid(\"period\" = periods, \"ssps\" = ssps, \"gcms\" = gcms) g #Each line is a specific scenario for future #Loop to download variables for each scenario lapply(1:nrow(g), function(i){   cmip6_world(model = g$gcms[i],                ssp = g$ssps[i],                time = g$period[i],                var = \"bioc\",                res = 10, path = geodata_dir) }) #It will take a while... list.files(geodata_dir, recursive = TRUE) #> [1] \"climate/wc2.1_10m/wc2.1_10m_bioc_ACCESS-CM2_ssp126_2041-2060.tif\" #> [2] \"climate/wc2.1_10m/wc2.1_10m_bioc_ACCESS-CM2_ssp126_2061-2080.tif\" #> [3] \"climate/wc2.1_10m/wc2.1_10m_bioc_ACCESS-CM2_ssp585_2041-2060.tif\" #> [4] \"climate/wc2.1_10m/wc2.1_10m_bioc_ACCESS-CM2_ssp585_2061-2080.tif\" #> [5] \"climate/wc2.1_10m/wc2.1_10m_bioc_MIROC6_ssp126_2041-2060.tif\"     #> [6] \"climate/wc2.1_10m/wc2.1_10m_bioc_MIROC6_ssp126_2061-2080.tif\"     #> [7] \"climate/wc2.1_10m/wc2.1_10m_bioc_MIROC6_ssp585_2041-2060.tif\"     #> [8] \"climate/wc2.1_10m/wc2.1_10m_bioc_MIROC6_ssp585_2061-2080.tif\"  #>  #> #Set climate as input directory #> in_dir <- file.path(geodata_dir, \"climate\")"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_projections.html","id":"format-for-renaming","dir":"Articles","previous_headings":"Pre-processing raster predictors > Organize and structure future climate variables from WorldClim","what":"Format for renaming","title":"Project models to multiple scenarios","text":"important argument name_format, defines format renaming variables. names variables SpatRaster must precisely match used model calibration running PCA (do_pca = TRUE set prepare_data() function; see Prepare Data Model Calibration details). Therefore, variables used calibrate models named “bio_1”, “bio_2”, etc., variables future raster layers must also named “bio_1”, “bio_2”, etc. However, variables different pattern, starting uppercase letters using zeros single-digit numbers (e.g., “Bio_01”, “Bio_02”, etc.), must named “Bio_01”, “Bio_02”, etc. function provides four options: \"bio_\": Variables renamed bio_1, bio_2, bio_3, bio_10, etc. \"bio_0\": Variables renamed bio_01, bio_02, bio_03, bio_10, etc. \"Bio_\": Variables renamed Bio_1, Bio_2, Bio_3, Bio_10, etc. \"Bio_0\": Variables renamed Bio_01, Bio_02, Bio_03, Bio_10, etc. Let’s check variables named fitted_model: variables follows standards first option (\"bio_\").","code":"fitted_model_maxnet$continuous_variables #> [1] \"bio_1\"  \"bio_7\"  \"bio_12\" \"bio_15\""},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_projections.html","id":"fixed-variables","dir":"Articles","previous_headings":"Pre-processing raster predictors > Organize and structure future climate variables from WorldClim","what":"Fixed variables","title":"Project models to multiple scenarios","text":"predicting times, can assume variables static (.e., remain unchanged projected scenarios). fixed_variables argument allows append static variables alongside bioclimatic variables. , let’s assume soilType remain static future scenarios:","code":"# Import raster layers (same used to calibrate and fit final models) var <- rast(system.file(\"extdata\", \"Current_variables.tif\", package = \"kuenm2\")) #Get soilType soiltype <- var$SoilType"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_projections.html","id":"organize-and-structure-worldclim-files","dir":"Articles","previous_headings":"Pre-processing raster predictors > Organize and structure future climate variables from WorldClim","what":"Organize and structure WorldClim files","title":"Project models to multiple scenarios","text":"Now, let’s organize WorldClim files organize_future_worldclim() function: can check files structured hierarchically nested folders using dir_tree() function fs package: organizing variables, next step create prepared_projection object.","code":"#Create folder to save structured files out_dir_future <- file.path(tempdir(), \"Future_raw\") #Here, in a temporary directory #Organize organize_future_worldclim(input_dir = in_dir, #Path to the raw variables from WorldClim                           output_dir = out_dir_future,                            name_format = \"bio_\", #Name format                           fixed_variables = var$SoilType) #Static variables #>   |                                                                              |                                                                      |   0%  |                                                                              |=========                                                             |  12%  |                                                                              |==================                                                    |  25%  |                                                                              |==========================                                            |  38%  |                                                                              |===================================                                   |  50%  |                                                                              |============================================                          |  62%  |                                                                              |====================================================                  |  75%  |                                                                              |=============================================================         |  88%  |                                                                              |======================================================================| 100% #>  #> Variables successfully organized in directory: #> /tmp/RtmpXniDQn/Future_raw  # Check files organized dir(out_dir_future, recursive = TRUE) #> [1] \"2041-2060/ssp126/ACCESS-CM2/Variables.tif\" #> [2] \"2041-2060/ssp126/MIROC6/Variables.tif\"     #> [3] \"2041-2060/ssp585/ACCESS-CM2/Variables.tif\" #> [4] \"2041-2060/ssp585/MIROC6/Variables.tif\"     #> [5] \"2081-2100/ssp126/ACCESS-CM2/Variables.tif\" #> [6] \"2081-2100/ssp126/MIROC6/Variables.tif\"     #> [7] \"2081-2100/ssp585/ACCESS-CM2/Variables.tif\" #> [8] \"2081-2100/ssp585/MIROC6/Variables.tif\" #Install package if necessary if(!require(\"fs\")){   install.packages(\"fs\") } dir_tree(out_dir_future) #> Temp\\RtmpkhmGWN/Future_raw #> ├── 2041-2060 #> │   ├── ssp126 #> │   │   ├── ACCESS-CM2 #> │   │   │   └── Variables.tif #> │   │   └── MIROC6 #> │   │       └── Variables.tif #> │   └── ssp585 #> │       ├── ACCESS-CM2 #> │       │   └── Variables.tif #> │       └── MIROC6 #> │           └── Variables.tif #> └── 2081-2100 #>     ├── ssp126 #>     │   ├── ACCESS-CM2 #>     │   │   └── Variables.tif #>     │   └── MIROC6 #>     │       └── Variables.tif #>     └── ssp585 #>         ├── ACCESS-CM2 #>         │   └── Variables.tif #>         └── MIROC6 #>             └── Variables.tif"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_projections.html","id":"preparation-of-data-for-model-projections","dir":"Articles","previous_headings":"","what":"Preparation of data for model projections","title":"Project models to multiple scenarios","text":"Now, let’s prepare data model projections across multiple scenarios, storing paths rasters representing scenario. contrast predict_selected(), requires SpatRaster object, need paths folders raster files stored. includes variables present time, used calibrate fit models. Currently, future climate files. present-day predictor variables must reside root directory processed future variables. Let’s copy rasters used model calibration fitting folder: Now, can prepare data projections. addition storing paths variables scenario, function also verifies variables used fit final models available across scenarios. perform check, need provide either fitted_models object intend use projection simply variable names. strongly suggest using fitted_models object minimize projection errors. also need define root directory containing scenarios projection (present, past, /future), along additional information regarding time periods, SSPs, GCMs. print projection_data object, summarizes scenarios predict also shows root directory predictor rasters stored: check structure prepared_projection object, can see ’s list containing: Paths variables representing distinct scenarios subfolders. pattern used identify format raster files within folders (default, *.tif). names predictors. list class prcomp Principal Component Analysis (PCA) performed set variables prepare_data().","code":"# Create a \"Current_raw\" folder in a temporary directory # and copy the rawvariables there. out_dir_current <- file.path(tempdir(), \"Current_raw\") dir.create(out_dir_current, recursive = TRUE)  # Save current variables in temporary directory terra::writeRaster(var, file.path(out_dir_current, \"Variables.tif\"))  #Check folder list.files(out_dir_current) #> [1] \"Variables.tif\" # Prepare projections using fitted models to check variables pr <- prepare_projection(models = fitted_model_maxnet,                          present_dir = out_dir_current, #Directory with present-day variables                          past_dir = NULL, #NULL because we won't project to the past                          past_period = NULL, #NULL because we won't project to the past                          past_gcm = NULL, #NULL because we won't project to the past                          future_dir = out_dir_future, #Directory with future variables                          future_period = c(\"2041-2060\", \"2081-2100\"),                          future_pscen = c(\"ssp126\", \"ssp585\"),                          future_gcm = c(\"ACCESS-CM2\", \"MIROC6\")) pr #> projection_data object summary #> ============================= #> Variables prepared to project models for Present and Future  #> Future projections contain the following periods, scenarios and GCMs: #>   - Periods: 2041-2060 | 2081-2100  #>   - Scenarios: ssp126 | ssp585  #>   - GCMs: ACCESS-CM2 | MIROC6  #> All variables are located in the following root directory: #> /tmp/RtmpXniDQn #Open prepared_projection in a new window View(pr)"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_projections.html","id":"project-selected-models-to-multiple-scenarios","dir":"Articles","previous_headings":"","what":"Project selected models to multiple scenarios","title":"Project models to multiple scenarios","text":"preparing data, can use project_selected() function predict selected models across multiple scenarios specified prepare_projections: function returns model_projections object. object similar prepared_data object, storing information predicted scenarios folder resulting projection rasters saved. Note results saved hierarchically nested subfolders, representing distinct scenario. root directory, function also saves file named “Projection_paths.RDS”, model_projections object. object can imported R using readRDS(file.path(out_dir, \"Projection_paths.RDS\")). default, scenario, function computes consensus metrics (mean, median, range, standard deviation) model across replicates (one model selected), well general consensus across models. function accepts several parameters control predictions predict_selected(), consensus compute, extrapolation type (free extrapolation (E), extrapolation clamping (EC), extrapolation (NE)), variables clamp, format prediction values (raw, cumulative, logistic, default cloglog). details, consult vignette Predict models single scenario.","code":"## Create a folder to save projection results #Here, in a temporary directory out_dir <- file.path(tempdir(), \"Projection_results/maxnet\") dir.create(out_dir, recursive = TRUE)  ## Project selected models to multiple scenarios p <- project_selected(models = fitted_model_maxnet,                        projection_data = pr,                       out_dir = out_dir,                        progress_bar = FALSE) #Do not print progress bar print(p) #> model_projections object summary #> ================================ #> Models projected for Present and Future  #> Future projections contain the following periods, scenarios and GCMs: #>   - Periods: 2041-2060 | 2081-2100  #>   - Scenarios: ssp126 | ssp585  #>   - GCMs: ACCESS-CM2 | MIROC6  #> All raster files containing the projection results are located in the following root directory: #>  /tmp/RtmpXniDQn/Projection_results/maxnet dir_tree(out_dir) #> Temp\\RtmpkhmGWN/Projection_results/maxnet #> ├── Future #> │   ├── 2041-2060 #> │   │   ├── ssp126 #> │   │   │   ├── ACCESS-CM2 #> │   │   │   │   ├── General_consensus.tif #> │   │   │   │   ├── Model_159_consensus.tif #> │   │   │   │   └── Model_189_consensus.tif #> │   │   │   └── MIROC6 #> │   │   │       ├── General_consensus.tif #> │   │   │       ├── Model_159_consensus.tif #> │   │   │       └── Model_189_consensus.tif #> │   │   └── ssp585 #> │   │       ├── ACCESS-CM2 #> │   │       │   ├── General_consensus.tif #> │   │       │   ├── Model_159_consensus.tif #> │   │       │   └── Model_189_consensus.tif #> │   │       └── MIROC6 #> │   │           ├── General_consensus.tif #> │   │           ├── Model_159_consensus.tif #> │   │           └── Model_189_consensus.tif #> │   └── 2081-2100 #> │       ├── ssp126 #> │       │   ├── ACCESS-CM2 #> │       │   │   ├── General_consensus.tif #> │       │   │   ├── Model_159_consensus.tif #> │       │   │   └── Model_189_consensus.tif #> │       │   └── MIROC6 #> │       │       ├── General_consensus.tif #> │       │       ├── Model_159_consensus.tif #> │       │       └── Model_189_consensus.tif #> │       └── ssp585 #> │           ├── ACCESS-CM2 #> │           │   ├── General_consensus.tif #> │           │   ├── Model_159_consensus.tif #> │           │   └── Model_189_consensus.tif #> │           └── MIROC6 #> │               ├── General_consensus.tif #> │               ├── Model_159_consensus.tif #> │               └── Model_189_consensus.tif #> ├── Present #> │   └── Present #> │       ├── General_consensus.tif #> │       ├── Model_159_consensus.tif #> │       └── Model_189_consensus.tif #> └── Projection_paths.RDS"},{"path":"https://marlonecobos.github.io/kuenm2/articles/model_projections.html","id":"import-rasters-resulting-from-projections","dir":"Articles","previous_headings":"","what":"Import rasters resulting from projections","title":"Project models to multiple scenarios","text":"model_projections object stores paths resultant rasters. import results, can use import_projections() function. default, imports consensus metrics (“median”, “range”, “mean”, “stdev”) scenarios (time periods, SSPs, GCMs) available model_projections object. Let’s import mean scenarios:  Alternatively, can import results specific scenarios. example, let’s import results “2041-2060” time period SSP 126:  model_projections object, can compute changes suitable areas scenarios (see projection_changes function), explore variance stemming replicates, model parameterizations, GCMs (see projection_variability), perform analysis extrapolation risks (see projection_mop). details, check vignette Explore Variability Uncertainty Projections.","code":"#Import mean of each projected scenario p_mean <- import_projections(projection = p, consensus = \"mean\") #Plot all scenarios plot(p_mean, cex.main = 0.8) p_2060_ssp126 <- import_projections(projection = p, consensus = \"mean\",                                      present = FALSE, #Do not import present projections                                     future_period = \"2041-2060\",                                     future_pscen = \"ssp126\") #Plot all scenarios plot(p_2060_ssp126, cex.main = 0.8)"},{"path":"https://marlonecobos.github.io/kuenm2/articles/prepare_data.html","id":"description","dir":"Articles","previous_headings":"","what":"Description","title":"Prepare Data for Model Calibration","text":"starting ENM process, data must formatted specific structure required functions kuenm2. vignette guides users steps necessary prepare occurrence data environmental predictors using built-tools. covers use prepare_data() prepare_user_data() generate standardized objects, essential model calibration. vignette also demonstrates options applying PCA, incorporating sampling bias, saving prepared data later use.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/articles/prepare_data.html","id":"getting-ready","dir":"Articles","previous_headings":"","what":"Getting ready","title":"Prepare Data for Model Calibration","text":"kuenm2 installed yet, please . See Main guide installation instructions. See basic data cleaning guide steps cleaning data. Use following lines code load kuenm2 required packages, define working directory (needed). general, setting working directory R considered good practice, provides better control files read saved . users working within R project, recommend setting working directory, since least one file saved later stages guide.","code":"# Load packages library(kuenm2) library(terra)  # Current directory getwd()  # Define new directory #setwd(\"YOUR/DIRECTORY\")  # uncomment this line if setting a new directory"},{"path":[]},{"path":"https://marlonecobos.github.io/kuenm2/articles/prepare_data.html","id":"import-data","dir":"Articles","previous_headings":"Prepare data","what":"Import data","title":"Prepare Data for Model Calibration","text":"use occurrence records provided within kuenm2 package. example data package derived Trindade & Marques (2024). occ_data object contains 51 occurrences Myrcia hatschbachii, tree endemic Southern Brazil. Although example data set three columns (species, x, y), users’ input data requires two numeric columns longitude latitude coordinates.  predictor variables, use data included package. data set comprises four bioclimatic variables WorldClim 2.1 10 arc-minute resolution, categorical variable (SoilType) SoilGrids resampled 10 arc-minutes. variables masked using polygon delimits area model calibration, generated drawing minimum convex polygon around records 300 km buffer.   Visualize occurrences records geography:","code":"# Import occurrences data(occ_data, package = \"kuenm2\")  # Check data structure str(occ_data) #> 'data.frame':    51 obs. of  3 variables: #>  $ species: chr  \"Myrcia hatschbachii\" \"Myrcia hatschbachii\" \"Myrcia hatschbachii\" \"Myrcia hatschbachii\" ... #>  $ x      : num  -51.3 -50.6 -49.3 -49.8 -50.2 ... #>  $ y      : num  -29 -27.6 -27.8 -26.9 -28.2 ... # Import raster layers var <- rast(system.file(\"extdata\", \"Current_variables.tif\", package = \"kuenm2\"))  # Check variables plot(var) # Visualize occurrences on one variable plot(var[[\"bio_1\"]], main = \"Bio 1\")  points(occ_data[, c(\"x\", \"y\")], col = \"black\")"},{"path":"https://marlonecobos.github.io/kuenm2/articles/prepare_data.html","id":"first-steps-in-preparing-data","dir":"Articles","previous_headings":"Prepare data","what":"First steps in preparing data","title":"Prepare Data for Model Calibration","text":"function prepare_data() central getting data ready model calibration. handles several key steps: Defining algorithm: Users can choose maxnet glm. Generating background points: Background points area sampled raster layers, unless provided user. points serve reference contrast presence records. Principal component analysis (PCA): optional step can applied set predictors PCA. Preparing calibration data: Presence records background points associate predictor values put together data.frame used ENM. Data partitioning: function divides data using k-folds prepare training testing sets via cross-validation process. Defining grid model parameters: helps setting combinations feature classes (FCs), regularization multiplier (RM) values (Maxnet), sets predictor variables. explanation roles RMs FCs Maxent models see Merow et al. 2013. function, recommend consulting documentation detailed explanations (e.g., help(prepare_data)). Now, let’s prepare data model calibration using prepare_data():  prepare_data() function returns prepared_data object, list containing various essential pieces information fro model calibration. example object printed summarize components.  parts prepared_data object can explored detail indexing following example.  default, prepare_data() prepares object fitting models using maxnet. However, can changed use GLM instead. using GLM, necessary set regularization multipliers, algorithm utilize .  default, prepare_data() extracts background points entire extent provided raster variables. species-specific polygon defining calibration area, can use mask raster variables delimit calibration area. example, let’s create 100km buffer around occurrence records:  Now, let’s use new polygon mask variables within prepare_data(). Let’s also increase number background points 1,000: Note warning message: “n_background’ >= initial number points, using points”. occurs , masking variables, total number pixels within buffer less specified n_background (1,000). cases, available points within calibration area used background points. following examples, ’ll use object d_maxnet, prepared maxnet algorithm without mask. However, functions compatible objects prepared GLM well.","code":"# Prepare data for maxnet model d <- prepare_data(algorithm = \"maxnet\",                   occ = occ_data,                   x = \"x\", y = \"y\",                   raster_variables = var,                   species = \"Myrcia hatschbachii\",                   categorical_variables = \"SoilType\",                   n_background = 1000,                   features = c(\"l\", \"q\", \"p\", \"lq\", \"lqp\"),                   r_multiplier = c(0.1, 1, 2, 3, 5)) #> Warning in handle_missing_data(occ_bg, weights): 43 rows were excluded from #> database because NAs were found. print(d) #> prepared_data object summary #> ============================ #> Species: Myrcia hatschbachii  #> Number of Records: 1008  #>   - Presence: 51  #>   - Background: 957  #> Training-Testing Method: #>   - k-fold Cross-validation: 4 folds #> Continuous Variables: #>   - bio_1, bio_7, bio_12, bio_15  #> Categorical Variables: #>   - SoilType  #> PCA Information: PCA not performed #> Weights: No weights provided #> Calibration Parameters: #>   - Algorithm: maxnet  #>   - Number of candidate models: 610  #>   - Features classes (responses): l, q, p, lq, lqp  #>   - Regularization multipliers: 0.1, 1, 2, 3, 5 # See first rows of calibration data head(d$calibration_data) #>   pr_bg    bio_1    bio_7 bio_12   bio_15 SoilType #> 1     1 16.49046 18.66075   1778 12.96107       19 #> 2     1 15.46644 19.65775   1560 14.14697       19 #> 3     1 15.70560 17.99450   1652 23.27548        6 #> 4     1 17.78899 19.55600   1597 18.91694        1 #> 5     1 15.50116 18.30750   1497 15.39440       19 #> 7     1 17.42421 17.25875   1760 34.17664        6  # See first rows of formula grid head(d$formula_grid) #>   ID           Formulas R_multiplier Features #> 1  1  ~bio_1 + bio_7 -1          0.1        l #> 2  2  ~bio_1 + bio_7 -1          1.0        l #> 3  3  ~bio_1 + bio_7 -1          2.0        l #> 4  4  ~bio_1 + bio_7 -1          3.0        l #> 5  5  ~bio_1 + bio_7 -1          5.0        l #> 6  6 ~bio_1 + bio_12 -1          5.0        l d_glm <- prepare_data(algorithm = \"glm\",                       occ = occ_data,                       x = \"x\", y = \"y\",                       raster_variables = var,                       species = \"Myrcia hatschbachii\",                       categorical_variables = \"SoilType\",                       n_background = 300,                       features = c(\"l\", \"q\", \"p\", \"lq\", \"lqp\"),                       r_multiplier = NULL) #Not necessary with glms #> Warning in handle_missing_data(occ_bg, weights): 8 rows were excluded from #> database because NAs were found. #Print object d_glm #> prepared_data object summary #> ============================ #> Species: Myrcia hatschbachii  #> Number of Records: 343  #>   - Presence: 51  #>   - Background: 292  #> Training-Testing Method: #>   - k-fold Cross-validation: 4 folds #> Continuous Variables: #>   - bio_1, bio_7, bio_12, bio_15  #> Categorical Variables: #>   - SoilType  #> PCA Information: PCA not performed #> Weights: No weights provided #> Calibration Parameters: #>   - Algorithm: glm  #>   - Number of candidate models: 122  #>   - Features classes (responses): l, q, p, lq, lqp #Convert dataframe with occurrences to SpatVector pts <- vect(occ_data, geom = c(x = \"x\", y = \"y\"), crs = \"EPSG:4326\") #Create buffer b <- buffer(x = pts, width = 100000) #Width in meters #Aggregate buffers b <- terra::aggregate(b) #Plot buffer plot(b) points(occ_data[, c(\"x\", \"y\")], col = \"black\") d_buffer <- prepare_data(algorithm = \"maxnet\",                          occ = occ_data,                          x = \"x\", y = \"y\",                          raster_variables = var,                          mask = b, #Polygon to mask variables                          species = \"Myrcia hatschbachii\",                          categorical_variables = \"SoilType\",                          n_background = 1000,                          features = c(\"l\", \"q\", \"p\", \"lq\", \"lqp\"),                          r_multiplier = c(0.1, 1, 2, 3, 5)) #> 'n_background' >= initial number of points, using all points. #> Warning in handle_missing_data(occ_bg, weights): 25 rows were excluded from #> database because NAs were found."},{"path":"https://marlonecobos.github.io/kuenm2/articles/prepare_data.html","id":"exploring-calibration-data","dir":"Articles","previous_headings":"Prepare data","what":"Exploring calibration data","title":"Prepare Data for Model Calibration","text":"Users can visualize distribution predictor values occurrence records, background points, entire calibration area using histograms. example presented . See full documentation help(explore_calibration_hist) help(plot_explore_calibration).  gray bars represent values across entire calibration area. Blue bars show values background, green bars display values presence points (magnified factor 2 improved visualization). can customize colors magnification factor.  Additionally, users can explore geographic distribution occurrence background points. See full documentation help(explore_calibration_geo).   Note , default, background points selected randomly within calibration area. However, users can influence spatial distribution background, increasing decreasing probability selection certain regions, providing bias file (demonstrated next section).","code":"# Prepare histogram data calib_hist <- explore_calibration_hist(data = d, raster_variables = var,                                        include_m = TRUE)  # Plot histograms plot_explore_calibration(explore_calibration = calib_hist) pbg <- explore_calibration_geo(data = d, raster_variables = var[[1]],                                plot = TRUE)"},{"path":"https://marlonecobos.github.io/kuenm2/articles/prepare_data.html","id":"using-a-bias-file","dir":"Articles","previous_headings":"Prepare data","what":"Using a bias file","title":"Prepare Data for Model Calibration","text":"bias file SpatRaster object contains values influence selection background points within calibration area. can particularly useful mitigating sampling bias, instance, incorporating density records target group (discussed Ponder et al. 2001, Anderson et al. 2003, Barber et al. 2020). bias file must extent, resolution, number cells raster variables, unless mask supplied. mask used, extent bias file encompass larger mask extent. Let’s illustrate example bias file included package. SpatRaster lower values center higher values towards borders:   now use bias file prepare two new datasets: one bias effect “direct” (higher probability regions higher bias values) another effect “inverse” (higher probability regions lower bias values):  Note bias effect “direct”, majority background points sampled borders calibration area, corresponding higher bias values. Conversely, “inverse” bias effect, background points selected center, bias values lower.","code":"# Import a bias file bias <- rast(system.file(\"extdata\", \"bias_file.tif\", package = \"kuenm2\"))  plot(bias) # Using bias as a direct effect in sampling d_bias_direct <- prepare_data(algorithm = \"maxnet\",                               occ = occ_data,                               x = \"x\", y = \"y\",                               raster_variables = var,                               species = \"Myrcia hatschbachii\",                               categorical_variables = \"SoilType\",                               n_background = 1000,                               bias_file = bias, bias_effect = \"direct\",  # bias parameters                               features = c(\"l\", \"q\", \"p\", \"lq\", \"lqp\"),                               r_multiplier = c(0.1, 1, 2, 3, 5)) #> Warning in handle_missing_data(occ_bg, weights): 57 rows were excluded from #> database because NAs were found.  # Using bias as an indirect effect in sampling d_bias_inverse <- prepare_data(algorithm = \"maxnet\",                                occ = occ_data,                                x = \"x\", y = \"y\",                                raster_variables = var,                                species = \"Myrcia hatschbachii\",                                categorical_variables = \"SoilType\",                                n_background = 1000,                                bias_file = bias, bias_effect = \"inverse\",   # bias parameters                                features = c(\"l\", \"q\", \"p\", \"lq\", \"lqp\"),                                r_multiplier = c(0.1, 1, 2, 3, 5)) #> Warning in handle_missing_data(occ_bg, weights): 45 rows were excluded from #> database because NAs were found.  # Compare background points generated randomly versus with bias effects ## Saving original plotting parameters original_par <- par(no.readonly = TRUE)  ## Adjusting plotting grid par(mfrow = c(2,2))    ## The plots to show sampling bias effects plot(bias, main = \"Bias file\") explore_calibration_geo(d, raster_variables = var[[1]],                         main = \"Random Background\") explore_calibration_geo(d_bias_direct, raster_variables = var[[1]],                         main = \"Direct Bias Effect\") explore_calibration_geo(d_bias_inverse, raster_variables = var[[1]],                         main = \"Inverse Bias Effect\") par(original_par)  # Reset grid"},{"path":"https://marlonecobos.github.io/kuenm2/articles/prepare_data.html","id":"pca-for-variables","dir":"Articles","previous_headings":"Prepare data","what":"PCA for variables","title":"Prepare Data for Model Calibration","text":"common approach ENM involves summarizing information set predictor variables smaller set uncorrelated variables using Principal Component Analysis (PCA) (see Cruz-Cardenaz et al. 2014 example). kuenm2 users can perform PCA internally use variables externally prepared PCs.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/articles/prepare_data.html","id":"internal-pca","dir":"Articles","previous_headings":"Prepare data > PCA for variables","what":"Internal PCA","title":"Prepare Data for Model Calibration","text":"kuenm2 can perform PCA transformations internally, eliminating need prepare new PC variables scenario projection. particularly advantageous projecting model results across multiple time scenarios (e.g., various Global Climate Models different future periods). performing PCA internally, need store raw environmental variables (e.g., bio_1, bio_2, etc.) directory, functions handle PCA transformation needed. Let’s explore implement :  elements calibration data formula grid now generated considering principal components (PCs). default, continuous variables included PCA, categorical variables (e.g., “SoilType”) excluded. default settings number PCs selected retain axes collectively explain 95% total variance, filter , keeping axes individually explain least 5% variance. parameters can changed using arguments function prepare_data  PCA performed internally, prepared_data object contains necessary information transform raw environmental variables required PCs means predicting projecting models, users provide raw raster variables, PCs obtained internally function.","code":"# Prepare data for maxnet models using PCA parameters d_pca <- prepare_data(algorithm = \"maxnet\",                       occ = occ_data,                       x = \"x\", y = \"y\",                       raster_variables = var,                        do_pca = TRUE, center = TRUE, scale = TRUE,  # PCA parameters                       species = \"Myrcia hatschbachii\",                       categorical_variables = \"SoilType\",                       n_background = 1000,                       features = c(\"l\", \"q\", \"p\", \"lq\", \"lqp\"),                       r_multiplier = c(0.1, 1, 2, 3, 5)) #> Warning in handle_missing_data(occ_bg, weights): 43 rows were excluded from #> database because NAs were found.  print(d_pca) #> prepared_data object summary #> ============================ #> Species: Myrcia hatschbachii  #> Number of Records: 1008  #>   - Presence: 51  #>   - Background: 957  #> Training-Testing Method: #>   - k-fold Cross-validation: 4 folds #> Continuous Variables: #>   - bio_1, bio_7, bio_12, bio_15  #> Categorical Variables: #>   - SoilType  #> PCA Information: #>   - Variables included: bio_1, bio_7, bio_12, bio_15  #>   - Number of PCA components: 4  #> Weights: No weights provided #> Calibration Parameters: #>   - Algorithm: maxnet  #>   - Number of candidate models: 610  #>   - Features classes (responses): l, q, p, lq, lqp  #>   - Regularization multipliers: 0.1, 1, 2, 3, 5 # Check calibration data head(d_pca$calibration_data) #>   pr_bg         PC1        PC2        PC3         PC4 SoilType #> 1     1  1.48690341 1.01252697  0.1180156 -0.09119257       19 #> 2     1  1.46028074 0.17701144  1.1573461 -0.12326796       19 #> 3     1  0.82676494 1.21965795  0.8145129 -0.67588891        6 #> 4     1  0.62680441 0.03967459  0.1525997  0.18784282        1 #> 5     1  0.94584897 0.93302089  1.4382424 -0.03192094       19 #> 7     1 -0.07597437 1.55268331 -0.2007953 -0.98153204        6  # Check formula grid head(d_pca$formula_grid) #>   ID      Formulas R_multiplier Features #> 1  1 ~PC1 + PC2 -1          0.1        l #> 2  2 ~PC1 + PC2 -1          1.0        l #> 3  3 ~PC1 + PC2 -1          2.0        l #> 4  4 ~PC1 + PC2 -1          3.0        l #> 5  5 ~PC1 + PC2 -1          5.0        l #> 6  6 ~PC1 + PC3 -1          5.0        l  # Explore variables distribution calib_hist_pca <- explore_calibration_hist(data = d_pca, raster_variables = var,                                            include_m = TRUE, breaks = 7)  plot_explore_calibration(explore_calibration = calib_hist_pca)"},{"path":"https://marlonecobos.github.io/kuenm2/articles/prepare_data.html","id":"external-pca","dir":"Articles","previous_headings":"Prepare data > PCA for variables","what":"External PCA","title":"Prepare Data for Model Calibration","text":"Alternatively, users can perform PCA data using perform_pca() function, one preference. See full documentation help(perform_pca). Se example perform_pca() :   Now, let’s use PCs generated perform_pca() prepare data:  Note since PCA performed externally, do_pca = FALSE set within prepare_data function. crucial setting TRUE incorrectly apply PCA variables already PCs. Consequently, prepared_data object scenario store PCA-related information. means users predict project models, must must provide PCs instead raw raster variables.","code":"pca_var <- perform_pca(raster_variables = var, exclude_from_pca = \"SoilType\",                        center = TRUE, scale = TRUE)  # Plot plot(pca_var$env) # Prepare data for maxnet model using PCA variables d_pca_extern <- prepare_data(algorithm = \"maxnet\",                              occ = occ_data,                              x = \"x\", y = \"y\",                              raster_variables = pca_var$env,  # Output of perform_pca()                              do_pca = FALSE,  # Set to FALSE because variables are PCs                              species = \"Myrcia hatschbachii\",                              categorical_variables = \"SoilType\",                              n_background = 1000,                              features = c(\"l\", \"q\", \"p\", \"lq\", \"lqp\"),                              r_multiplier = c(0.1, 1, 2, 3, 5)) #> Warning in handle_missing_data(occ_bg, weights): 43 rows were excluded from #> database because NAs were found.  print(d_pca_extern) #> prepared_data object summary #> ============================ #> Species: Myrcia hatschbachii  #> Number of Records: 1008  #>   - Presence: 51  #>   - Background: 957  #> Training-Testing Method: #>   - k-fold Cross-validation: 4 folds #> Continuous Variables: #>   - PC1, PC2, PC3, PC4  #> Categorical Variables: #>   - SoilType  #> PCA Information: PCA not performed #> Weights: No weights provided #> Calibration Parameters: #>   - Algorithm: maxnet  #>   - Number of candidate models: 610  #>   - Features classes (responses): l, q, p, lq, lqp  #>   - Regularization multipliers: 0.1, 1, 2, 3, 5 # Check calibration data head(d_pca_extern$calibration_data) #>   pr_bg         PC1        PC2        PC3         PC4 SoilType #> 1     1  1.48690341 1.01252697  0.1180156 -0.09119257       19 #> 2     1  1.46028074 0.17701144  1.1573461 -0.12326796       19 #> 3     1  0.82676494 1.21965795  0.8145129 -0.67588891        6 #> 4     1  0.62680441 0.03967459  0.1525997  0.18784282        1 #> 5     1  0.94584897 0.93302089  1.4382424 -0.03192094       19 #> 7     1 -0.07597437 1.55268331 -0.2007953 -0.98153204        6  # Check formula grid head(d_pca_extern$formula_grid) #>   ID      Formulas R_multiplier Features #> 1  1 ~PC1 + PC2 -1          0.1        l #> 2  2 ~PC1 + PC2 -1          1.0        l #> 3  3 ~PC1 + PC2 -1          2.0        l #> 4  4 ~PC1 + PC2 -1          3.0        l #> 5  5 ~PC1 + PC2 -1          5.0        l #> 6  6 ~PC1 + PC3 -1          5.0        l"},{"path":"https://marlonecobos.github.io/kuenm2/articles/prepare_data.html","id":"prepare-user-pre-processed-data","dir":"Articles","previous_headings":"","what":"Prepare user pre-processed data","title":"Prepare Data for Model Calibration","text":"users already data prepared calibration, can use prepare_user_data() function create object required model calibration. User-prepared calibration data must data.frame includes column indicating presence (1) background (0) records, along columns values variables. package includes example data.frame reference. See example use :  prepare_user_data() function operates similarly prepare_data(), key difference; instead requiring data.frame occurrence coordinates SpatRaster predictor variables, takes already prepared user data.frame (see ). See full documentation help(prepare_user_data). function also allows provide list folds cross-validation used model calibration. user_folds NULL, function automatically split data based number folds specified kfolds argument. Internal PCA variables also available function.","code":"data(\"user_data\", package = \"kuenm2\")  head(user_data) #>   pr_bg    bio_1    bio_7 bio_12   bio_15 SoilType #> 1     1 16.49046 18.66075   1778 12.96107       19 #> 2     1 15.46644 19.65775   1560 14.14697       19 #> 3     1 15.70560 17.99450   1652 23.27548        6 #> 4     1 17.78899 19.55600   1597 18.91694        1 #> 5     1 15.50116 18.30750   1497 15.39440       19 #> 7     1 17.42421 17.25875   1760 34.17664        6 # Prepare data for maxnet model data_user <- prepare_user_data(algorithm = \"maxnet\",                                user_data = user_data,  # user-prepared data.frame                                pr_bg = \"pr_bg\",                                species = \"Myrcia hatschbachii\",                                categorical_variables = \"SoilType\",                                features = c(\"l\", \"q\", \"p\", \"lq\", \"lqp\"),                                r_multiplier = c(0.1, 1, 2, 3, 5))  data_user  #> prepared_data object summary #> ============================ #> Species: Myrcia hatschbachii  #> Number of Records: 527  #>   - Presence: 51  #>   - Background: 476  #> Training-Testing Method: #>   - k-fold Cross-validation: 4 folds #> Continuous Variables: #>   - bio_1, bio_7, bio_12, bio_15  #> Categorical Variables: #>   - SoilType  #> PCA Information: PCA not performed #> Weights: No weights provided #> Calibration Parameters: #>   - Algorithm: maxnet  #>   - Number of candidate models: 610  #>   - Features classes (responses): l, q, p, lq, lqp  #>   - Regularization multipliers: 0.1, 1, 2, 3, 5"},{"path":"https://marlonecobos.github.io/kuenm2/articles/prepare_data.html","id":"saving-a-prepared_data-object","dir":"Articles","previous_headings":"","what":"Saving a prepared_data object","title":"Prepare Data for Model Calibration","text":"prepared_data object crucial next step ENM workflow kuenm2, model calibration. object essentially list, users can save local directory using saveRDS(). Saving object facilitates loading back R session later using readRDS(). See example :","code":"# Set directory to save (here, in a temporary directory) dir_to_save <- file.path(tempdir())  # Save the data saveRDS(d, file.path(dir_to_save, \"Data.rds\"))  # Import data d <- readRDS(file.path(dir_to_save, \"Data.rds\"))"},{"path":"https://marlonecobos.github.io/kuenm2/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Marlon E. Cobos. Author, maintainer. Weverton Trindade. Author. Luis F. Arias-Giraldo. Author. Luis Osorio-Olvera. Author. . Townsend Peterson. Author.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Cobos M, Trindade W, Arias-Giraldo L, Osorio-Olvera L, Peterson (2025). kuenm2: Detailed Development Ecological Niche Models. R package version 0.0.10, https://marlonecobos.github.io/kuenm2/.","code":"@Manual{,   title = {kuenm2: Detailed Development of Ecological Niche Models},   author = {Marlon E. Cobos and Weverton Trindade and Luis F. Arias-Giraldo and Luis Osorio-Olvera and A. Townsend Peterson},   year = {2025},   note = {R package version 0.0.10},   url = {https://marlonecobos.github.io/kuenm2/}, }"},{"path":"https://marlonecobos.github.io/kuenm2/index.html","id":"kuenm2-detailed-development-of-ecological-niche-models","dir":"","previous_headings":"","what":"Detailed Development of Ecological Niche Models","title":"Detailed Development of Ecological Niche Models","text":"Marlon E. Cobos, Weverton Trindade, Luis F. Arias-Giraldo, Luis Osorio-Olvera, . Townsend Peterson Package description Installing package Basic data cleaning Data preparation Model calibration Model explorations Model projections Projection comparisons Variability uncertainty Checking vignettes","code":""},{"path":"https://marlonecobos.github.io/kuenm2/index.html","id":"package-description","dir":"","previous_headings":"","what":"Package description","title":"Detailed Development of Ecological Niche Models","text":"kuenm2 new version kuenm Cobos et al. 2019, R package designed make process ecological niche modeling (ENM) easier, faster, reproducible, time robust. aim package facilitate crucial steps ENM process: data preparation, model calibration, selected model exploration, model projections, analyses uncertainty variability. new version package reduces dependency strictly organized working directory (required projections multiple scenarios needed). Instead, kuenm2 functions generate specific R objects store necessary information subsequent steps. ENM workflow kuenm2 begins data preparation, requires minimum data.frame containing occurrence record coordinates (longitude latitude) SpatRaster object predictor variables. kuenm2 fits maximum entropy (Maxnet) models logistic generalized linear models (GLMs). Maxnet models created described Phillips et al. (2017), GLMs constructed Cobos Peterson (2023).","code":""},{"path":"https://marlonecobos.github.io/kuenm2/index.html","id":"installing-the-package","dir":"","previous_headings":"","what":"Installing the package","title":"Detailed Development of Ecological Niche Models","text":"Note: Internet connection required install package. install latest release kuenm2 use following line code:  development version kuenm2 can installed using code .  problems? problems installation development version GitHub, restart R session, close RStudio sessions may open, try . installation asked update packages, don’t need specific version one packages installed. packages gives error updating, please install alone using install.packages(), try installing kuenm2 .  load package use:","code":"# Installing from CRAN  #install.packages(\"kuenm2\")  # in progress # Installing and loading packages if(!require(remotes)){   install.packages(\"remotes\") }  # To install the package use remotes::install_github(\"marlonecobos/kuenm2\")  # To install the package and its vignettes use (if needed use: force = TRUE)   remotes::install_github(\"marlonecobos/kuenm2\", build_vignettes = TRUE)  # in progress # Load kuenm2 library(kuenm2)"},{"path":"https://marlonecobos.github.io/kuenm2/index.html","id":"workflow-in-kuenm2","dir":"","previous_headings":"","what":"Workflow in kuenm2","title":"Detailed Development of Ecological Niche Models","text":"kuenm2 package facilitates following steps ENM process: basic data cleaning, data preparation, model calibration, model exploration, model projections, projection comparisons, exploration variability uncertainty. figure shows schematic view package works. brief description steps can performed package presented . complete description demonstration steps, see package vignettes listed section Checking vignettes. Figure 1. Schematic view workflow use kuenm2.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/index.html","id":"basic-data-cleaning","dir":"","previous_headings":"Workflow in kuenm2","what":"Basic data cleaning","title":"Detailed Development of Ecological Niche Models","text":"Data cleaning tools kuenm2 help automate following basic steps: columns sorting, missing-data cleaning, duplicate removal, exclusion coordinates longitude latitude values 0, filtering based coordinate decimal precision (see function initial_cleaning()). addition, users can erase duplicates based pixels raster layer, move records barely outside valid pixels raster layer (see function advanced_cleaning()).","code":""},{"path":"https://marlonecobos.github.io/kuenm2/index.html","id":"data-preparation","dir":"","previous_headings":"Workflow in kuenm2","what":"Data preparation","title":"Detailed Development of Ecological Niche Models","text":"kuenm2 two main functions help users prepare data ENM process. functions take initial data, guide users make decisions algorithm used models combination parameters (feature classes, regularization multiplier, sets variables) explored later model calibration. Users can input occurrence records raster layers, data.frame prepared hand. main functions step prepare_data() prepare_user_data(). Users can also explore detail environmental values look like data model calibration using results preparing data functions explore_calibration_geo(), explore_calibration_hist(), plot_explore_calibration().","code":""},{"path":"https://marlonecobos.github.io/kuenm2/index.html","id":"model-calibration","dir":"","previous_headings":"Workflow in kuenm2","what":"Model calibration","title":"Detailed Development of Ecological Niche Models","text":"Model calibration computationally challenging process automated kuenm2. step, candidate models trained tested using k-fold cross-validation approach. , models selected based multiple criteria warranty models used later steps robust among candidates. main function used step calibration().","code":""},{"path":"https://marlonecobos.github.io/kuenm2/index.html","id":"model-explorations","dir":"","previous_headings":"Workflow in kuenm2","what":"Model explorations","title":"Detailed Development of Ecological Niche Models","text":"best performing models selected, users need fit models (fit_selected()) order explore characteristics continue next steps. Fitted models can used assess variable importance models, well explore variable response curves. See functions variable_importance() response_curves().","code":""},{"path":"https://marlonecobos.github.io/kuenm2/index.html","id":"model-projections","dir":"","previous_headings":"Workflow in kuenm2","what":"Model projections","title":"Detailed Development of Ecological Niche Models","text":"selected models fit explored, projections single multiple scenarios can done. facilitate projections simple complex combinations scenarios, multiple functions available. function predict_selected() performs projections single scenarios, function project_selected() helps multiple scenarios. Notice, however, projecting multiple scenarios, steps need done. example projections future scenarios, WorldClim variables, see functions: organize_future_worldclim(), prepare_projection().","code":""},{"path":"https://marlonecobos.github.io/kuenm2/index.html","id":"projection-comparisons","dir":"","previous_headings":"Workflow in kuenm2","what":"Projection comparisons","title":"Detailed Development of Ecological Niche Models","text":"projections multiple scenarios involve transfer another time can compared current scenario, kuenm2 provides way quantify characterize changes. can done using function projection_changes() results help describe changes scenarios, distinct levels agreement changes among scenarios.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/index.html","id":"variability-and-uncertainty","dir":"","previous_headings":"Workflow in kuenm2","what":"Variability and uncertainty","title":"Detailed Development of Ecological Niche Models","text":"results model projections multiple scenarios, tools analyses variability uncertainty included kuenm2. Variability model projections (projection_variability()) represented geographically exploring variance comes replicates, distinct model parameterizations, general circulation models (projections times). represent uncertainty, Mobility Oriented-Parity (MOP) metric used compare projection scenarios conditions model training (projection_mop()).","code":""},{"path":"https://marlonecobos.github.io/kuenm2/index.html","id":"checking-the-vignettes","dir":"","previous_headings":"","what":"Checking the vignettes","title":"Detailed Development of Ecological Niche Models","text":"Users can check kuenm2 vignettes full explanation package functionality. installing development version form GitHub, make sure use argument build_vignettes = TRUE. Check vignettes code :","code":"# Guide to basic data cleaning before the ENM process vignette(\"basic_data_cleaning\")  # Guide to prepare data for the ENM process vignette(\"prepare_data\")  # Guide to train and evaluate candidate models, and select based on performance #vignette(\"model_calibration\")  # in progress  # Guide to explore selected models, variable importance, response curves #vignette(\"model_exploration\")  # in progress  # Guide to predict models in geographic space (single scenarios) #vignette(\"model_predictions\")  # in progress  # Guide to project models in geographic space (multiple scenarios) #vignette(\"model_projections\")  # in progress  # Guide to explore variability and uncertainty in projections (multiple scenarios) #vignette(\"variability_and_uncertainty\")  # in progress"},{"path":"https://marlonecobos.github.io/kuenm2/reference/advanced_cleaning.html","id":null,"dir":"Reference","previous_headings":"","what":"Advanced occurrence data cleaning — advanced_cleaning","title":"Advanced occurrence data cleaning — advanced_cleaning","text":"Advanced processes data cleaning involving duplicate removal movement records.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/advanced_cleaning.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Advanced occurrence data cleaning — advanced_cleaning","text":"","code":"advanced_cleaning(data, x, y, raster_layer, cell_duplicates = TRUE,                   move_points_inside = FALSE, move_limit_distance = NULL,                   verbose = TRUE)  remove_cell_duplicates(data, x, y,                        raster_layer)  move_2closest_cell(data, x, y, raster_layer,                    move_limit_distance, verbose = TRUE)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/advanced_cleaning.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Advanced occurrence data cleaning — advanced_cleaning","text":"data data.frame occurrence records. Rows NA values omitted. x (character) name column data containing longitude values. y (character) name column data containing latitude values. raster_layer raster layer (object class SpatRaster). cell_duplicates (logical) whether remove duplicate coordinates considering raster cells. Default = TRUE. move_points_inside (logical) whether move records outside raster cells valid values closest cell values. Default = FALSE. move_limit_distance maximum distance move records outside cells valid values. Default = NULL. Must defined move_points_inside = TRUE. verbose (logical) whether print messages progress. Default = TRUE.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/advanced_cleaning.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Advanced occurrence data cleaning — advanced_cleaning","text":"data.frame occurrence records resulting advanced cleaning procedures. columns added describe changes made original data.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/advanced_cleaning.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Advanced occurrence data cleaning — advanced_cleaning","text":"Data used functions gone initial processes cleaning filtering.","code":""},{"path":[]},{"path":"https://marlonecobos.github.io/kuenm2/reference/bivariate_response.html","id":null,"dir":"Reference","previous_headings":"","what":"Bivariate response plot for fitted models — bivariate_response","title":"Bivariate response plot for fitted models — bivariate_response","text":"plot suitability prediction two-dimensional environmental space.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/bivariate_response.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bivariate response plot for fitted models — bivariate_response","text":"","code":"bivariate_response(models, variable1 , variable2, modelID = NULL, n = 500,                    new_data = NULL, extrapolate = TRUE, add_bar = TRUE ,                    add_limits = TRUE, color_palette  = NULL,                    xlab = NULL, ylab = NULL, ...)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/bivariate_response.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bivariate response plot for fitted models — bivariate_response","text":"models object class fitted_models returned fit_selected() function. variable1 (character) name variable plotted x axis. variable2 (character) name variable plotted y axis. modelID (character) name ModelID presents fitted object. Default = NULL. n (numeric) number breaks plotting grid. Default = 500 new_data SpatRaster, data.frame,  matrix variables representing area interest. Default = NULL. extrapolate (logical) whether allow extrapolation study behavior response outside calibration limits. Ignored new_data defined. Default = TRUE. add_bar (logical) whether add bar legend. Default = TRUE. add_limits (logical) whether add calibration limits extrapolate = TRUE. Default = TRUE. color_palette (function) color palette function used assign colors plot. default, NULL uses rev(hcl.colors(n, \"terrain\")). xlab (character) label x axis. default, NULL, uses name defined variable1. ylab (character) label y axis. default, NULL, uses name defined variable2. ... additional arguments passed image.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/bivariate_response.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bivariate response plot for fitted models — bivariate_response","text":"bivariate plot considering variable1 variable2.","code":""},{"path":[]},{"path":"https://marlonecobos.github.io/kuenm2/reference/bivariate_response.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bivariate response plot for fitted models — bivariate_response","text":"","code":"# Example with glmnet # Import example of fitted_models (output of fit_selected()) data(fitted_model_maxnet, package = \"kuenm2\")  # Response curve (notice response affected by covariance) bivariate_response(models = fitted_model_maxnet, modelID = \"Model_189\",                    variable1 = \"bio_1\", variable2 = \"bio_12\")   # Example with glm # Import example of fitted_models (output of fit_selected()) data(fitted_model_glm, package = \"kuenm2\")  # Response curve bivariate_response(models = fitted_model_glm, modelID = \"Model_86\",                    variable1 = \"bio_1\", variable2 = \"bio_7\")"},{"path":"https://marlonecobos.github.io/kuenm2/reference/calibration.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting and evaluation of models, and selection of the best ones — calibration","title":"Fitting and evaluation of models, and selection of the best ones — calibration","text":"function fits evaluates candidate models using data grid formulas prepared prepare_data(). supports algorithms glm maxnet. function selects best models based unimodality (optional), partial ROC, omission rate, AIC values.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/calibration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting and evaluation of models, and selection of the best ones — calibration","text":"","code":"calibration(data, error_considered, remove_concave = FALSE,             proc_for_all = FALSE, omission_rate = NULL, delta_aic = 2,             allow_tolerance = TRUE, tolerance = 0.01,             addsamplestobackground = TRUE, use_weights = NULL,             write_summary = FALSE, output_directory = NULL,             skip_existing_models = FALSE, return_all_results = TRUE,             parallel = FALSE, ncores = NULL, progress_bar = TRUE,             verbose = TRUE)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/calibration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting and evaluation of models, and selection of the best ones — calibration","text":"data object class prepared_data returned prepare_data() function. contains calibration data, formulas grid, kfolds, model type. error_considered (numeric) values 0 100 representing percentage potential error due source uncertainty data. value used calculate omission rates partial ROC. See details. remove_concave (logical) whether remove candidate models presenting concave curves. Default FALSE. proc_for_all (logical) whether apply partial ROC tests candidate models selected models. Default FALSE, meaning tests applied selected models. omission_rate (numeric) values 0 - 100, maximum omission rate candidate model can considered potentially selected model. default, NULL, uses value error_considered. one value used error_considered, omission_rate must defined. delta_aic (numeric) value delta AIC used threshold select models. Default 2. allow_tolerance (logical) whether allow selection models minimum values omission rates even omission rate surpasses omission_rate. applicable candidate models omission rates higher omission_rate. Default TRUE. tolerance (numeric) value added minimum omission rate exceeds omission_rate. allow_tolerance = TRUE, selected models omission rate equal less minimum rate plus tolerance. Default 0.01. addsamplestobackground (logical) whether add background presence sample already . Default TRUE. use_weights (logical) whether apply weights present data. default, NULL, uses weights provided data. present data, NULL weights 1 presences 100 background. turned FALSE, uses NULL weights even present data. write_summary (logical) whether save evaluation results candidate model disk. Default FALSE. output_directory (character) file name, without path, saving evaluation results candidate model. applicable write_summary = TRUE. skip_existing_models (logical) whether check skip candidate models already fitted saved output_directory. applicable write_summary = TRUE. Default FALSE. return_all_results (logical) whether return evaluation results replicate. Default TRUE, meaning evaluation results replicate returned. parallel (logical) whether fit candidate models parallel. Default FALSE. ncores (numeric) number cores use parallel processing. Default NULL uses available cores - 1. applicable parallel = TRUE. progress_bar (logical) whether display progress bar processing. Default TRUE. verbose (logical) whether display messages processing. Default TRUE.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/calibration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting and evaluation of models, and selection of the best ones — calibration","text":"object class 'calibration_results' containing following elements: species: character string name species. calibration data: data.frame containing column (pr_bg) identifies occurrence points (1) background points (0), along corresponding values predictor variables point. formula_grid: data frame containing calibration grid possible formulas parameters. kfolds: list vectors row indices corresponding fold. data_xy: data.frame occurrence background coordinates. continuous_variables: character indicating continuous variables. categorical_variables: character, categorical variable names (used). weights: numeric vector specifying weights data_xy (used). pca: principal component analysis performed variables, list class \"prcomp\". See prcomp() details. algorithm: model type (glm maxnet) calibration_results: list containing data frame evaluation metrics replicates (return_all_results = TRUE) summary evaluation metrics candidate model. omission_rate: omission rate used select models. addsamplestobackground: logical value indicating whether presence sample already background added. selected_models: data frame ID summary evaluation metrics selected models. summary: list containing delta AIC values model selection, ID values models failed fit, concave curves, non-significant pROC values, omission rates threshold, delta AIC values threshold, selected models.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/calibration.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting and evaluation of models, and selection of the best ones — calibration","text":"Partial ROC calculated using values defined error_considered following Peterson et al. (2008). Omission rates calculated using separate testing data subsets. Users can specify multiple values error_considered calculate metric (e.g., c(5, 10)), one can used omission rate model selection. Model fitting complexity (AICc) assessed using models generated complete set occurrences. AICc values computed proposed Warren Seifert (2011).","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/calibration.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting and evaluation of models, and selection of the best ones — calibration","text":"Ninomiya, Yoshiyuki, Shuichi Kawano. \"AIC Lasso generalized linear models.\" (2016): 2537-2560. Warren, D. L., & Seifert, S. N. (2011). Ecological niche modeling Maxent: importance model complexity performance model selection criteria. Ecological applications, 21(2), 335-342.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/calibration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting and evaluation of models, and selection of the best ones — calibration","text":"","code":"# Import prepared data for maxnet models data(sp_swd, package = \"kuenm2\")  # Model calibration (maxnet) m <- calibration(data = sp_swd, error_considered = 10) #> Task 1/1: fitting and evaluating models: #>    |                                                                               |                                                                      |   0%   |                                                                               |=========                                                             |  12%   |                                                                               |==================                                                    |  25%   |                                                                               |==========================                                            |  38%   |                                                                               |===================================                                   |  50%   |                                                                               |============================================                          |  62%   |                                                                               |====================================================                  |  75%   |                                                                               |=============================================================         |  88%   |                                                                               |======================================================================| 100% #>  #>  #> Model selection step: #> Selecting best among 8 models. #> Calculating pROC... #>  #> Filtering 8 models. #> Removing 0 model(s) because they failed to fit. #> 7 models were selected with omission rate below 10%. #> Selecting 2 final model(s) with delta AIC <2. #> Validating pROC of selected models... #>    |                                                                               |                                                                      |   0%   |                                                                               |===================================                                   |  50%   |                                                                               |======================================================================| 100% #>  #> All selected models have significant pROC values.  m #> calibration_results object summary (maxnet) #> ============================================================= #> Species: Myrcia hatschbachii  #> Number of candidate models: 8  #>   - Models removed because they failed to fit: 0  #>   - Models identified with concave curves: 0  #>   - Model with concave curves not removed  #>   - Models removed with non-significant values of pROC: 0  #>   - Models removed with omission error > 10%: 1  #>   - Models removed with delta AIC > 2: 5  #> Selected models: 2  #>   - Up to 5 printed here: #>   ID                                                           Formulas #> 5  5                        ~bio_1 + bio_7 + I(bio_1^2) + I(bio_7^2) -1 #> 8  8 ~bio_1 + bio_7 + bio_12 + I(bio_1^2) + I(bio_7^2) + I(bio_12^2) -1 #>   Features R_multiplier pval_pROC_at_10.mean Omission_rate_at_10.mean    dAIC #> 5       lq            1                    0                   0.0978 0.00000 #> 8       lq            1                    0                   0.0978 1.22774 #>   Parameters #> 5          3 #> 8          4  # Import prepared data for GLM models data(sp_swd_glm, package = \"kuenm2\")  ## Model calibration (GLM) m_glm <- calibration(data = sp_swd_glm, error_considered = 10) #> Task 1/1: fitting and evaluating models: #>    |                                                                               |                                                                      |   0%   |                                                                               |======                                                                |   8%   |                                                                               |============                                                          |  17%   |                                                                               |==================                                                    |  25%   |                                                                               |=======================                                               |  33%   |                                                                               |=============================                                         |  42%   |                                                                               |===================================                                   |  50%   |                                                                               |=========================================                             |  58%   |                                                                               |===============================================                       |  67%   |                                                                               |====================================================                  |  75%   |                                                                               |==========================================================            |  83%   |                                                                               |================================================================      |  92%   |                                                                               |======================================================================| 100% #>  #>  #> Model selection step: #> Selecting best among 12 models. #> Calculating pROC... #>  #> Filtering 12 models. #> Removing 0 model(s) because they failed to fit. #> 8 models were selected with omission rate below 10%. #> Selecting 2 final model(s) with delta AIC <2. #> Validating pROC of selected models... #>    |                                                                               |                                                                      |   0%   |                                                                               |===================================                                   |  50%   |                                                                               |======================================================================| 100% #>  #> All selected models have significant pROC values.  m_glm #> calibration_results object summary (glm) #> ============================================================= #> Species: Myrcia hatschbachii  #> Number of candidate models: 12  #>   - Models removed because they failed to fit: 0  #>   - Models identified with concave curves: 1  #>   - Model with concave curves not removed  #>   - Models removed with non-significant values of pROC: 0  #>   - Models removed with omission error > 10%: 4  #>   - Models removed with delta AIC > 2: 6  #> Selected models: 2  #>   - Up to 5 printed here: #>   ID                                                        Formulas Features #> 5  5                        ~bio_1 + bio_7 + I(bio_1^2) + I(bio_7^2)       lq #> 8  8 ~bio_1 + bio_7 + bio_12 + I(bio_1^2) + I(bio_7^2) + I(bio_12^2)       lq #>   pval_pROC_at_10.mean Omission_rate_at_10.mean       dAIC Parameters #> 5                    0                   0.0962 0.02361168          4 #> 8                    0                   0.0962 0.00000000          6"},{"path":"https://marlonecobos.github.io/kuenm2/reference/detect_concave.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect concave curves in GLM and GLMNET models — detect_concave","title":"Detect concave curves in GLM and GLMNET models — detect_concave","text":"Identifies presence concave response curves within calibration range GLM GLMNET models.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/detect_concave.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect concave curves in GLM and GLMNET models — detect_concave","text":"","code":"detect_concave(model, calib_data, extrapolation_factor = 0.1,                averages_from = \"pr\", var_limits = NULL, plot = FALSE,                mfrow = NULL, legend = FALSE)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/detect_concave.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect concave curves in GLM and GLMNET models — detect_concave","text":"model object class glmnet_mx glm. calib_data data.frame matrix data used model calibration. extrapolation_factor (numeric) multiplier used calculate extrapolation range. Larger values allow broader extrapolation beyond observed data range. Default 0.1. averages_from (character) specifies averages modes variables calculated. Available options \"pr\" (calculate averages presence localities) \"pr_bg\" (use combined set presence background localities). Default \"pr\". See details. var_limits (list) named list specifying lower /upper limits variables. first value represents lower limit, second value represents upper limit. Default NULL, meaning specific limits applied, range calculated using extrapolation_factor. See details. plot (logical) whether plot response curve variables. Default FALSE. mfrow (numeric) vector form c(number rows, number columns) specifying layout plots. Default c(1, 1), meaning one plot per window. legend (logical) whether include legend plot. legend indicates whether response curve convex, concave outside range limits, concave within range limits. Default FALSE.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/detect_concave.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect concave curves in GLM and GLMNET models — detect_concave","text":"list following elements variable: is_concave (logical): indicates whether response curve variable concave within limit range. occurs quadratic term's coefficient positive vertex lies x_min x_max, vertex (numeric): vertex parabola, representing point curve changes direction. b2 (numeric): coefficient quadratic term variable. Positive values indicate concave curve. x_min x_max (numeric): range limits identify concave curves, calculated observed data range multiplied extrapolation factor. real_x_min real_x_max (numeric) actual range data, excluding extrapolation factor.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/detect_concave.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Detect concave curves in GLM and GLMNET models — detect_concave","text":"Concave curves identified analyzing beta coefficients quadratic terms within variable's range. range extrapolation calculated difference variable's maximum minimum values model, multiplied extrapolation factor. concave curve detected beta coefficient positive, vertex — curve changes direction — lies lower upper limits variable. Users can specify lower upper limits certain variables using var_limits. example, var_limits = list(\"bio12\" = c(0, NA), \"bio15\" = c(0, 100)), lower limit bio12 0, upper limit calculated using extrapolation factor. Similarly, lower upper limits bio15 0 100, respectively. calculating vertex position, response curve given variable generated variables set mean values (mode categorical variables). values calculated either presence localities (averages_from = \"pr\") combined set presence background localities (averages_from = \"pr_bg\").","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/detect_concave.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect concave curves in GLM and GLMNET models — detect_concave","text":"","code":"# Import example of a fitted_model (output of fit_selected()) that have # concave curves data(\"fitted_model_concave\", package = \"kuenm2\")  #Response curves ccurves <- detect_concave(model = fitted_model_concave$Models$Model_798$Full_model,                           calib_data = fitted_model_concave$calibration_data,                           extrapolation_factor = 0.2,                           var_limits = list(\"bio_2\" = c(0, NA),                                             \"sand\" = c(0, NA),                                             \"clay\" = c(0, NA)),                           plot = TRUE, mfrow = c(2, 3), legend = TRUE)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/explore_calibration_geo.html","id":null,"dir":"Reference","previous_headings":"","what":"Explore the spatial distribution of occurrence and background points — explore_calibration_geo","title":"Explore the spatial distribution of occurrence and background points — explore_calibration_geo","text":"Explore spatial distribution occurrence background points","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/explore_calibration_geo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Explore the spatial distribution of occurrence and background points — explore_calibration_geo","text":"","code":"explore_calibration_geo(data, raster_variables, plot = TRUE, ...)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/explore_calibration_geo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Explore the spatial distribution of occurrence and background points — explore_calibration_geo","text":"data object class prepared_data returned prepare_data() function. raster_variables (SpatRaster) predictor variables used model calibration. plot (logical) wheter plot SpatRaster. Default TRUE. ... additional arguments passed terra::plot().","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/explore_calibration_geo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Explore the spatial distribution of occurrence and background points — explore_calibration_geo","text":"categorical SpatRaster four factor values representing: 1 - Background cells  2 - Presence cells  3 - Cells presence background  4 - Non-used cells","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/explore_calibration_geo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Explore the spatial distribution of occurrence and background points — explore_calibration_geo","text":"","code":"# Import raster layers var <- terra::rast(system.file(\"extdata\", \"Current_variables.tif\",                                package = \"kuenm2\"))  # Import occurrences data(sp_swd, package = \"kuenm2\")  # Explore calibration data pbg <- explore_calibration_geo(data = sp_swd, raster_variables = var[[1]])"},{"path":"https://marlonecobos.github.io/kuenm2/reference/explore_calibration_hist.html","id":null,"dir":"Reference","previous_headings":"","what":"Explore variable distribution for occurrence and background points — explore_calibration_hist","title":"Explore variable distribution for occurrence and background points — explore_calibration_hist","text":"function prepares data generate overlaid histograms visualize distribution predictor variables occurrence (presence) background points.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/explore_calibration_hist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Explore variable distribution for occurrence and background points — explore_calibration_hist","text":"","code":"explore_calibration_hist(data, include_m = FALSE, raster_variables = NULL,                          magnify_occurrences = 2, breaks = 15)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/explore_calibration_hist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Explore variable distribution for occurrence and background points — explore_calibration_hist","text":"data object class prepared_data returned prepare_data() function. include_m (logical) whether include data plotting histogram entire area background points sampled. Default FALSE, meaning background presence information plotted. raster_variables (SpatRaster) predictor variables used prepared data prepared_data. applicable include_m TRUE. magnify_occurrences (numeric) factor frequency occurrences magnified better visualization. Default 2, meaning occurrence frequencies plot doubled. breaks (numeric) single number giving desired number intervals histogram.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/explore_calibration_hist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Explore variable distribution for occurrence and background points — explore_calibration_hist","text":"list information plot informative histograms explore data used modeling process. Histogram plots can plotted function plot_explore_calibration().","code":""},{"path":[]},{"path":"https://marlonecobos.github.io/kuenm2/reference/explore_calibration_hist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Explore variable distribution for occurrence and background points — explore_calibration_hist","text":"","code":"# Import raster layers var <- terra::rast(system.file(\"extdata\", \"Current_variables.tif\",                                package = \"kuenm2\"))  # Import occurrences data(sp_swd_cat, package = \"kuenm2\")  # Explore calibration data calib_hist <- explore_calibration_hist(data = sp_swd_cat,                                        raster_variables = var,                                        include_m = TRUE)  # To visualize results use the function plot_explore_calibration()"},{"path":"https://marlonecobos.github.io/kuenm2/reference/extract_var_from_formulas.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract predictor names from formulas — extract_var_from_formulas","title":"Extract predictor names from formulas — extract_var_from_formulas","text":"Extract predictor names formulas","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/extract_var_from_formulas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract predictor names from formulas — extract_var_from_formulas","text":"","code":"extract_var_from_formulas(formulas, ...)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/extract_var_from_formulas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract predictor names from formulas — extract_var_from_formulas","text":"formulas (character formula) model formulas. ... Arguments pass .vars()","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/extract_var_from_formulas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract predictor names from formulas — extract_var_from_formulas","text":"character vector list length formulas, containing names predictors formula.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/extract_var_from_formulas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract predictor names from formulas — extract_var_from_formulas","text":"","code":"# Import an example of calibration results data(calib_results_maxnet, package = \"kuenm2\")  # Extract predictor names vars <- extract_var_from_formulas(calib_results_maxnet$formula_grid$Formulas)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/fit_selected.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit models selected after calibration — fit_selected","title":"Fit models selected after calibration — fit_selected","text":"function fits models selected candidate model training testing using function calibration().","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/fit_selected.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit models selected after calibration — fit_selected","text":"","code":"fit_selected(calibration_results, n_replicates = 1, rep_type = \"kfold\",              train_portion = 0.7, write_models = FALSE, file_name = NULL,              parallel = FALSE, ncores = NULL, progress_bar = TRUE,              verbose = TRUE, seed = 1)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/fit_selected.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit models selected after calibration — fit_selected","text":"calibration_results object class calibration_results returned calibration() function. n_replicates (numeric) number model replicates. Using default, 1, implies one replicate fit data. rep_type (character) replicate type. can : \"kfold\", \"bootstrap\", \"subsample\". Default \"kfold\". train_portion (numeric) proportion occurrence records used train model replicate. parameter applicable rep_type set \"bootstrap\" \"subsample\". Default 0.7. write_models (logical) whether save final fitted models disk. Default FALSE. file_name (character) file name, without path, saving final models. applicable write_models = TRUE. parallel (logical) whether fit final models parallel. Default FALSE. ncores (numeric) number cores use parallel processing. Default NULL uses available cores - 1. applicable parallel = TRUE. progress_bar (logical) whether display progress bar processing. Default TRUE. verbose (logical) whether display detailed messages processing. Default TRUE. seed (numeric) integer value used specify initial seed split data. Default 1.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/fit_selected.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit models selected after calibration — fit_selected","text":"object class 'fitted_models' containing following elements: species character string name species. Models list fitted models, including replicates (trained parts data) full models (trained available records). calibration_data data.frame containing column (pr_bg) identifies occurrence points (1) background points (0), along corresponding values predictor variables point. selected_models data frame ID summary evaluation metrics selected models. weights numeric vector specifying weights predictor variables (used). pca list class prcomp representing result principal component analysis (performed). addsamplestobackground logical value indicating whether presence sample already background added. omission_rate omission rate determined calibration step. thresholds thresholds binarize replicate consensus (mean median), calculated based omission rate set calibration().","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/fit_selected.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit models selected after calibration — fit_selected","text":"function also computes model consensus (mean median), thresholds binarize model predictions based omission rate set model calibration select models.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/fit_selected.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit models selected after calibration — fit_selected","text":"","code":"# An example with maxnet models data(calib_results_maxnet, package = \"kuenm2\")  # Fit models using calibration results fm <- fit_selected(calibration_results = calib_results_maxnet,                    n_replicates = 2) #> Fitting replicates... #>    |                                                                               |                                                                      |   0%   |                                                                               |==================                                                    |  25%   |                                                                               |===================================                                   |  50%   |                                                                               |====================================================                  |  75%   |                                                                               |======================================================================| 100% #>  #> Fitting full models... #>    |                                                                               |                                                                      |   0%   |                                                                               |===================================                                   |  50%   |                                                                               |======================================================================| 100%  # Output the fitted models fm #> fitted_models object summary #> ============================ #> Species: Myrcia hatschbachii  #> Algortihm: maxnet  #> Number of fitted models: 2  #> Models fitted with 2 replicates  # An example with GLMs data(calib_results_glm, package = \"kuenm2\")  # Fit models using calibration results fm_glm <- fit_selected(calibration_results = calib_results_glm,                        n_replicates = 2) #> Fitting replicates... #>    |                                                                               |                                                                      |   0%   |                                                                               |===================================                                   |  50%   |                                                                               |======================================================================| 100% #>  #> Fitting full models... #>    |                                                                               |                                                                      |   0%   |                                                                               |======================================================================| 100%  # Output the fitted models fm_glm #> fitted_models object summary #> ============================ #> Species: Myrcia hatschbachii  #> Algortihm: glm  #> Number of fitted models: 1  #> Models fitted with 2 replicates"},{"path":"https://marlonecobos.github.io/kuenm2/reference/glm_mx.html","id":null,"dir":"Reference","previous_headings":"","what":"Maxent-like Generalized Linear Models (GLM) — glm_mx","title":"Maxent-like Generalized Linear Models (GLM) — glm_mx","text":"function fits Generalized Linear Model (GLM) binary presence-background data. allows specification custom weights, default presences weight 1 background 100.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/glm_mx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maxent-like Generalized Linear Models (GLM) — glm_mx","text":"","code":"glm_mx(formula, family = binomial(link = \"cloglog\"), data,        weights = NULL, ...)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/glm_mx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maxent-like Generalized Linear Models (GLM) — glm_mx","text":"formula formula specifying model fitted, format used glm. family description error distribution link function used model. Defaults binomial(link = \"cloglog\"), commonly used presence-background data. data data.frame containing variables model. Must include column named pr_bg indicates whether record presence (1) background (0), least another column independent variable (predictor). weights Optional. numeric vector weights observation. provided, default weights 1 presences 100 background used. ... Additional arguments passed glm.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/glm_mx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Maxent-like Generalized Linear Models (GLM) — glm_mx","text":"fitted glm object. model object includes minimum maximum values non-factor variables dataset, stored model$varmin model$varmax.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/glm_mx.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Maxent-like Generalized Linear Models (GLM) — glm_mx","text":"details glms using presence background emulating Maxent , see Fithian Hastie (2013) doi:10.1214/13-AOAS667.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/glmnet_mx.html","id":null,"dir":"Reference","previous_headings":"","what":"Maxent-like glmnet models — glmnet_mx","title":"Maxent-like glmnet models — glmnet_mx","text":"function fits Maxent-like models using glmnet package, designed presence-background data.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/glmnet_mx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maxent-like glmnet models — glmnet_mx","text":"","code":"glmnet_mx(p, data, f, regmult = 1.0, regfun = maxnet.default.regularization,           addsamplestobackground = TRUE, weights = NULL, ...)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/glmnet_mx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maxent-like glmnet models — glmnet_mx","text":"p vector binary presence-background labels, 1 indicates presence 0 indicates background. data data.frame containing predictor variables model. must include number rows length p. f formula specifying model fitted, format used model.matrix. regmult (numeric) Regularization multiplier, default 1.0. regfun function calculates regularization penalties. Default maxnet.default.regularization. addsamplestobackground (logical) Whether add presence points background background data. Default TRUE. weights (numeric) numeric vector weights observation. Default NULL, sets weights 1 presence points 100 background points. ... Additional arguments pass glmnet.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/glmnet_mx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Maxent-like glmnet models — glmnet_mx","text":"fitted Maxent-like model object class glmnet_mx, includes model coefficients, AIC (requested), elements feature mins maxes, sample means, entropy.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/glmnet_mx.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Maxent-like glmnet models — glmnet_mx","text":"function modified package maxnet fits Maxent-like model using regularization avoid -fitting. Regularization weights computed using provided function (can changed) can multiplied regularization multiplier (regmult). function also includes option calculate AIC.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/import_projections.html","id":null,"dir":"Reference","previous_headings":"","what":"Import rasters resulting from projection functions — import_projections","title":"Import rasters resulting from projection functions — import_projections","text":"function facilitates import rasters generated written disk project_selected(), projection_changes(), variability_projections(), projection_mop() functions. Users can select specific periods (past/future), emission scenarios, General Circulation Models (GCMs), result types import.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/import_projections.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import rasters resulting from projection functions — import_projections","text":"","code":"import_projections(   projection,   consensus = c(\"median\", \"range\", \"mean\", \"stdev\"),   present = TRUE,   past_period = NULL,   past_gcm = NULL,   future_period = NULL,   future_pscen = NULL,   future_gcm = NULL,   change_types = c(\"summary\", \"by_gcm\", \"by_change\"),   mop_types = c(\"simple\", \"basic\", \"towards_high_combined\", \"towards_low_combined\",     \"towards_high_end\", \"towards_low_end\") )"},{"path":"https://marlonecobos.github.io/kuenm2/reference/import_projections.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import rasters resulting from projection functions — import_projections","text":"projection object class model_projections, changes_projections, variability_projections, mop_projections. object direct output one projection functions listed description. consensus (character) consensus measures import. Available options : 'median', 'range', 'mean' 'stdev' (standard deviation). Default c(\"median\", \"range\", \"mean\", \"stdev\"), imports options. applicable projection model_projections object. present (logical) wheter import present-day projections. Default TRUE. applicable projection  changes_projections object. past_period (character) names specific past periods (e.g., 'LGM' 'MID') import. Default NULL, meaning available past periods imported. past_gcm (character) names specific General Circulation Models (GCMs) past import. Default NULL, meaning available past GCMs imported. future_period (character) names specific future periods (e.g., '2041-2060' '2081-2100') import. Default NULL, meaning available future periods imported. future_pscen (character) names specific future emission scenarios (e.g., 'ssp126' 'ssp585') import. Default NULL, meaning available future scenarios imported. future_gcm (character) names specific General Circulation Models (GCMs) future import. Default NULL, meaning available future GCMs imported. change_types (character) names type computed changes import. Available options : 'summary', 'by_gcm', 'by_change'. Default c(\"summary\", \"by_gcm\", \"by_change\"), importing types. applicable projection changes_projections object. mop_types (character) type(s) MOP import. Available options : basic', 'simple', 'towards_high_combined', 'towards_low_combined', towards_high_end', 'towards_low_end'. Default NULL, meaning available MOPs imported. applicable projection mop_projections object.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/import_projections.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import rasters resulting from projection functions — import_projections","text":"SpatRaster list SpatRasters, structured according input projection class: projection model_projections: stacked SpatRaster containing selected projections. projection changes_projections: list SpatRasters, organized selected change_types (e.g., 'summary', 'by_gcm', /'by_change'). projection mop_projections: list SpatRasters, organized selected mop_types (e.g., 'simple' 'basic'). projection variability_projections: list SpatRasters, containing computed variability.","code":""},{"path":[]},{"path":"https://marlonecobos.github.io/kuenm2/reference/import_projections.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import rasters resulting from projection functions — import_projections","text":"","code":"# Load packages library(terra) #> terra 1.8.54 # Step 1: Organize variables for current projection ## Import current variables (used to fit models) var <- terra::rast(system.file(\"extdata\", \"Current_variables.tif\",                                package = \"kuenm2\"))  ## Create a folder in a temporary directory to copy the variables out_dir_current <- file.path(tempdir(), \"Current_raw2\") dir.create(out_dir_current, recursive = TRUE)  ## Save current variables in temporary directory terra::writeRaster(var, file.path(out_dir_current, \"Variables.tif\"))   # Step 2: Organize future climate variables (example with WorldClim) ## Directory containing the downloaded future climate variables (example) in_dir <- system.file(\"extdata\", package = \"kuenm2\")  ## Create a folder in a temporary directory to copy the future variables out_dir_future <- file.path(tempdir(), \"Future_raw2\")  ## Organize and rename the future climate data (structured by year and GCM) ### 'SoilType' will be appended as a static variable in each scenario organize_future_worldclim(input_dir = in_dir, output_dir = out_dir_future,                           name_format = \"bio_\", fixed_variables = var$SoilType) #>    |                                                                               |                                                                      |   0%   |                                                                               |=========                                                             |  12%   |                                                                               |==================                                                    |  25%   |                                                                               |==========================                                            |  38%   |                                                                               |===================================                                   |  50%   |                                                                               |============================================                          |  62%   |                                                                               |====================================================                  |  75%   |                                                                               |=============================================================         |  88%   |                                                                               |======================================================================| 100% #>  #> Variables successfully organized in directory: #> /tmp/RtmpraqRyK/Future_raw2  # Step 3: Prepare data to run multiple projections ## An example with maxnet models ## Import example of fitted_models (output of fit_selected()) data(fitted_model_maxnet, package = \"kuenm2\")  ## Prepare projection data using fitted models to check variables pr <- prepare_projection(models = fitted_model_maxnet,                          present_dir = out_dir_current,                          future_dir = out_dir_future,                          future_period = c(\"2041-2060\", \"2081-2100\"),                          future_pscen = c(\"ssp126\", \"ssp585\"),                          future_gcm = c(\"ACCESS-CM2\", \"MIROC6\"),                          raster_pattern = \".tif*\")  # Step 4: Run multiple model projections ## A folder to save projection results out_dir <- file.path(tempdir(), \"Projection_results/maxnet\") dir.create(out_dir, recursive = TRUE)  ## Project selected models to multiple scenarios p <- project_selected(models = fitted_model_maxnet, projection_data = pr,                       out_dir = out_dir) #>    |                                                                               |                                                                      |   0%   |                                                                               |========                                                              |  11%   |                                                                               |================                                                      |  22%   |                                                                               |=======================                                               |  33%   |                                                                               |===============================                                       |  44%   |                                                                               |=======================================                               |  56%   |                                                                               |===============================================                       |  67%   |                                                                               |======================================================                |  78%   |                                                                               |==============================================================        |  89%   |                                                                               |======================================================================| 100%  # Use import_projections to import results: raster_p <- import_projections(projection = p, consensus = \"mean\") plot(raster_p)   # Step 5: Identify areas of change in projections ## Contraction, expansion and stability changes <- projection_changes(model_projections = p, output_dir = out_dir,                               overwrite = TRUE) # Use import_projections to import results: raster_changes <- import_projections(projection = changes,                                      change_type = c(\"summary\", \"by_gcm\"))  plot(raster_changes$by_gcm)  plot(raster_changes$Summary)   # Step 6: Perform MOP for all projection scenarios ## Create a folder to save MOP results out_dir <- file.path(tempdir(), \"MOP_results\") dir.create(out_dir, recursive = TRUE)  #Import prepared data to serve as a base for MOP comparisons data(sp_swd_cat, package = \"kuenm2\")  ## Run MOP kmop <- projection_mop(data = sp_swd_cat, projection_data = pr,                        out_dir = out_dir, fitted_models = fitted_model_maxnet,                        type = \"detailed\") #>    |                                                                               |                                                                      |   0%   |                                                                               |========                                                              |  11%   |                                                                               |================                                                      |  22%   |                                                                               |=======================                                               |  33%   |                                                                               |===============================                                       |  44%   |                                                                               |=======================================                               |  56%   |                                                                               |===============================================                       |  67%   |                                                                               |======================================================                |  78%   |                                                                               |==============================================================        |  89%   |                                                                               |======================================================================| 100% # Use import_projections to import results: raster_mop <- import_projections(projection = kmop,                                  mop_types = c(\"simple\", \"basic\",                                                \"towards_high_combined\",                                                \"towards_low_combined\")) plot(raster_mop$simple)  plot(raster_mop$basic)  plot(raster_mop$towards_high_combined)  plot(raster_mop$towards_low_combined)   # Step 7: Compute variance from distinct sources ## Set folder to save results out_dir <- file.path(tempdir()) v <- projection_variability(model_projections = p, by_replicate = FALSE,                             write_files = TRUE, output_dir = out_dir,                             overwrite=TRUE) #> Calculating variability from distinct models: scenario 1 of 5 #> Calculating variability from distinct models: scenario 2 of 5 #> Calculating variability from distinct GCMs: scenario 2 of 5 #> Calculating variability from distinct models: scenario 3 of 5 #> Calculating variability from distinct GCMs: scenario 3 of 5 #> Calculating variability from distinct models: scenario 4 of 5 #> Calculating variability from distinct GCMs: scenario 4 of 5 #> Calculating variability from distinct models: scenario 5 of 5 #> Calculating variability from distinct GCMs: scenario 5 of 5 v #> $Present #> class       : SpatRaster  #> size        : 52, 40, 1  (nrow, ncol, nlyr) #> resolution  : 0.1666667, 0.1666667  (x, y) #> extent      : -53.5, -46.83333, -30.83333, -22.16667  (xmin, xmax, ymin, ymax) #> coord. ref. : lon/lat WGS 84 (EPSG:4326)  #> source(s)   : memory #> name        :    by_model  #> min value   : 8.74016e-18  #> max value   : 1.78190e-01  #>  #> $`Future_2041-2060_ssp126` #> class       : SpatRaster  #> size        : 52, 40, 2  (nrow, ncol, nlyr) #> resolution  : 0.1666667, 0.1666667  (x, y) #> extent      : -53.5, -46.83333, -30.83333, -22.16667  (xmin, xmax, ymin, ymax) #> coord. ref. : lon/lat WGS 84 (EPSG:4326)  #> source(s)   : memory #> names       :     by_model,       by_gcm  #> min values  : 3.919573e-24, 2.292895e-20  #> max values  : 3.273341e-01, 1.272195e-01  #>  #> $`Future_2041-2060_ssp585` #> class       : SpatRaster  #> size        : 52, 40, 2  (nrow, ncol, nlyr) #> resolution  : 0.1666667, 0.1666667  (x, y) #> extent      : -53.5, -46.83333, -30.83333, -22.16667  (xmin, xmax, ymin, ymax) #> coord. ref. : lon/lat WGS 84 (EPSG:4326)  #> source(s)   : memory #> names       :     by_model,       by_gcm  #> min values  : 4.933464e-24, 5.044065e-24  #> max values  : 3.362731e-01, 1.425250e-01  #>  #> $`Future_2081-2100_ssp126` #> class       : SpatRaster  #> size        : 52, 40, 2  (nrow, ncol, nlyr) #> resolution  : 0.1666667, 0.1666667  (x, y) #> extent      : -53.5, -46.83333, -30.83333, -22.16667  (xmin, xmax, ymin, ymax) #> coord. ref. : lon/lat WGS 84 (EPSG:4326)  #> source(s)   : memory #> names       :     by_model,       by_gcm  #> min values  : 3.264598e-23, 2.467159e-20  #> max values  : 2.897881e-01, 1.651514e-01  #>  #> $`Future_2081-2100_ssp585` #> class       : SpatRaster  #> size        : 52, 40, 2  (nrow, ncol, nlyr) #> resolution  : 0.1666667, 0.1666667  (x, y) #> extent      : -53.5, -46.83333, -30.83333, -22.16667  (xmin, xmax, ymin, ymax) #> coord. ref. : lon/lat WGS 84 (EPSG:4326)  #> source(s)   : memory #> names       :     by_model,       by_gcm  #> min values  : 6.933348e-33, 1.386670e-32  #> max values  : 2.583937e-01, 2.152776e-01  #>  #> $root_directory #> [1] \"/tmp/RtmpraqRyK/variance\" #>  #> attr(,\"class\") #> [1] \"variability_projections\" raster_variability <- import_projections(projection = v,                                          future_period = \"2041-2060\") plot(raster_variability)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/initial_cleaning.html","id":null,"dir":"Reference","previous_headings":"","what":"Initial occurrence data cleaning steps — initial_cleaning","title":"Initial occurrence data cleaning steps — initial_cleaning","text":"Simple occurrence data cleaning procedures.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/initial_cleaning.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initial occurrence data cleaning steps — initial_cleaning","text":"","code":"initial_cleaning(data, species, x, y,                  other_columns = NULL, keep_all_columns = TRUE,                  sort_columns = TRUE, remove_na = TRUE, remove_empty = TRUE,                  remove_duplicates = TRUE, by_decimal_precision = FALSE,                  decimal_precision = 0, longitude_precision = NULL,                  latitude_precision = NULL)  sort_columns(data, species, x, y, keep_all_columns = FALSE)  remove_missing(data, columns = NULL, remove_na = TRUE,                remove_empty = TRUE, keep_all_columns = TRUE)  remove_duplicates(data, columns = NULL, keep_all_columns = TRUE)  remove_corrdinates_00(data, x, y)  filter_decimal_precision(data, x,                          y, decimal_precision = 0,                          longitude_precision = NULL,                          latitude_precision = NULL)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/initial_cleaning.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initial occurrence data cleaning steps — initial_cleaning","text":"data data.frame occurrence records. species (character) name column data containing species name. x (character) name column data containing longitude values. y (character) name column data containing latitude values. other_columns (character) vector column name(s) data considered performing cleaning steps, default = NULL. keep_all_columns (logical) whether keep columns data. Default = TRUE. sort_columns (logical) whether sort species, longitude, latitude columns data. Default = TRUE. remove_na (logical) whether remove NA values columns considered. Default = TRUE. remove_empty (logical) whether remove empty (missing) values columns considered. Default = TRUE. remove_duplicates (logical) whether remove duplicates columns considered. Default = TRUE. by_decimal_precision (logical) whether remove certain records coordinate precision lower following three parameters. Default = FALSE decimal_precision (numeric) decimal precision threshold coordinates. Default = 0. Ignored following two parameters defined. longitude_precision (numeric) decimal precision threshold longitude. Default = NULL. latitude_precision (numeric) decimal precision threshold latitude. Default = NULL. columns (character) vector additional column name(s) data considered removing missing duplicate records, default = NULL.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/initial_cleaning.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initial occurrence data cleaning steps — initial_cleaning","text":"data.frame resulting occurrence records.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/initial_cleaning.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Initial occurrence data cleaning steps — initial_cleaning","text":"Function initial_cleaning helps perform simple steps data cleaning.","code":""},{"path":[]},{"path":"https://marlonecobos.github.io/kuenm2/reference/kuenm2-package.html","id":null,"dir":"Reference","previous_headings":"","what":"kuenm2: Detailed Development of Ecological Niche Models — kuenm2-package","title":"kuenm2: Detailed Development of Ecological Niche Models — kuenm2-package","text":"kuenm2 new set tools help development detailed ecological niche models using multiple algorithms. Pre-modeling analyses explorations can done prepare data. Model calibration (model selection) can done creating testing several candidate models. Handy options producing final models transfers included. tools assess extrapolation risks variability model transfers also available.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/kuenm2-package.html","id":"functions-by-stage-in-the-enm-process","dir":"Reference","previous_headings":"","what":"Functions by stage in the ENM process","title":"kuenm2: Detailed Development of Ecological Niche Models — kuenm2-package","text":"Data preparation: initial_cleaning(), advanced_cleaning(), prepare_data(), prepare_user_data() Model calibration: calibration(), select_models() Model exploration: fit_selected(), variable_importance(), plot_importance(), response_curve(), bivariate_response() Model projection: predict_selected(), project_selected() Post-modeling: projection_variability(), projection_changes(), projection_mop()","code":""},{"path":[]},{"path":"https://marlonecobos.github.io/kuenm2/reference/kuenm2-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"kuenm2: Detailed Development of Ecological Niche Models — kuenm2-package","text":"Maintainer: Marlon E. Cobos manubio13@gmail.com (ORCID) Authors: Weverton Trindade wevertonf1993@gmail.com (ORCID) Luis F. Arias-Giraldo lfarias.giraldo@gmail.com (ORCID) Luis Osorio-Olvera luismurao@gmail.com (ORCID) . Townsend Peterson town@ku.edu (ORCID)","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/organize_future_worldclim.html","id":null,"dir":"Reference","previous_headings":"","what":"Organize and structure future climate variables from WorldClim — organize_future_worldclim","title":"Organize and structure future climate variables from WorldClim — organize_future_worldclim","text":"function imports future climate variables downloaded WorldClim, renames files, organizes folders categorized year General Circulation Model (GCM). simplifies preparation climate data, making compatible prepare_projection() function, ensuring required variables properly structured modeling projections.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/organize_future_worldclim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Organize and structure future climate variables from WorldClim — organize_future_worldclim","text":"","code":"organize_future_worldclim(input_dir, output_dir, name_format = \"bio_\",                           variables = NULL, fixed_variables = NULL,                           check_extent = TRUE, mask = NULL,                           progress_bar = TRUE, overwrite = FALSE)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/organize_future_worldclim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Organize and structure future climate variables from WorldClim — organize_future_worldclim","text":"input_dir (character) path folder containing future climate variables downloaded WorldClim. output_dir (character) path folder organized data saved. name_format (character) format renaming variable. Options \"bio_\", \"Bio_\", \"bio_0\", \"Bio_0\". See details information. Default \"bio_\". variables (character) names variables retain. Default NULL, meaning variables kept. fixed_variables (SpatRaster) optional static variables (.e., soil type) used model, remain unchanged future scenarios. variable included future scenario. Default NULL. check_extent (logical) whether ensure fixed_variables spatial extent bioclimatic variables. Applicable fixed_variables provided. Default TRUE. mask (SpatRaster, SpatVector, SpatExtent) spatial object used mask variables (optional). Default NULL. progress_bar (logical) whether display progress bar processing. Default TRUE. overwrite whether overwrite existing files output directory. Default FALSE.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/organize_future_worldclim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Organize and structure future climate variables from WorldClim — organize_future_worldclim","text":"list paths folders organized climate data saved.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/organize_future_worldclim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Organize and structure future climate variables from WorldClim — organize_future_worldclim","text":"raw variables downloaded WorldClim named \"Bio01\", \"Bio02\", \"Bio03\", \"Bio10\", etc. name_format parameter controls variables renamed: \"bio_\": variables renamed bio_1, bio_2, bio_3, bio_10, etc. \"bio_0\": variables renamed bio_01, bio_02, bio_03, bio_10, etc \"Bio_\": variables renamed Bio_1, Bio_2, Bio_3, Bio_10, etc. \"Bio_0\": variables renamed Bio_01, Bio_02, Bio_03, Bio_10, etc.","code":""},{"path":[]},{"path":"https://marlonecobos.github.io/kuenm2/reference/organize_future_worldclim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Organize and structure future climate variables from WorldClim — organize_future_worldclim","text":"","code":"# Import the current variables used to fit the model. # In this case, SoilType will be treated as a static variable (constant # across future scenarios). var <- terra::rast(system.file(\"extdata\", \"Current_variables.tif\",                                package = \"kuenm2\"))  # Set the input directory containing the raw future climate variables. # For this example, the data is located in the \"inst/extdata\" folder. in_dir <- system.file(\"extdata\", package = \"kuenm2\")  # Create a \"Future_raw\" folder in a temporary directory and copy the raw # variables there. out_dir <- file.path(tempdir(), \"Future_raw\")  # Organize and rename the future climate data, structuring it by year and GCM. # The 'SoilType' variable will be appended as a static variable in each scenario. # The files will be renamed following the \"bio_\" format organize_future_worldclim(input_dir = in_dir, output_dir = out_dir,                           name_format = \"bio_\",                           fixed_variables = var$SoilType) #>    |                                                                               |                                                                      |   0%   |                                                                               |=========                                                             |  12%   |                                                                               |==================                                                    |  25%   |                                                                               |==========================                                            |  38%   |                                                                               |===================================                                   |  50%   |                                                                               |============================================                          |  62%   |                                                                               |====================================================                  |  75%   |                                                                               |=============================================================         |  88%   |                                                                               |======================================================================| 100% #>  #> Variables successfully organized in directory: #> /tmp/RtmpraqRyK/Future_raw  # Check files organized dir(out_dir, recursive = TRUE) #> [1] \"2041-2060/ssp126/ACCESS-CM2/Variables.tif\" #> [2] \"2041-2060/ssp126/MIROC6/Variables.tif\"     #> [3] \"2041-2060/ssp585/ACCESS-CM2/Variables.tif\" #> [4] \"2041-2060/ssp585/MIROC6/Variables.tif\"     #> [5] \"2081-2100/ssp126/ACCESS-CM2/Variables.tif\" #> [6] \"2081-2100/ssp126/MIROC6/Variables.tif\"     #> [7] \"2081-2100/ssp585/ACCESS-CM2/Variables.tif\" #> [8] \"2081-2100/ssp585/MIROC6/Variables.tif\""},{"path":"https://marlonecobos.github.io/kuenm2/reference/partial_roc.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial ROC calculation for multiple candidate models — partial_roc","title":"Partial ROC calculation for multiple candidate models — partial_roc","text":"Computes partial ROC tests multiple candidate models.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/partial_roc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial ROC calculation for multiple candidate models — partial_roc","text":"","code":"partial_roc(formula_grid, data, omission_rate = 10,             addsamplestobackground = TRUE, weights = NULL,             algorithm = \"maxnet\", parallel = FALSE, ncores = NULL,             progress_bar = TRUE)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/partial_roc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial ROC calculation for multiple candidate models — partial_roc","text":"formula_grid data.frame grid formulas defining candidate models test. data object class prepared_data returned prepare_data() function object class calibration_results returned calibration() function. contains calibration data k-folds. omission_rate (numeric) values 0 100 representing percentage potential error due source uncertainty. value used calculate omission rate. Default 10. See details. addsamplestobackground (logical) whether add background presence sample already . Default TRUE. weights (numeric) numeric vector specifying weights occurrence records. Default NULL. algorithm (character) type algorithm, either \"glm\" \"maxnet\". Default \"maxnet\". parallel (logical) whether fit candidate models parallel. Default FALSE. ncores (numeric) number cores use parallel processing. Default NULL uses available cores - 1. applicable parallel = TRUE. progress_bar (logical) whether display progress bar processing. Default TRUE.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/partial_roc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial ROC calculation for multiple candidate models — partial_roc","text":"data frame summary statistics AUC ratios significance calculated replicates candidate model. Specifically, includes mean standard deviation metrics model.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/partial_roc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Partial ROC calculation for multiple candidate models — partial_roc","text":"Partial ROC calculated following Peterson et al. (2008) doi:10.1016/j.ecolmodel.2007.11.008.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/partial_roc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partial ROC calculation for multiple candidate models — partial_roc","text":"","code":"# Import prepared data to get model formulas data(sp_swd, package = \"kuenm2\")  # Calculate proc for the first 5 candidate models res_proc <- partial_roc(formula_grid = sp_swd$formula_grid[1:2,],                         data = sp_swd, omission_rate = 10,                         algorithm = \"maxnet\") #>    |                                                                               |                                                                      |   0%   |                                                                               |===================================                                   |  50%   |                                                                               |======================================================================| 100%"},{"path":"https://marlonecobos.github.io/kuenm2/reference/perform_pca.html","id":null,"dir":"Reference","previous_headings":"","what":"Principal Component Analysis for raster layers — perform_pca","title":"Principal Component Analysis for raster layers — perform_pca","text":"function performs principal component analysis (PCA) set raster variables.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/perform_pca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Principal Component Analysis for raster layers — perform_pca","text":"","code":"perform_pca(raster_variables, exclude_from_pca = NULL, project = FALSE,             projection_data = NULL, out_dir = NULL, overwrite = FALSE,             progress_bar = FALSE, center = TRUE, scale = FALSE,             variance_explained = 95, min_explained = 5)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/perform_pca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Principal Component Analysis for raster layers — perform_pca","text":"raster_variables (SpatRaster) set predictor variables function summarize set orthogonal, uncorrelated components based PCA. exclude_from_pca (character) variable names within raster_variables included PCA transformation. Instead, variables added directly final set output variables without modified. default NULL, meaning variables used unless specified otherwise. project (logical) whether function project new data different scenarios (e.g. future variables) onto PCA coordinates generated initial analysis. TRUE, argument projection_data needs defined. Default FALSE. projection_data object class prepared_projection returned prepare_projection() function. file contains paths raster files representing scenario. applicable project = TRUE. Default NULL. out_dir (character) path root directory saving raster files projection. Default = NULL. overwrite (logical) whether overwrite SpatRaster already exists projecting. applicable write_files set TRUE. Default FALSE. progress_bar (logical) whether display progress bar processing projections. applicable project = TRUE. Default FALSE center (logical) whether variables zero-centered. Default TRUE. scale (logical) whether variables scaled unit variance analysis takes place. Default FALSE. variance_explained (numeric) cumulative percentage total variance must explained selected principal components. Default 95. min_explained (numeric) minimum percentage total variance principal component must explain retained. Default 5.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/perform_pca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Principal Component Analysis for raster layers — perform_pca","text":"list containing following elements: env: SpatRaster object contains orthogonal components derived PCA. PCs correspond variables used perform analysis. pca: object class prcomp, containing details PCA analysis. See prcomp(). variance_explained_cum_sum: cumulative percentage total variance explained selected principal components. value indicates much data’s original variability captured PCA transformation. projection_directory: root directory projection files saved. NULL project set TRUE. directory contains projected raster files scenario.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/perform_pca.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Principal Component Analysis for raster layers — perform_pca","text":"","code":"# PCA with current variables # Import raster layers var <- terra::rast(system.file(\"extdata\", \"Current_variables.tif\",                                package = \"kuenm2\"))  # PCA pca_var <- perform_pca(raster_variables = var, exclude_from_pca = \"SoilType\",                        center = TRUE, scale = TRUE)  pca_var #> $env #> class       : SpatRaster  #> size        : 52, 40, 5  (nrow, ncol, nlyr) #> resolution  : 0.1666667, 0.1666667  (x, y) #> extent      : -53.5, -46.83333, -30.83333, -22.16667  (xmin, xmax, ymin, ymax) #> coord. ref. : lon/lat WGS 84 (EPSG:4326)  #> sources     : memory  (4 layers)  #>               Current_variables.tif   #> varnames    : Current_variables  #>               Current_variables  #> names       :       PC1,       PC2,       PC3,       PC4, SoilType  #> min values  : -3.621362, -2.041276, -3.923471, -1.730859,        1  #> max values  :  2.929786,  3.029667,  1.752452,  1.601162,       23  #>  #> $pca #> Standard deviations (1, .., p=4): #> [1] 1.4574175 0.9290330 0.8020786 0.6078666 #>  #> Rotation (n x k) = (4 x 4): #>               PC1        PC2         PC3         PC4 #> bio_1  -0.5327531 -0.1500983 -0.66580466  0.50034864 #> bio_7   0.3338164 -0.9359166 -0.09775690 -0.05541088 #> bio_12  0.5032916  0.2775767 -0.73525490 -0.35923383 #> bio_15 -0.5928223 -0.1564666 -0.08091963 -0.78583200 #>  #> $variance_explained_cumsum #>       PC1       PC2       PC3       PC4  #>  53.10165  74.67920  90.76246 100.00000  #>  #> $projection_directory #> NULL #>   # Project PCA for new scenarios (future) # First, organize and prepare future variables # Set the input directory containing the raw future climate variables # For this example, the data is located in the \"inst/extdata\" folder. in_dir <- system.file(\"extdata\", package = \"kuenm2\")  # Create a \"Future_raw\" folder in a temporary directory and copy the variables. out_dir_future <- file.path(tempdir(), \"Future_raw1\")  # Organize and rename the future climate data, structuring it by year and GCM. # The 'SoilType' variable will be appended as a static variable in each scenario. # The files will be renamed following the \"bio_\" format organize_future_worldclim(input_dir = in_dir, output_dir = out_dir_future,                           name_format = \"bio_\", fixed_variables = var$SoilType) #>    |                                                                               |                                                                      |   0%   |                                                                               |=========                                                             |  12%   |                                                                               |==================                                                    |  25%   |                                                                               |==========================                                            |  38%   |                                                                               |===================================                                   |  50%   |                                                                               |============================================                          |  62%   |                                                                               |====================================================                  |  75%   |                                                                               |=============================================================         |  88%   |                                                                               |======================================================================| 100% #>  #> Variables successfully organized in directory: #> /tmp/RtmpraqRyK/Future_raw1  # Prepare projections pr <- prepare_projection(variable_names = c(\"bio_1\", \"bio_7\", \"bio_12\",                                             \"bio_15\", \"SoilType\"),                          future_dir = out_dir_future,                          future_period = c(\"2041-2060\", \"2081-2100\"),                          future_pscen = c(\"ssp126\", \"ssp585\"),                          future_gcm = c(\"ACCESS-CM2\", \"MIROC6\"),                          raster_pattern = \".tif*\")  # Create folder to save projection results out_dir <- file.path(tempdir(), \"PCA_projections\") dir.create(out_dir, recursive = TRUE)  # Perform and project PCA for new scenarios (future) proj_pca <- perform_pca(raster_variables = var, exclude_from_pca = \"SoilType\",                         project = TRUE, projection_data = pr,                         out_dir = out_dir, center = TRUE, scale = TRUE)  proj_pca$projection_directory  # Directory with projected PCA-variables #> [1] \"/tmp/RtmpraqRyK/PCA_projections\""},{"path":"https://marlonecobos.github.io/kuenm2/reference/plot_explore_calibration.html","id":null,"dir":"Reference","previous_headings":"","what":"Histograms to visualize data from explore_calibration objects — plot_explore_calibration","title":"Histograms to visualize data from explore_calibration objects — plot_explore_calibration","text":"Plots histograms visualize data explore_calibration object generated explore_calibration_hist function.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/plot_explore_calibration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Histograms to visualize data from explore_calibration objects — plot_explore_calibration","text":"","code":"plot_explore_calibration(explore_calibration, color_m = \"grey\",                          color_background = \"#56B4E9\",                          color_presence = \"#009E73\", alpha = 0.4,                          lines = FALSE, which_lines = c(\"cl\", \"mean\"),                          lty_range = 1, lty_cl = 2, lty_mean = 3,                          lwd_range = 3, lwd_cl = 2, lwd_mean = 2,                          xlab = NULL, ylab = NULL, mfrow = NULL)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/plot_explore_calibration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Histograms to visualize data from explore_calibration objects — plot_explore_calibration","text":"explore_calibration object class explore_calibration generated explore_calibration_hist function. color_m (character) color used fill histogram bars entire area (M). Default \"grey\". color_background (character) color used fill histogram bars background data. Default \"#56B4E9\". color_presence (character) color used fill histogram bars presence data. Default \"#009E73\". alpha (numeric) opacity factor fill bars, typically range 0-1. Default 0.4. lines (logical) whether add vertical lines plot representing range, confidence interval, mean variables. Default = FALSE. which_lines (character) vector indicating lines plot. Available options \"range\", \"cl\" (confidence interval), \"mean\". Default c(\"range\", \"cl\", \"mean\"). lty_range (numeric) line type plotting ranges variables. Default 1, meaning solid line. lty_cl (numeric) line type plotting confidence interval variables. Default 2, meaning dashed line. lty_mean (numeric) line type plotting mean variables. Default 3, meaning dotted line. lwd_range (numeric) line width line representing range. Default 3. lwd_cl (numeric) line width line representing confidence interval. Default 2. lwd_mean (numeric) line width line representing mean. Default 2. xlab (character) vector names labeling x-axis. must length number variables. Default NULL, meaning labels extracted explore_calibration object. ylab (character) label y-axis. Default NULL, meaning y-axis labeled \"Frequency\". mfrow (numeric) vector specifying number rows columns plot layout, e.g., c(rows, columns). Default NULL, meaning grid arranged automatically based number plots.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/plot_explore_calibration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Histograms to visualize data from explore_calibration objects — plot_explore_calibration","text":"","code":"# Import raster layers var <- terra::rast(system.file(\"extdata\", \"Current_variables.tif\",                                package = \"kuenm2\"))  # Import occurrences data(sp_swd_cat, package = \"kuenm2\")  # Explore calibration data calib_hist <- explore_calibration_hist(data = sp_swd_cat,                                        raster_variables = var,                                        include_m = TRUE)  # Plot histograms plot_explore_calibration(explore_calibration = calib_hist, mfrow = c(2, 3))"},{"path":"https://marlonecobos.github.io/kuenm2/reference/plot_importance.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary plot for variable importance in models — plot_importance","title":"Summary plot for variable importance in models — plot_importance","text":"See details plot_importance","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/plot_importance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary plot for variable importance in models — plot_importance","text":"","code":"plot_importance(x, xlab = NULL, ylab = \"Relative contribution\",                 main = \"Variable importance\", extra_info = TRUE, ...)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/plot_importance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary plot for variable importance in models — plot_importance","text":"x data.frame output variable_importance(). xlab (character) label x axis. ylab (character) label y axis. main (character) main title plot. extra_info (logical) results one model, adds information number models using predictor mean contribution found. ... additional arguments passed barplot boxplot. Value barplot boxplot depending number models considered.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict method for glmnet_mx (maxnet) models — predict","title":"Predict method for glmnet_mx (maxnet) models — predict","text":"Predict method glmnet_mx (maxnet) models","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict method for glmnet_mx (maxnet) models — predict","text":"","code":"predict.glmnet_mx(object, newdata, clamp = FALSE,                   type = c(\"link\", \"exponential\", \"cloglog\", \"logistic\",                   \"cumulative\"))"},{"path":"https://marlonecobos.github.io/kuenm2/reference/predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict method for glmnet_mx (maxnet) models — predict","text":"object glmnet_mx object. newdata data predict . clamp (logical) whether clamp predictions. Default = FALSE. type (character) type prediction performed. Options : \"link\", \"exponential\", \"cloglog\", \"logistic\", cumulative. Defaults \"link\" defined.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict method for glmnet_mx (maxnet) models — predict","text":"glmnet_mx (maxnet) prediction.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/predict_selected.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict selected models for a single scenario — predict_selected","title":"Predict selected models for a single scenario — predict_selected","text":"function predicts selected models single set new data using either maxnet glm provides options save output compute consensus results (mean, median, etc.) across replicates models.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/predict_selected.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict selected models for a single scenario — predict_selected","text":"","code":"predict_selected(models, raster_variables, mask = NULL, write_files = FALSE,                  write_replicates = FALSE, out_dir = NULL,                  consensus_per_model = TRUE, consensus_general = TRUE,                  consensus = c(\"median\", \"range\", \"mean\", \"stdev\"),                  extrapolation_type = \"E\", var_to_clamp = NULL,                  type = NULL, overwrite = FALSE, progress_bar = TRUE)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/predict_selected.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict selected models for a single scenario — predict_selected","text":"models object class fitted_models returned fit_selected() function. raster_variables SpatRaster data.frame predictor variables. names variables must match used calibrate models used run PCA do_pca = TRUE prepare_data() function. mask (SpatRaster, SpatVector, SpatExtent) spatial object used mask variables predict. Default NULL. write_files (logical) whether save predictions (SpatRasters data.frame) disk. Default FALSE. write_replicates (logical) whether save predictions replicate disk. applicable write_files TRUE. Default FALSE. out_dir (character) directory path predictions saved. relevant write_files = TRUE. consensus_per_model (logical) whether compute consensus (mean, median, etc.) model across replicates. Default TRUE. consensus_general (logical) whether compute general consensus across models. Default TRUE. consensus (character) vector specifying types consensus calculate across replicates models. Available options \"median\", \"range\", \"mean\", \"stdev\" (standard deviation). Default c(\"median\", \"range\", \"mean\", \"stdev\"). extrapolation_type (character) extrapolation type model. Models can transferred three options: free extrapolation ('E'), extrapolation clamping ('EC'), extrapolation ('NE'). Default = 'E'. See details. var_to_clamp (character) vector specifying variables clamp extrapolate. applicable extrapolation_type \"EC\" \"NE\". Default NULL, meaning variables clamped extrapolated. type (character) format prediction values. maxnet models, valid options \"raw\", \"cumulative\", \"logistic\", \"cloglog\". glm models, valid options \"response\" \"raw\". NULL (default), function uses \"cloglog\" maxnet models \"response\" glm models. overwrite (logical) whether overwrite SpatRasters already exist. applicable write_files = TRUE. Default FALSE. progress_bar (logical) whether display progress bar processing. Default TRUE.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/predict_selected.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict selected models for a single scenario — predict_selected","text":"list containing SpatRaster data.frames predictions replicate, long consensus results model overall general consensus.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/predict_selected.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predict selected models for a single scenario — predict_selected","text":"predicting areas variables beyond lower upper limits calibration data, users can choose free extrapolate predictions (extrapolation_type = \"E\"), extrapolate clamping (extrapolation_type = \"EC\"), extrapolate (extrapolation_type = \"NE\"). clamping, variables set minimum maximum values established maximum minimum values within calibration data. extrapolation approach, cell least one variable listed var_to_clamp falling outside calibration range assigned suitability value 0.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/predict_selected.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict selected models for a single scenario — predict_selected","text":"","code":"# Import variables to predict on var <- terra::rast(system.file(\"extdata\", \"Current_variables.tif\",                                package = \"kuenm2\"))  # Example with maxnet # Import example of fitted_models (output of fit_selected()) data(\"fitted_model_maxnet\", package = \"kuenm2\")  # Predict to single scenario p <- predict_selected(models = fitted_model_maxnet, raster_variables = var) #>    |                                                                               |                                                                      |   0%   |                                                                               |===================================                                   |  50%   |                                                                               |======================================================================| 100%  # Example with GLMs # Import example of fitted_models (output of fit_selected()) data(\"fitted_model_glm\", package = \"kuenm2\")  # Predict to single scenario p_glm <- predict_selected(models = fitted_model_glm, raster_variables = var) #>    |                                                                               |                                                                      |   0%   |                                                                               |======================================================================| 100%  # Plot predictions terra::plot(c(p$General_consensus$median, p_glm$General_consensus$median),             col = rev(terrain.colors(240)), main = c(\"MAXNET\", \"GLM\"),             zlim = c(0, 1))"},{"path":"https://marlonecobos.github.io/kuenm2/reference/prepare_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare data for model calibration — prepare_data","title":"Prepare data for model calibration — prepare_data","text":"function prepares data model calibration, including optional PCA, background point generation, k-fold partitioning, creation grid parameter combinations, including regularization multiplier values, feature classes, sets environmental variables.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/prepare_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare data for model calibration — prepare_data","text":"","code":"prepare_data(algorithm, occ, x, y, raster_variables, species = NULL,              mask = NULL, n_background = 1000, features = c(\"lq\", \"lqp\"),              r_multiplier = c(0.1, 0.5, 1, 2, 3), kfolds = 4,              categorical_variables = NULL, do_pca = FALSE, center = TRUE,              scale = TRUE, exclude_from_pca = NULL, variance_explained = 95,              min_explained = 5, min_number = 2, min_continuous = NULL,              bias_file = NULL, bias_effect = NULL, weights = NULL,              include_xy = TRUE, write_pca = FALSE, pca_directory = NULL,              write_file = FALSE, file_name = NULL, seed = 1)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/prepare_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare data for model calibration — prepare_data","text":"algorithm (character) modeling algorithm, either \"glm\" \"maxnet\". occ (data frame) data.frame containing coordinates (longitude latitude) occurrence records. x (character) string specifying name column occ contains longitude values. y (character) string specifying name column occ contains latitude values. raster_variables (SpatRaster) predictor variables used calibrate models. species (character) string specifying species name (optional). Default NULL. mask spatial object used mask variables area model calibrated. Mask must one following classes: SpatRaster, SpatVector, SpatExtent. Default NULL. n_background (numeric) number points represent background model. Default 1000. features (character) vector feature classes. Default c(\"q\", \"lq\", \"lp\", \"qp\", \"lqp\"). r_multiplier (numeric) vector regularization parameters maxnet. Default c(0.1, 1, 2, 3, 5). kfolds (numeric) number groups (folds) occurrence data split cross-validation. Default 4. categorical_variables (character) names variables categorical. Default NULL. do_pca (logical) whether perform principal component analysis (PCA) set variables. Default FALSE. center (logical) whether variables zero-centered. Default TRUE. scale (logical) whether variables scaled unit variance analysis takes place. Default FALSE. exclude_from_pca (character) variable names within raster_variables included PCA transformation. Instead, variables added directly final set output variables without modified. default NULL, meaning variables used unless specified otherwise. variance_explained (numeric) cumulative percentage total variance must explained selected principal components. Default 95. min_explained (numeric) minimum percentage total variance principal component must explain retained. Default 5. min_number (numeric) minimum number variables included model formulas generated. min_continuous (numeric) minimum number continuous variables required combination. Default NULL. bias_file (SpatRaster) raster containing bias values (probability weights) influence selection background points. must extent, resolution, number cells raster variables, unless mask provided. Default NULL. bias_effect (character) string specifying values bias_file interpreted. Options \"direct\" \"inverse\". \"direct\", higher values bias file increase likelihood selecting background points. \"inverse\", higher values decrease likelihood. Default = NULL. Must defined bias_file provided. weights (numeric) numeric vector specifying weights occurrence records. Default NULL. include_xy (logical) whether include coordinates (longitude latitude) results preparing data. Columns containing coordinates renamed \"x\" \"y\". Default TRUE. write_pca (logical) whether save PCA-derived raster layers (principal components) disk. Default FALSE. pca_directory (character) path name folder PC raster layers saved. applicable write_pca = TRUE. Default NULL. write_file (logical) whether write resulting prepared_data list local directory. Default FALSE. file_name (character) path name folder resulting list saved. applicable write_file = TRUE. Default NULL. seed (numeric) integer value specify initial seed split data extract background. Default 1.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/prepare_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare data for model calibration — prepare_data","text":"object class prepared_data containing elements run model calibration routine. elements include: species, calibration data, grid model parameters, indices k-folds cross validation, xy coordinates, names continuous categorical variables, weights, results PCA, modeling algorithm.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/prepare_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare data for model calibration — prepare_data","text":"","code":"# Import occurrences data(occ_data, package = \"kuenm2\")  # Import raster layers var <- terra::rast(system.file(\"extdata\", \"Current_variables.tif\",                                package = \"kuenm2\"))  # Import a bias file bias <- terra::rast(system.file(\"extdata\", \"bias_file.tif\",                                 package = \"kuenm2\"))  # Prepare data for maxnet model sp_swd <- prepare_data(algorithm = \"maxnet\", occ = occ_data,                        x = \"x\", y = \"y\",                        raster_variables = var,                        species = occ_data[1, 1],                        categorical_variables = \"SoilType\",                        n_background = 500, bias_file = bias,                        bias_effect = \"direct\",                        features = c(\"l\", \"q\", \"p\", \"lq\", \"lqp\"),                        r_multiplier = c(0.1, 1, 2, 3, 5)) #> Warning: 27 rows were excluded from database because NAs were found. print(sp_swd) #> prepared_data object summary #> ============================ #> Species: Myrcia hatschbachii  #> Number of Records: 524  #>   - Presence: 51  #>   - Background: 473  #> Training-Testing Method: #>   - k-fold Cross-validation: 4 folds #> Continuous Variables: #>   - bio_1, bio_7, bio_12, bio_15  #> Categorical Variables: #>   - SoilType  #> PCA Information: PCA not performed #> Weights: No weights provided #> Calibration Parameters: #>   - Algorithm: maxnet  #>   - Number of candidate models: 610  #>   - Features classes (responses): l, q, p, lq, lqp  #>   - Regularization multipliers: 0.1, 1, 2, 3, 5   # Prepare data for glm model sp_swd_glm <- prepare_data(algorithm = \"glm\", occ = occ_data,                            x = \"x\", y = \"y\",                            raster_variables = var,                            species = occ_data[1, 1],                            categorical_variables = \"SoilType\",                            n_background = 500, bias_file = bias,                            bias_effect = \"direct\",                            features = c(\"l\", \"q\", \"p\", \"lq\", \"lqp\")) #> Warning: 27 rows were excluded from database because NAs were found. print(sp_swd_glm) #> prepared_data object summary #> ============================ #> Species: Myrcia hatschbachii  #> Number of Records: 524  #>   - Presence: 51  #>   - Background: 473  #> Training-Testing Method: #>   - k-fold Cross-validation: 4 folds #> Continuous Variables: #>   - bio_1, bio_7, bio_12, bio_15  #> Categorical Variables: #>   - SoilType  #> PCA Information: PCA not performed #> Weights: No weights provided #> Calibration Parameters: #>   - Algorithm: glm  #>   - Number of candidate models: 122  #>   - Features classes (responses): l, q, p, lq, lqp"},{"path":"https://marlonecobos.github.io/kuenm2/reference/prepare_projection.html","id":null,"dir":"Reference","previous_headings":"","what":"Preparation of data for model projections — prepare_projection","title":"Preparation of data for model projections — prepare_projection","text":"function prepared data model projections multiple scenarios, storing paths rasters representing scenario.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/prepare_projection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preparation of data for model projections — prepare_projection","text":"","code":"prepare_projection(models = NULL, variable_names = NULL, present_dir = NULL,                    past_dir = NULL, past_period = NULL, past_gcm = NULL,                    future_dir = NULL, future_period = NULL,                    future_pscen = NULL, future_gcm = NULL,                    write_file = FALSE, filename = NULL,                    raster_pattern = \".tif*\")"},{"path":"https://marlonecobos.github.io/kuenm2/reference/prepare_projection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preparation of data for model projections — prepare_projection","text":"models object class fitted_models returned fit_selected() function. Default NULL. variable_names (character) names variables used fit model PCA prepare_data() function. applicable models argument provided. Default NULL. present_dir (character) path folder containing variables represent current scenario projection. Default NULL. past_dir (character) path folder containing subfolders v ariables representing past scenarios projection. Default NULL. past_period (character) names subfolders within past_dir, representing specific time periods (e.g., 'LGM' 'MID'). past_gcm (character) names subfolders within past_period folders, representing specific General Circulation Models (GCMs). future_dir (character) path folder containing subfolders variables representing future scenarios projection. Default NULL. future_period (character) names subfolders within future_dir, representing specific time periods (e.g., '2041-2060' '2081-2100'). Default NULL. future_pscen (character) names subfolders within future_period, representing specific emission scenarios (e.g., 'ssp126' 'ssp585'). Default NULL. future_gcm (character) names subfolders within future_pscen folders, representing specific General Circulation Models (GCMs). Default NULL. write_file (logical) whether write object containing paths structured folders. object required projecting models across multiple scenarios using project_selected() function. Default FALSE. filename (character) path name folder object saved. applicable write_file = TRUE. Default NULL. raster_pattern (character) pattern used identify format raster files within folders. Default \".tif*\".","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/prepare_projection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preparation of data for model projections — prepare_projection","text":"object class prepared_projection containing following elements: Present, Past, Future: paths variables structured subfolders. Raster_pattern: pattern used identify format raster files within folders. PCA: principal component analysis (PCA) performed set variables prepare_data(), list class \"prcomp\" returned. See ?stats::prcomp() details. variables: names raw predictos variables used project.","code":""},{"path":[]},{"path":"https://marlonecobos.github.io/kuenm2/reference/prepare_projection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preparation of data for model projections — prepare_projection","text":"","code":"# Import example of fitted_models (output of fit_selected()) data(\"fitted_model_maxnet\", package = \"kuenm2\")  # Organize and structure future climate variables from WorldClim # Import the current variables used to fit the model. # In this case, SoilType will be treated as a static variable (constant # across future scenarios). var <- terra::rast(system.file(\"extdata\", \"Current_variables.tif\",                                package = \"kuenm2\"))  # Create a \"Current_raw\" folder in a temporary directory and copy the raw # variables there. out_dir_current <- file.path(tempdir(), \"Current_raw\") dir.create(out_dir_current, recursive = TRUE)  # Save current variables in temporary directory terra::writeRaster(var, file.path(out_dir_current, \"Variables.tif\"))  # Set the input directory containing the raw future climate variables. # For this example, the data is located in the \"inst/extdata\" folder. in_dir <- system.file(\"extdata\", package = \"kuenm2\")  # Create a \"Future_raw\" folder in a temporary directory and copy the raw # variables there. out_dir_future <- file.path(tempdir(), \"Future_raw\")  # Organize and rename the future climate data, structuring it by year and GCM. # The 'SoilType' variable will be appended as a static variable in each scenario. # The files will be renamed following the \"bio_\" format organize_future_worldclim(input_dir = in_dir,                           output_dir = out_dir_future,                           name_format = \"bio_\", variables = NULL,                           fixed_variables = var$SoilType, mask = NULL,                           overwrite = TRUE) #>    |                                                                               |                                                                      |   0%   |                                                                               |=========                                                             |  12%   |                                                                               |==================                                                    |  25%   |                                                                               |==========================                                            |  38%   |                                                                               |===================================                                   |  50%   |                                                                               |============================================                          |  62%   |                                                                               |====================================================                  |  75%   |                                                                               |=============================================================         |  88%   |                                                                               |======================================================================| 100% #>  #> Variables successfully organized in directory: #> /tmp/RtmpraqRyK/Future_raw  # Prepare projections using fitted models to check variables pr <- prepare_projection(models = fitted_model_maxnet,                          present_dir = out_dir_current,                          past_dir = NULL,                          past_period = NULL,                          past_gcm = NULL,                          future_dir = out_dir_future,                          future_period = c(\"2041-2060\", \"2081-2100\"),                          future_pscen = c(\"ssp126\", \"ssp585\"),                          future_gcm = c(\"ACCESS-CM2\", \"MIROC6\"),                          write_file = FALSE,                          filename = NULL,                          raster_pattern = \".tif*\") pr #> projection_data object summary #> ============================= #> Variables prepared to project models for Present and Future  #> Future projections contain the following periods, scenarios and GCMs: #>   - Periods: 2041-2060 | 2081-2100  #>   - Scenarios: ssp126 | ssp585  #>   - GCMs: ACCESS-CM2 | MIROC6  #> All variables are located in the following root directory: #> /tmp/RtmpraqRyK  # Prepare projections using variables names pr_b <- prepare_projection(models = NULL,                            variable_names = c(\"bio_1\", \"bio_7\", \"bio_12\"),                            present_dir = out_dir_current,                            past_dir = NULL,                            past_period = NULL,                            past_gcm = NULL,                            future_dir = out_dir_future,                            future_period = c(\"2041-2060\", \"2081-2100\"),                            future_pscen = c(\"ssp126\", \"ssp585\"),                            future_gcm = c(\"ACCESS-CM2\", \"MIROC6\"),                            write_file = FALSE,                            filename = NULL,                            raster_pattern = \".tif*\") pr_b #> projection_data object summary #> ============================= #> Variables prepared to project models for Present and Future  #> Future projections contain the following periods, scenarios and GCMs: #>   - Periods: 2041-2060 | 2081-2100  #>   - Scenarios: ssp126 | ssp585  #>   - GCMs: ACCESS-CM2 | MIROC6  #> All variables are located in the following root directory: #> /tmp/RtmpraqRyK"},{"path":"https://marlonecobos.github.io/kuenm2/reference/prepare_user_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare data for model calibration with user-prepared calibration data — prepare_user_data","title":"Prepare data for model calibration with user-prepared calibration data — prepare_user_data","text":"function prepares data model calibration using user-prepared calibration data. includes optional PCA, k-fold partitioning, creation grid parameter combinations, including distinct regularization multiplier values, various feature classes, different sets environmental variables.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/prepare_user_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare data for model calibration with user-prepared calibration data — prepare_user_data","text":"","code":"prepare_user_data(algorithm, user_data, pr_bg, species = NULL, x = NULL,                   y = NULL, features = c(\"lq\", \"lqp\"),                   r_multiplier = c(0.1, 0.5, 1, 2, 3), kfolds = 4,                   user_folds = NULL, categorical_variables = NULL, do_pca = FALSE,                   center = TRUE, scale = TRUE, exclude_from_pca = NULL,                   variance_explained = 95, min_explained = 5,                   min_number = 2, min_continuous = NULL, weights = NULL,                   include_xy = TRUE, write_pca = FALSE, pca_directory = NULL,                   write_file = FALSE, file_name = NULL, seed = 1)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/prepare_user_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare data for model calibration with user-prepared calibration data — prepare_user_data","text":"algorithm (character) modeling algorithm, either \"glm\" \"maxnet\". user_data (data frame) data.frame column presence (1) background (0) records, together variable values (one variable per column). See example data(\"user_data\", package = \"kuenm2\"). pr_bg (character) name column user_data contains presence/background records. species (character) string specifying species name (optional). Default NULL. x (character) string specifying name column user_data contains longitude values. Default NULL. Must defined present user_data otherwise considered another predictor variable. y (character) string specifying name column user_data contains latitude values. Default NULL. Must defined present user_data otherwise considered another predictor variable. features (character) vector feature classes. Default c(\"q\", \"lq\", \"lp\", \"qp\", \"lqp\"). r_multiplier (numeric) vector regularization parameters maxnet. Default c(0.1, 1, 2, 3, 5). kfolds (numeric) number groups (folds) occurrence data split cross-validation. Default 4. user_folds user provided list folds cross-validation used model calibration. element list contains indices split use_data training testing sets. categorical_variables (character) names variables categorical. Default NULL. do_pca (logical) whether perform principal component analysis (PCA) set variables. Default FALSE. center (logical) whether variables zero-centered. Default TRUE. scale (logical) whether variables scaled unit variance analysis takes place. Default FALSE. exclude_from_pca (character) variable names within raster_variables included PCA transformation. Instead, variables added directly final set output variables without modified. default NULL, meaning variables used unless specified otherwise. variance_explained (numeric) cumulative percentage total variance must explained selected principal components. Default 95. min_explained (numeric) minimum percentage total variance principal component must explain retained. Default 5. min_number (numeric) minimum number variables included model formulas generated. min_continuous (numeric) minimum number continuous variables required combination. Default NULL. weights (numeric) numeric vector specifying weights occurrence records. Default NULL. include_xy (logical) whether include coordinates (longitude latitude) results preparing data. Default TRUE. write_pca (logical) whether save PCA-derived raster layers (principal components) disk. Default FALSE. pca_directory (character) path name folder PC raster layers saved. applicable write_pca = TRUE. Default NULL. write_file (logical) whether write resulting prepared_data list local directory. Default FALSE. file_name (character) path name folder resulting list saved. applicable write_file = TRUE. Default NULL. seed (numeric) integer value specify initial seed split data. Default 1.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/prepare_user_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare data for model calibration with user-prepared calibration data — prepare_user_data","text":"object class prepared_data containing elements run model calibration routine. elements include: species, calibration data, grid model parameters, indices k-folds cross validation, xy coordinates, names continuous categorical variables, weights, results PCA, modeling algorithm.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/prepare_user_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare data for model calibration with user-prepared calibration data — prepare_user_data","text":"","code":"# Import user-prepared data data(\"user_data\", package = \"kuenm2\")  # Prepare data for maxnet model maxnet_swd_user <- prepare_user_data(algorithm = \"maxnet\",                                      user_data = user_data, pr_bg = \"pr_bg\",                                      species = \"Myrcia hatschbachii\",                                      categorical_variables = \"SoilType\",                                      features = c(\"l\", \"q\", \"p\", \"lq\", \"lqp\"),                                      r_multiplier = c(0.1, 1, 2, 3, 5)) maxnet_swd_user #> prepared_data object summary #> ============================ #> Species: Myrcia hatschbachii  #> Number of Records: 527  #>   - Presence: 51  #>   - Background: 476  #> Training-Testing Method: #>   - k-fold Cross-validation: 4 folds #> Continuous Variables: #>   - bio_1, bio_7, bio_12, bio_15  #> Categorical Variables: #>   - SoilType  #> PCA Information: PCA not performed #> Weights: No weights provided #> Calibration Parameters: #>   - Algorithm: maxnet  #>   - Number of candidate models: 610  #>   - Features classes (responses): l, q, p, lq, lqp  #>   - Regularization multipliers: 0.1, 1, 2, 3, 5   # Prepare data for glm model glm_swd_user <- prepare_user_data(algorithm = \"glm\",                                   user_data = user_data, pr_bg = \"pr_bg\",                                   species = \"Myrcia hatschbachii\",                                   categorical_variables = \"SoilType\",                                   features = c(\"l\", \"q\", \"p\", \"lq\", \"lqp\")) glm_swd_user #> prepared_data object summary #> ============================ #> Species: Myrcia hatschbachii  #> Number of Records: 527  #>   - Presence: 51  #>   - Background: 476  #> Training-Testing Method: #>   - k-fold Cross-validation: 4 folds #> Continuous Variables: #>   - bio_1, bio_7, bio_12, bio_15  #> Categorical Variables: #>   - SoilType  #> PCA Information: PCA not performed #> Weights: No weights provided #> Calibration Parameters: #>   - Algorithm: glm  #>   - Number of candidate models: 122  #>   - Features classes (responses): l, q, p, lq, lqp"},{"path":"https://marlonecobos.github.io/kuenm2/reference/print.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for kuenm2 objects — print","title":"Print method for kuenm2 objects — print","text":"Print method kuenm2 objects","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/print.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for kuenm2 objects — print","text":"","code":"# S3 method for class 'prepared_data' print(x, ...)  # S3 method for class 'calibration_results' print(x, ...)  # S3 method for class 'fitted_models' print(x, ...)  # S3 method for class 'projection_data' print(x, ...)  # S3 method for class 'model_projections' print(x, ...)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/print.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for kuenm2 objects — print","text":"x object classes: prepared_data, calibration_results, fitted_models, projection_data, model_projections. ... additional arguments affecting summary produced. Ignored functions.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/print.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for kuenm2 objects — print","text":"printed version object summarizes main elements contained.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/project_selected.html","id":null,"dir":"Reference","previous_headings":"","what":"Project selected models to multiple sets of new data (scenarios) — project_selected","title":"Project selected models to multiple sets of new data (scenarios) — project_selected","text":"function performs predictions selected models multiple scenarios, specified projection_data object created prepare_projection() function. addition generating predictions replicate, function calculates consensus measures (e.g., mean, median) across replicates models.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/project_selected.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project selected models to multiple sets of new data (scenarios) — project_selected","text":"","code":"project_selected(models, projection_data, out_dir, mask = NULL,                  consensus_per_model = TRUE, consensus_general = TRUE,                  consensus = c(\"median\", \"range\", \"mean\", \"stdev\"),                  write_replicates = FALSE, extrapolation_type = \"E\",                  var_to_clamp = NULL, type = NULL, overwrite = FALSE,                  parallel = FALSE, ncores = NULL,                  progress_bar = TRUE, verbose = TRUE)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/project_selected.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project selected models to multiple sets of new data (scenarios) — project_selected","text":"models object class fitted_models returned fit_selected() function. projection_data object class projection_data returned prepare_projection() function. file contains paths rasters representing scenario. out_dir (character) path root directory saving raster file projection. mask (SpatRaster, SpatVector, SpatExtent) spatial object used mask variables predict. Default NULL. consensus_per_model (logical) whether calculate consensus across replicates one replicate per model. Default TRUE. consensus_general (logical) whether calculate consensus across models one selected model. Default TRUE. consensus (character) consensus measures calculate. Options available 'median', 'range', 'mean' 'stdev' (standard deviation). Default c(\"median\", \"range\", \"mean\", \"stdev\"). write_replicates (logical) whether write projections replicate. Default FALSE. extrapolation_type (character) extrapolation type model. Models can transferred three options: free extrapolation ('E'), extrapolation clamping ('EC'), extrapolation ('NE'). Default = 'E'. See details. var_to_clamp (character) vector specifying variables clamp. applicable extrapolation_type \"EC\" \"NE\". Default NULL, meaning variables clamped extrapolated. type (character) format prediction values. maxnet models, valid options \"raw\", \"cumulative\", \"logistic\", \"cloglog\". glm models, valid options \"response\" \"raw\". NULL (default), function uses \"cloglog\" maxnet models \"response\" glm models. overwrite (logical) whether overwrite SpatRaster already exists. applicable write_files set TRUE. Default FALSE. parallel (logical) whether fit candidate models parallel. Default FALSE. ncores (numeric) number cores use parallel processing. Default NULL uses available cores - 1. applicable parallel = TRUE. progress_bar (logical) whether display progress bar processing. Default TRUE. verbose (logical) whether display messages processing. Default TRUE.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/project_selected.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Project selected models to multiple sets of new data (scenarios) — project_selected","text":"model_projections object provides paths raster files projection results corresponding thresholds used binarize predictions.","code":""},{"path":[]},{"path":"https://marlonecobos.github.io/kuenm2/reference/project_selected.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Project selected models to multiple sets of new data (scenarios) — project_selected","text":"","code":"# Step 1: Organize variables for current projection ## Import current variables (used to fit models) var <- terra::rast(system.file(\"extdata\", \"Current_variables.tif\",                                package = \"kuenm2\"))  ## Create a folder in a temporary directory to copy the variables out_dir_current <- file.path(tempdir(), \"Current_raw_wc\") dir.create(out_dir_current, recursive = TRUE)  ## Save current variables in temporary directory terra::writeRaster(var, file.path(out_dir_current, \"Variables.tif\"))   # Step 2: Organize future climate variables (example with WorldClim) ## Directory containing the downloaded future climate variables (example) in_dir <- system.file(\"extdata\", package = \"kuenm2\")  ## Create a folder in a temporary directory to copy the future variables out_dir_future <- file.path(tempdir(), \"Future_raw_wc\")  ## Organize and rename the future climate data (structured by year and GCM) ### 'SoilType' will be appended as a static variable in each scenario organize_future_worldclim(input_dir = in_dir, output_dir = out_dir_future,                           name_format = \"bio_\", fixed_variables = var$SoilType) #>    |                                                                               |                                                                      |   0%   |                                                                               |=========                                                             |  12%   |                                                                               |==================                                                    |  25%   |                                                                               |==========================                                            |  38%   |                                                                               |===================================                                   |  50%   |                                                                               |============================================                          |  62%   |                                                                               |====================================================                  |  75%   |                                                                               |=============================================================         |  88%   |                                                                               |======================================================================| 100% #>  #> Variables successfully organized in directory: #> /tmp/RtmpraqRyK/Future_raw_wc  # Step 3: Prepare data to run multiple projections ## An example with maxnet models ## Import example of fitted_models (output of fit_selected()) data(fitted_model_maxnet, package = \"kuenm2\")  ## Prepare projection data using fitted models to check variables pr <- prepare_projection(models = fitted_model_maxnet,                          present_dir = out_dir_current,                          future_dir = out_dir_future,                          future_period = c(\"2041-2060\", \"2081-2100\"),                          future_pscen = c(\"ssp126\", \"ssp585\"),                          future_gcm = c(\"ACCESS-CM2\", \"MIROC6\"),                          raster_pattern = \".tif*\")  # Step 4: Run multiple model projections ## A folder to save projection results out_dir <- file.path(tempdir(), \"Projection_results/maxnet_projections\") dir.create(out_dir, recursive = TRUE)  ## Project selected models to multiple scenarios p <- project_selected(models = fitted_model_maxnet, projection_data = pr,                       out_dir = out_dir) #>    |                                                                               |                                                                      |   0%   |                                                                               |========                                                              |  11%   |                                                                               |================                                                      |  22%   |                                                                               |=======================                                               |  33%   |                                                                               |===============================                                       |  44%   |                                                                               |=======================================                               |  56%   |                                                                               |===============================================                       |  67%   |                                                                               |======================================================                |  78%   |                                                                               |==============================================================        |  89%   |                                                                               |======================================================================| 100%"},{"path":"https://marlonecobos.github.io/kuenm2/reference/projection_changes.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute changes of suitable areas between scenarios — projection_changes","title":"Compute changes of suitable areas between scenarios — projection_changes","text":"function performs map algebra operations represent suitable areas change compared scenario model trained. Changes identified loss (contraction), gain (expansion) stability. multiple climate models (GCM) used, calculates level agreement among emission scenario.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/projection_changes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute changes of suitable areas between scenarios — projection_changes","text":"","code":"projection_changes(model_projections, reference_id = 1, consensus = \"median\",                    include_id = NULL, user_threshold = NULL, by_gcm = TRUE,                    by_change = TRUE, general_summary = TRUE,                    force_resample = TRUE, write_results = TRUE,                    output_dir = NULL, overwrite = FALSE,                    write_bin_models = FALSE, return_raster = FALSE)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/projection_changes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute changes of suitable areas between scenarios — projection_changes","text":"model_projections model_projections object generated project_selected() function. object contains file paths raster projection results thresholds used binarization predictions. reference_id (numeric) reference ID projections corresponding current time model_projections. Default 1. See details section information. consensus (character) consensus measure use calculating changes. Available options 'mean', 'median', 'range', 'stdev' (standard deviation). Default 'median'. include_id (numeric) vector containing reference IDs include computing changes. Default NULL, meaning projections included. See details section information. user_threshold (numeric) optional threshold binarizing predictions. Default NULL, meaning function apply thresholds stored model_projections, calculated earlier using omission rate calibration(). by_gcm (logical) whether compute changes across GCMs. Default TRUE. by_change (logical) whether compute results separately change, identifying areas gain, loss, stability GCM. Default TRUE. general_summary (logical) whether generate general summary, mapping many GCMs project gain, loss, stability scenario. Default TRUE. force_resample (logical) whether force projection rasters extent resolution raster corresponding reference_id, represents current projections. Default TRUE. write_results (logical) whether write raster files containing computed changes disk. Default TRUE. output_dir (character) directory path resulting raster files containing computed changes saved. relevant write_results = TRUE. overwrite (logical) whether overwrite SpatRaster already exist. applicable write_results set TRUE. Default FALSE. write_bin_models (logical) whether write binarized models GCM disk. Default FALSE. return_raster (logical) whether return list containing SpatRasters computed changes. Default FALSE, meaning function return NULL object. Setting argument TRUE using multiple GCMs large extent fine resolution may overload RAM.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/projection_changes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute changes of suitable areas between scenarios — projection_changes","text":"return_raster = TRUE,  function returns list containing SpatRasters computed changes. list includes following elements: Binarized: binarized models GCM. Results_by_gcm: computed changes GCM. Results_by_change: list SpatRaster represents specific change. Summary_changes: general summary indicates many GCMs project gain, loss, stability scenario return_raster = FALSE, function returns NULL object.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/projection_changes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute changes of suitable areas between scenarios — projection_changes","text":"comparing changes binarized prodictions time, four possible outcomes: Stable-Suitable: area remains suitable current projected times. Stable-Unsuitable: area remains unsuitable current projected times. Gain: area unsuitable current time becomes suitable projected time (indicating expansion). Loss: area suitable current time becomes unsuitable projected time (indicating contraction). reference scenario (current conditions) can accessed paths element model_projections object (model_projections$path). ID differ 1 one projection current conditions. Specific projections can included excluded analysis using include_id argument. example, setting 'include_id = c(3, 5, 7)' compute changes scenarios 3, 5, 7. Conversely, setting 'include_id = -c(3, 5, 7)' exclude scenarios 3, 5, 7 analysis.","code":""},{"path":[]},{"path":"https://marlonecobos.github.io/kuenm2/reference/projection_changes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute changes of suitable areas between scenarios — projection_changes","text":"","code":"# Step 1: Organize variables for current projection ## Import current variables (used to fit models) var <- terra::rast(system.file(\"extdata\", \"Current_variables.tif\",                                package = \"kuenm2\"))  ## Create a folder in a temporary directory to copy the variables out_dir_current <- file.path(tempdir(), \"Current_raw3\") dir.create(out_dir_current, recursive = TRUE)  ## Save current variables in temporary directory terra::writeRaster(var, file.path(out_dir_current, \"Variables.tif\"))   # Step 2: Organize future climate variables (example with WorldClim) ## Directory containing the downloaded future climate variables (example) in_dir <- system.file(\"extdata\", package = \"kuenm2\")  ## Create a folder in a temporary directory to copy the future variables out_dir_future <- file.path(tempdir(), \"Future_raw3\")  ## Organize and rename the future climate data (structured by year and GCM) ### 'SoilType' will be appended as a static variable in each scenario organize_future_worldclim(input_dir = in_dir, output_dir = out_dir_future,                           name_format = \"bio_\", fixed_variables = var$SoilType) #>    |                                                                               |                                                                      |   0%   |                                                                               |=========                                                             |  12%   |                                                                               |==================                                                    |  25%   |                                                                               |==========================                                            |  38%   |                                                                               |===================================                                   |  50%   |                                                                               |============================================                          |  62%   |                                                                               |====================================================                  |  75%   |                                                                               |=============================================================         |  88%   |                                                                               |======================================================================| 100% #>  #> Variables successfully organized in directory: #> /tmp/RtmpraqRyK/Future_raw3  # Step 3: Prepare data to run multiple projections ## An example with maxnet models ## Import example of fitted_models (output of fit_selected()) data(fitted_model_maxnet, package = \"kuenm2\")  ## Prepare projection data using fitted models to check variables pr <- prepare_projection(models = fitted_model_maxnet,                          present_dir = out_dir_current,                          future_dir = out_dir_future,                          future_period = c(\"2041-2060\", \"2081-2100\"),                          future_pscen = c(\"ssp126\", \"ssp585\"),                          future_gcm = c(\"ACCESS-CM2\", \"MIROC6\"),                          raster_pattern = \".tif*\")  # Step 4: Run multiple model projections ## A folder to save projection results out_dir <- file.path(tempdir(), \"Projection_results/maxnet1\") dir.create(out_dir, recursive = TRUE)  ## Project selected models to multiple scenarios p <- project_selected(models = fitted_model_maxnet, projection_data = pr,                       out_dir = out_dir) #>    |                                                                               |                                                                      |   0%   |                                                                               |========                                                              |  11%   |                                                                               |================                                                      |  22%   |                                                                               |=======================                                               |  33%   |                                                                               |===============================                                       |  44%   |                                                                               |=======================================                               |  56%   |                                                                               |===============================================                       |  67%   |                                                                               |======================================================                |  78%   |                                                                               |==============================================================        |  89%   |                                                                               |======================================================================| 100%  # Step 5: Identify areas of change in projections ## Contraction, expansion and stability changes <- projection_changes(model_projections = p, write_results = FALSE,                               return_raster = TRUE)  terra::plot(changes$Binarized)  # SpatRaster with the binarized predictions  terra::plot(changes$Results_by_gcm)  # SpatRaster with changes by GCM  changes$Results_by_change  # List of SpatRaster(s) by changes with GCM agreement #> $`Future_2041-2060_ssp126` #> class       : SpatRaster  #> size        : 52, 40, 4  (nrow, ncol, nlyr) #> resolution  : 0.1666667, 0.1666667  (x, y) #> extent      : -53.5, -46.83333, -30.83333, -22.16667  (xmin, xmax, ymin, ymax) #> coord. ref. : lon/lat WGS 84 (EPSG:4326)  #> source(s)   : memory #> names       :           Unsuitable-stable,           Gain,           Loss,           Suitable-stable  #> min values  : Unsuitable-stable in 0 GCMs, Gain in 0 GCMs, Loss in 0 GCMs, Suitable-stable in 0 GCMs  #> max values  : Unsuitable-stable in 2 GCMs, Gain in 2 GCMs, Loss in 2 GCMs, Suitable-stable in 2 GCMs  #>  #> $`Future_2041-2060_ssp585` #> class       : SpatRaster  #> size        : 52, 40, 4  (nrow, ncol, nlyr) #> resolution  : 0.1666667, 0.1666667  (x, y) #> extent      : -53.5, -46.83333, -30.83333, -22.16667  (xmin, xmax, ymin, ymax) #> coord. ref. : lon/lat WGS 84 (EPSG:4326)  #> source(s)   : memory #> names       :           Unsuitable-stable,           Gain,           Loss,           Suitable-stable  #> min values  : Unsuitable-stable in 0 GCMs, Gain in 0 GCMs, Loss in 0 GCMs, Suitable-stable in 0 GCMs  #> max values  : Unsuitable-stable in 2 GCMs, Gain in 2 GCMs, Loss in 2 GCMs, Suitable-stable in 2 GCMs  #>  #> $`Future_2081-2100_ssp126` #> class       : SpatRaster  #> size        : 52, 40, 4  (nrow, ncol, nlyr) #> resolution  : 0.1666667, 0.1666667  (x, y) #> extent      : -53.5, -46.83333, -30.83333, -22.16667  (xmin, xmax, ymin, ymax) #> coord. ref. : lon/lat WGS 84 (EPSG:4326)  #> source(s)   : memory #> names       :           Unsuitable-stable,           Gain,           Loss,           Suitable-stable  #> min values  : Unsuitable-stable in 0 GCMs, Gain in 0 GCMs, Loss in 0 GCMs, Suitable-stable in 0 GCMs  #> max values  : Unsuitable-stable in 2 GCMs, Gain in 2 GCMs, Loss in 2 GCMs, Suitable-stable in 2 GCMs  #>  #> $`Future_2081-2100_ssp585` #> class       : SpatRaster  #> size        : 52, 40, 4  (nrow, ncol, nlyr) #> resolution  : 0.1666667, 0.1666667  (x, y) #> extent      : -53.5, -46.83333, -30.83333, -22.16667  (xmin, xmax, ymin, ymax) #> coord. ref. : lon/lat WGS 84 (EPSG:4326)  #> source(s)   : memory #> names       :           Unsuitable-stable,           Gain,           Loss,           Suitable-stable  #> min values  : Unsuitable-stable in 0 GCMs, Gain in 0 GCMs, Loss in 0 GCMs, Suitable-stable in 0 GCMs  #> max values  : Unsuitable-stable in 2 GCMs, Gain in 2 GCMs, Loss in 2 GCMs, Suitable-stable in 1 GCMs  #>  terra::plot(changes$Results_by_change$`Future_2041-2060_ssp585`)  # an example of the previous  terra::plot(changes$Summary_changes)  # SpatRaster with a general summary"},{"path":"https://marlonecobos.github.io/kuenm2/reference/projection_mop.html","id":null,"dir":"Reference","previous_headings":"","what":"Analysis of extrapolation risks in projections using the MOP metric — projection_mop","title":"Analysis of extrapolation risks in projections using the MOP metric — projection_mop","text":"Calculates mobility-oriented parity metric sub-products represent dissimilarities non-analogous conditions comparing set reference conditions (M) model projection conditions (G).","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/projection_mop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analysis of extrapolation risks in projections using the MOP metric — projection_mop","text":"","code":"projection_mop(data, projection_data, out_dir, fitted_models = NULL,                subset_variables = TRUE, mask = NULL,  type = \"basic\",                calculate_distance = FALSE, where_distance = \"in_range\",                distance = \"euclidean\", scale = FALSE, center = FALSE,                fix_NA = TRUE, percentage = 1, comp_each = 2000, tol = NULL,                rescale_distance = FALSE, parallel = FALSE, ncores = NULL,                progress_bar = TRUE, overwrite = FALSE)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/projection_mop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analysis of extrapolation risks in projections using the MOP metric — projection_mop","text":"data object class prepared_data returned prepare_data() function. projection_data object class projection_data returned prepare_projection()function. file contains paths rasters representing scenario. out_dir (character) path root directory saving raster file projection. fitted_models object class fitted_models returned fit_selected() function. subset_variables (logical) whether include analysis variables present selected models. Default TRUE. mask (SpatRaster, SpatVector, SpatExtent) spatial object used mask variables (optional). Default NULL. type (character) type MOP analysis performed. Options available \"basic\", \"simple\" \"detailed\". See Details information. calculate_distance (logical) whether calculate distances (dissimilarities) m g. default, FALSE, runs rapidly assess dissimilarity levels. where_distance (character) calculate distances, considering conditions g positioned comparison range conditions m. Options available \"in_range\", \"out_range\" \"\". Default \"in_range\". distance (character) distances calculated, euclidean mahalanobis. applicable calculate_distance = TRUE. scale (logical numeric) whether scale scale. Default FALSE. center (logical numeric) whether center scale. Default FALSE. fix_NA (logical) whether fix layers cells NA values layers. Setting FALSE may save time rasters big NA matching problems. Default TRUE. percentage (numeric) percentage m closest conditions used derive mean environmental distances combination conditions g. comp_each (numeric) number combinations g used distance calculations time. Increasing number requires RAM tol (numeric) tolerance detect linear dependencies calculating Mahalanobis distances. default, NULL, uses .Machine$double.eps. rescale_distance (logical) whether re-scale distances 0-1. Re-scaling prevents comparisons dissimilarity values obtained runs different values percentage. parallel (logical) whether fit candidate models parallel. Default FALSE. ncores (numeric) number cores use parallel processing. Default NULL uses available cores - 1. applicable parallel = TRUE. progress_bar (logical) whether display progress bar processing. Default TRUE. overwrite (logical) whether overwrite SpatRaster already exists. applicable write_files set TRUE. Default FALSE.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/projection_mop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analysis of extrapolation risks in projections using the MOP metric — projection_mop","text":"object class mop_projections, root directory dataframe containing file paths results stored scenario. paths contain following files: summary - data.frame details data used analysis: variables - names variables considered. type - type MOP analysis performed. scale - value according argument scale. center - value according argument center. calculate_distance - value according argument calculate_distance. distance - option regarding distance used. percentage - percentage m used reference distance calculation. rescale_distance - value according argument rescale_distance. fix_NA - value according argument fix_NA. N_m - total number elements (cells values valid rows) m. N_g - total number elements (cells values valid rows) g. m_min - minimum values (lower limit) variables reference conditions (m). m_max - maximum values (upper limit) variables reference conditions (m). mop_distances - calculate_distance = TRUE, SpatRaster vector distance values set interest (g). Higher values represent greater dissimilarity compared set reference (m). mop_basic - SpatRaster vector, set interest, representing conditions least one variables non-analogous set reference. Values : 1 non-analogous conditions, NA conditions inside ranges reference set. mop_simple - SpatRaster vector, set interest, representing many variables set interest non-analogous reference set. NA used conditions inside ranges reference set. mop_detailed - list containing: interpretation_combined - data.frame help identify combinations variables towards_low_combined towards_high_combined non-analogous m. towards_low_end - SpatRaster matrix variables representing non-analogous conditions found towards low values variable. towards_high_end - SpatRaster matrix variables representing non-analogous conditions found towards high values variable. towards_low_combined - SpatRaster vector values representing identity variables found non-analogous conditions towards low values. vector, interpretation requires use data.frame interpretation_combined. towards_high_combined - SpatRaster vector values representing identity variables found non-analogous conditions towards high values. vector, interpretation requires use data.frame interpretation_combined.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/projection_mop.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Analysis of extrapolation risks in projections using the MOP metric — projection_mop","text":"type options return results differ detail non-analogous conditions identified. basic - makes calculation proposed Owens et al. (2013) doi:10.1016/j.ecolmodel.2013.04.011. simple - calculates many variables set interest non-analogous reference set. detailed - calculates five additional extrapolation metrics. See mop_detailed Value full details. where_distance options determine values used calculate dissimilarity in_range - conditions inside m ranges out_range - conditions outside m ranges - conditions variables used represent conditions different units, scaling centering recommended. step valid Euclidean distances used.","code":""},{"path":[]},{"path":"https://marlonecobos.github.io/kuenm2/reference/projection_mop.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analysis of extrapolation risks in projections using the MOP metric — projection_mop","text":"","code":"# Step 1: Import prepared data to serve as a base for MOP comparisons data(sp_swd_cat, package = \"kuenm2\")  # Step 2: Organize variables for current projection ## Import current variables (used to fit models) var <- terra::rast(system.file(\"extdata\", \"Current_variables.tif\",                                package = \"kuenm2\"))  ## Create a folder in a temporary directory to copy the variables out_dir_current <- file.path(tempdir(), \"Current_raw4\") dir.create(out_dir_current, recursive = TRUE)  ## Save current variables in temporary directory terra::writeRaster(var, file.path(out_dir_current, \"Variables.tif\"))   # Step 3: Organize future climate variables (example with WorldClim) ## Directory containing the downloaded future climate variables (example) in_dir <- system.file(\"extdata\", package = \"kuenm2\")  ## Create a folder in a temporary directory to copy the future variables out_dir_future <- file.path(tempdir(), \"Future_raw4\")  ## Organize and rename the future climate data (structured by year and GCM) ### 'SoilType' will be appended as a static variable in each scenario organize_future_worldclim(input_dir = in_dir, output_dir = out_dir_future,                           name_format = \"bio_\", fixed_variables = var$SoilType) #>    |                                                                               |                                                                      |   0%   |                                                                               |=========                                                             |  12%   |                                                                               |==================                                                    |  25%   |                                                                               |==========================                                            |  38%   |                                                                               |===================================                                   |  50%   |                                                                               |============================================                          |  62%   |                                                                               |====================================================                  |  75%   |                                                                               |=============================================================         |  88%   |                                                                               |======================================================================| 100% #>  #> Variables successfully organized in directory: #> /tmp/RtmpraqRyK/Future_raw4  # Step 4: Prepare data to run multiple projections ## An example with maxnet models ## Import example of fitted_models (output of fit_selected()) data(fitted_model_maxnet, package = \"kuenm2\")  ## Prepare projection data using fitted models to check variables pr <- prepare_projection(models = fitted_model_maxnet,                          present_dir = out_dir_current,                          future_dir = out_dir_future,                          future_period = c(\"2041-2060\", \"2081-2100\"),                          future_pscen = c(\"ssp126\", \"ssp585\"),                          future_gcm = c(\"ACCESS-CM2\", \"MIROC6\"),                          raster_pattern = \".tif*\")  # Step 5: Perform MOP for all projection scenarios ## Create a folder to save MOP results out_dir <- file.path(tempdir(), \"MOPresults\") dir.create(out_dir, recursive = TRUE)  ## Run MOP kmop <- projection_mop(data = sp_swd_cat, projection_data = pr,                        out_dir = out_dir, fitted_models = fitted_model_maxnet,                        type = \"detailed\") #>    |                                                                               |                                                                      |   0%   |                                                                               |========                                                              |  11%   |                                                                               |================                                                      |  22%   |                                                                               |=======================                                               |  33%   |                                                                               |===============================                                       |  44%   |                                                                               |=======================================                               |  56%   |                                                                               |===============================================                       |  67%   |                                                                               |======================================================                |  78%   |                                                                               |==============================================================        |  89%   |                                                                               |======================================================================| 100%"},{"path":"https://marlonecobos.github.io/kuenm2/reference/projection_variability.html","id":null,"dir":"Reference","previous_headings":"","what":"Explores variance coming from distinct sources in model predictions — projection_variability","title":"Explores variance coming from distinct sources in model predictions — projection_variability","text":"Calculates variance model predictions, distinguishing different sources variation. Potential sources include replicates, model parameterizations, general circulation models (GCMs).","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/projection_variability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Explores variance coming from distinct sources in model predictions — projection_variability","text":"","code":"projection_variability(model_projections, by_replicate = TRUE, by_gcm = TRUE,                        by_model = TRUE, consensus = \"median\",                        write_files = FALSE, output_dir = NULL,                        return_rasters = TRUE, progress_bar = FALSE,                        verbose = TRUE, overwrite = FALSE)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/projection_variability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Explores variance coming from distinct sources in model predictions — projection_variability","text":"model_projections model_projections object generated project_selected() function. object contains file paths raster projection results thresholds used binarizing predictions. by_replicate (logical) whether compute variance originating replicates. by_gcm (logical) whether compute variance originating general circulation models (GCMs) by_model (logical) whether compute variance originating model parameterizations. consensus (character) (character) consensus measure use calculating changes. Available options 'mean', 'median', 'range', 'stdev' (standard deviation). Default 'median'. write_files (logical) whether write raster files containing computed variance disk. Default FALSE. output_dir (character) directory path resulting raster files containing computed changes saved. relevant write_results = TRUE. return_rasters (logical) whether return list containing SpatRasters computed changes. Default TRUE. Setting argument FALSE returns NULL object. progress_bar (logical) whether display progress bar processing. Default TRUE. verbose (logical) whether display messages processing. Default TRUE. overwrite whether overwrite SpatRaster already exists. applicable write_files set TRUE. Default FALSE.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/projection_variability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Explores variance coming from distinct sources in model predictions — projection_variability","text":"object class variability_projections. return_rasters = TRUE, function returns list containing SpatRasters computed variances, categorized replicate, model, GCMs. write_files = TRUE, also returns directory path computed rasters saved disk, object can used import files later import_projections() function. return_rasters = FALSE write_files = FALSE, function returns NULL","code":""},{"path":[]},{"path":"https://marlonecobos.github.io/kuenm2/reference/projection_variability.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Explores variance coming from distinct sources in model predictions — projection_variability","text":"","code":"# Step 1: Organize variables for current projection ## Import current variables (used to fit models) var <- terra::rast(system.file(\"extdata\", \"Current_variables.tif\",                                package = \"kuenm2\"))  ## Create a folder in a temporary directory to copy the variables out_dir_current <- file.path(tempdir(), \"Current_raw5\") dir.create(out_dir_current, recursive = TRUE)  ## Save current variables in temporary directory terra::writeRaster(var, file.path(out_dir_current, \"Variables.tif\"))   # Step 2: Organize future climate variables (example with WorldClim) ## Directory containing the downloaded future climate variables (example) in_dir <- system.file(\"extdata\", package = \"kuenm2\")  ## Create a folder in a temporary directory to copy the future variables out_dir_future <- file.path(tempdir(), \"Future_raw5\")  ## Organize and rename the future climate data (structured by year and GCM) ### 'SoilType' will be appended as a static variable in each scenario organize_future_worldclim(input_dir = in_dir, output_dir = out_dir_future,                           name_format = \"bio_\", fixed_variables = var$SoilType) #>    |                                                                               |                                                                      |   0%   |                                                                               |=========                                                             |  12%   |                                                                               |==================                                                    |  25%   |                                                                               |==========================                                            |  38%   |                                                                               |===================================                                   |  50%   |                                                                               |============================================                          |  62%   |                                                                               |====================================================                  |  75%   |                                                                               |=============================================================         |  88%   |                                                                               |======================================================================| 100% #>  #> Variables successfully organized in directory: #> /tmp/RtmpraqRyK/Future_raw5  # Step 3: Prepare data to run multiple projections ## An example with maxnet models ## Import example of fitted_models (output of fit_selected()) data(fitted_model_maxnet, package = \"kuenm2\")  ## Prepare projection data using fitted models to check variables pr <- prepare_projection(models = fitted_model_maxnet,                          present_dir = out_dir_current,                          future_dir = out_dir_future,                          future_period = c(\"2041-2060\", \"2081-2100\"),                          future_pscen = c(\"ssp126\", \"ssp585\"),                          future_gcm = c(\"ACCESS-CM2\", \"MIROC6\"),                          raster_pattern = \".tif*\")  # Step 4: Run multiple model projections ## A folder to save projection results out_dir <- file.path(tempdir(), \"Projection_results/maxnet3\") dir.create(out_dir, recursive = TRUE)  ## Project selected models to multiple scenarios p <- project_selected(models = fitted_model_maxnet, projection_data = pr,                       out_dir = out_dir) #>    |                                                                               |                                                                      |   0%   |                                                                               |========                                                              |  11%   |                                                                               |================                                                      |  22%   |                                                                               |=======================                                               |  33%   |                                                                               |===============================                                       |  44%   |                                                                               |=======================================                               |  56%   |                                                                               |===============================================                       |  67%   |                                                                               |======================================================                |  78%   |                                                                               |==============================================================        |  89%   |                                                                               |======================================================================| 100%  # Step 5: Compute variance from distinct sources v <- projection_variability(model_projections = p, by_replicate = FALSE) #> Calculating variability from distinct models: scenario 1 of 5 #> Calculating variability from distinct models: scenario 2 of 5 #> Calculating variability from distinct GCMs: scenario 2 of 5 #> Calculating variability from distinct models: scenario 3 of 5 #> Calculating variability from distinct GCMs: scenario 3 of 5 #> Calculating variability from distinct models: scenario 4 of 5 #> Calculating variability from distinct GCMs: scenario 4 of 5 #> Calculating variability from distinct models: scenario 5 of 5 #> Calculating variability from distinct GCMs: scenario 5 of 5  #terra::plot(v$Present$by_rep)  # Variance from replicates, present projection terra::plot(v$Present$by_model)  # From models  #terra::plot(v$`Future_2041-2060_ssp126`$by_rep)  # From replicates future projection terra::plot(v$`Future_2041-2060_ssp126`$by_model)  # From models  terra::plot(v$`Future_2041-2060_ssp126`$by_gcm)  # From GCMs"},{"path":"https://marlonecobos.github.io/kuenm2/reference/response_curve.html","id":null,"dir":"Reference","previous_headings":"","what":"Variable response curves for fitted models — response_curve","title":"Variable response curves for fitted models — response_curve","text":"view variable responses fitted models. Responses based single multiple models can plotted.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/response_curve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variable response curves for fitted models — response_curve","text":"","code":"response_curve(models, variable, modelID = NULL, n = 100,                by_replicates = FALSE, data = NULL, new_data = NULL,                averages_from = \"pr_bg\", extrapolate = TRUE,                extrapolation_factor = 0.1, add_points = FALSE, p_col = NULL,                l_limit = NULL, u_limit = NULL,                xlab = NULL, ylab = \"Suitability\",                col = \"darkblue\", ...)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/response_curve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variable response curves for fitted models — response_curve","text":"models object class fitted_models returned fit_selected() function. variable (character) name variable plotted. modelID (character) vector ModelID(s) considered models object. default models included.Default = NULL. n (numeric) integer guiding number breaks. Default = 100 by_replicates (logical) whether use replicates full_model estimate model's response curve. Default = FALSE. data data.frame matrix data used model calibration step. Default = NULL. new_data SpatRaster, data.frame,  matrix variables representing range variable values area interest. Default = NULL. must defined case model entered explicitly include data component. averages_from (character) specifies averages modes variables calculated. Available options \"pr\" (calculate averages presence localities) \"pr_bg\" (use combined set presence background localities). Default \"pr_bg\". See details. extrapolate (logical) whether allow extrapolation study behavior response outside calibration limits. Ignored new_data defined. Default = TRUE. extrapolation_factor (numeric) multiplier used calculate extrapolation range. Larger values allow broader extrapolation beyond observed data range. Default 0.1. add_points (logical) TRUE, adds original observed points (0/1) plot. Default = FALSE. p_col (character) color observed points add_points = TRUE. valid R color name hexadecimal code. Default = \"black\". l_limit (numeric) specifies lower limit variable. Default NULL, meaning lower limit calculated based data's minimum value extrapolation_factor (extrapolation = TRUE). u_limit (numeric) specifies upper limit variable. Default NULL, meaning upper limit calculated based data's minimum value extrapolation_factor (extrapolation = TRUE). xlab (character) label x axis. default, NULL, uses name defined variable. ylab (character) label y axis. Default = \"Suitability\". col (character) color lines. Default = \"darkblue\". ... additional arguments passed plot.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/response_curve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variable response curves for fitted models — response_curve","text":"plot response curve variable.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/response_curve.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Variable response curves for fitted models — response_curve","text":"response curves generated variables set mean values (mode categorical variables), calculated either presence localities (averages_from = \"pr\") combined set presence background localities (averages_from = \"pr_bg\"). categorical variables, bar plot generated error bars showing variability across models (multiple models included).","code":""},{"path":[]},{"path":"https://marlonecobos.github.io/kuenm2/reference/response_curve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Variable response curves for fitted models — response_curve","text":"","code":"# Example with maxnet # Import example of fitted_models (output of fit_selected()) data(fitted_model_maxnet, package = \"kuenm2\")  #Response curves response_curve(models = fitted_model_maxnet,                variable = \"bio_1\", by_replicates = TRUE)  response_curve(models = fitted_model_maxnet, variable = \"bio_1\",                modelID = \"Model_189\", by_replicates = TRUE)   # Example with GLM # Import example of fitted_models (output of fit_selected()) data(fitted_model_glm, package = \"kuenm2\")  #Response curves response_curve(models = fitted_model_glm,                variable = \"bio_1\", by_replicates = TRUE)  response_curve(models = fitted_model_glm, variable = \"bio_1\",                modelID = \"Model_86\", by_replicates = TRUE)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/select_models.html","id":null,"dir":"Reference","previous_headings":"","what":"Select models that perform the best among candidates — select_models","title":"Select models that perform the best among candidates — select_models","text":"function selects best models according user-defined criteria, evaluating statistical significance (partial ROC), predictive ability (omission rates), model complexity (AIC).","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/select_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select models that perform the best among candidates — select_models","text":"","code":"select_models(calibration_results = NULL, candidate_models = NULL, data = NULL,               algorithm = NULL, compute_proc = FALSE,               addsamplestobackground = TRUE, weights = NULL,               remove_concave = FALSE, omission_rate = NULL,               allow_tolerance = TRUE, tolerance = 0.01,               significance = 0.05, delta_aic = 2, parallel = FALSE,               ncores = NULL, progress_bar = FALSE,verbose = TRUE)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/select_models.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select models that perform the best among candidates — select_models","text":"calibration_results object class calibration_results returned calibration() function. Default NULL. candidate_models (data.frame) summary evaluation metrics candidate model. Required calibration_results NULL. output calibration(), data.frame located $calibration_results$Summary. Default NULL. data object class prepared_data returned prepare_data() function. Required calibration_results NULL compute_proc TRUE. algorithm (character) model algorithm, either \"glm\" \"maxnet\". default, NULL, uses one defined part calibration_results, data. arguments used, algorithm must defined. compute_proc (logical) whether compute partial ROC tests selected models. required partial ROC calculated candidate models calibration. Default FALSE. addsamplestobackground (logical) whether add background presence sample already . Required compute_proc TRUE calibration_results NULL.Default TRUE. weights (numeric) numeric vector specifying weights occurrence records. Required compute_proc TRUE calibration_results NULL. Default NULL. remove_concave (logical) whether remove candidate models presenting concave curves. Default FALSE. omission_rate (numeric) maximum omission rate candidate model can considered potentially selected model. default, NULL, uses value provided part calibration_results. purposes selection existing results evaluation, value must match one values used omission tests, must manually defined. allow_tolerance (logical) whether allow selection models minimum values omission rates even omission rate surpasses omission_rate. applicable candidate models omission rates higher omission_rate. Default TRUE. tolerance (numeric) value added minimum omission rate exceeds omission_rate. allow_tolerance = TRUE, selected models omission rate equal less minimum rate plus tolerance. Default 0.01. significance (numeric) significance level select models based partial ROC (pROC). Default 0.05. See Details. delta_aic (numeric) value delta AIC used threshold select models. Default 2. parallel (logical) whether calculate PROC candidate models parallel. Default FALSE. ncores (numeric) number cores use parallel processing. Default NULL uses available cores - 1. applicable parallel = TRUE. progress_bar (logical) whether display progress bar processing. Default TRUE. verbose (logical) whether display messages processing. Default TRUE.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/select_models.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select models that perform the best among candidates — select_models","text":"calibration_results provided, returns new calibration_results new selected models summary. calibration_results NULL, returns list containing following elements: selected_models: data frame ID summary evaluation metrics selected models. summary: list containing delta AIC values model selection, ID values models failed fit, concave curves, non-significant pROC values, omission rates threshold, delta AIC values threshold, selected models.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/select_models.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Select models that perform the best among candidates — select_models","text":"Partial ROC calculated following Peterson et al. (2008).","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/select_models.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select models that perform the best among candidates — select_models","text":"","code":"# Import example of calibration results (output of calibration function) ## GLM data(calib_results_glm, package = \"kuenm2\")  #Select new best models based on another value of omission rate new_best_model <- select_models(calibration_results = calib_results_glm,                                 algorithm = \"glm\", compute_proc = TRUE,                                 omission_rate = 10)  # Omission error of 10 #> Selecting best among 100 models. #> Calculating pROC... #>  #> Filtering 100 models. #> Removing 0 model(s) because they failed to fit. #> 51 models were selected with omission rate below 10%. #> Selecting 3 final model(s) with delta AIC <2. #> Validating pROC of selected models... #>  #> All selected models have significant pROC values.  # Compare with best models selected previously calib_results_glm$summary$Selected  # Model 86 selected #> [1] 86 new_best_model$summary$Selected  # Models 64, 73 and 86 selected #> [1] 64 73 86"},{"path":"https://marlonecobos.github.io/kuenm2/reference/variable_importance.html","id":null,"dir":"Reference","previous_headings":"","what":"Variable importance — variable_importance","title":"Variable importance — variable_importance","text":"Variable importance","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/variable_importance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variable importance — variable_importance","text":"","code":"variable_importance(models, modelID = NULL, parallel = FALSE, ncores = NULL,                     progress_bar = TRUE, verbose = TRUE)"},{"path":"https://marlonecobos.github.io/kuenm2/reference/variable_importance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variable importance — variable_importance","text":"models object class fitted_models returned fit_selected() function. modelID (character). Default = NULL. parallel (logical) whether calculate importance parallel. Default FALSE. ncores (numeric) number cores use parallel processing. Default NULL uses available cores - 1. applicable parallel = TRUE. progress_bar (logical) whether display progress bar processing. Default TRUE. verbose (logical) whether display detailed messages processing. Default TRUE.","code":""},{"path":"https://marlonecobos.github.io/kuenm2/reference/variable_importance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variable importance — variable_importance","text":"data.frame containing relative contribution variable. identification distinct models added fitted contains multiple models.","code":""},{"path":[]},{"path":"https://marlonecobos.github.io/kuenm2/reference/variable_importance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Variable importance — variable_importance","text":"","code":"# Example with maxnet # Import example of fitted_models (output of fit_selected()) data(fitted_model_maxnet, package = \"kuenm2\")  # Variable importance imp_maxnet <- variable_importance(models = fitted_model_maxnet) #>  #> Calculating variable contribution for model 1 of 2 #>    |                                                                               |                                                                      |   0%   |                                                                               |=======================                                               |  33%   |                                                                               |===============================================                       |  67%   |                                                                               |======================================================================| 100% #>  #> Calculating variable contribution for model 2 of 2 #>    |                                                                               |                                                                      |   0%   |                                                                               |==============                                                        |  20%   |                                                                               |============================                                          |  40%   |                                                                               |==========================================                            |  60%   |                                                                               |========================================================              |  80%   |                                                                               |======================================================================| 100%  # Plot plot_importance(imp_maxnet)   # Example with glm # Import example of fitted_models (output of fit_selected()) data(fitted_model_glm, package = \"kuenm2\")  # Variable importance imp_glm <- variable_importance(models = fitted_model_glm) #>  #> Calculating variable contribution for model 1 of 1 #>    |                                                                               |                                                                      |   0%   |                                                                               |========                                                              |  11%   |                                                                               |================                                                      |  22%   |                                                                               |=======================                                               |  33%   |                                                                               |===============================                                       |  44%   |                                                                               |=======================================                               |  56%   |                                                                               |===============================================                       |  67%   |                                                                               |======================================================                |  78%   |                                                                               |==============================================================        |  89%   |                                                                               |======================================================================| 100%  # Plot plot_importance(imp_glm)"}]
